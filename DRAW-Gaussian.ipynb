{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/train-images-idx3-ubyte.gz\n",
      "Extracting mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"mnist/\", one_hot=True)\n",
    "num_train=mnist.train.num_examples\n",
    "num_val=mnist.validation.num_examples\n",
    "num_test=mnist.test.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predefined parameters\n",
    "channel=1\n",
    "height=28\n",
    "width=28\n",
    "patch=7\n",
    "n_glimpse=15\n",
    "lstm_hidden_dim=256\n",
    "latent_dim=512\n",
    "eps=1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "def decode_attention_para(hidden_decode,paser):\n",
    "    '''\n",
    "    calculate parameters(gx,gy,sigma,stride,gamma) from h_dec\n",
    "    each is (batch,1) tensor\n",
    "    '''\n",
    "    paras=paser(hidden_decode)\n",
    "    gx,gy,sigma,stride,gamma=tf.split(paras,[1,1,1,1,1],axis=1)\n",
    "    gx=(gx+1.0)*(width+1)/2.0\n",
    "    gy=(gy+1.0)*(height+1)/2.0\n",
    "    sigma=tf.exp(sigma)\n",
    "    stride=tf.exp(stride)*(max(width,height)-1.0)/(patch-1.0)\n",
    "    gamma=tf.exp(gamma)\n",
    "    return gx,gy,sigma,stride,gamma\n",
    "\n",
    "\n",
    "def filterbank(batch_size,gx,gy,sigma,stride):\n",
    "    '''\n",
    "    calculate filterbank FX and FY using parameters\n",
    "    shape of FX is (batch,channel,patch,width), each tensor in axis=3 is gaussian distribution centered at gx and scale is sigma\n",
    "    shape of FY is (batch,channel,patch,height), similar to FX\n",
    "    '''\n",
    "    # initialize FY, shape=(batch,patch,height), value is multipling range(height) for (batch*patch) times\n",
    "    FY=tf.tile(tf.reshape(tf.range(height,dtype=tf.float32),(1,1,height)),multiples=(batch_size,patch,1))\n",
    "    # center position, shape=(batch,patch), value is like (-2stride+gy,-stride+gy,gy,stride+gy,2stride+gy) for all batches\n",
    "    py=tf.tile(tf.reshape(tf.range(patch,dtype=tf.float32)-(patch-1)//2,(1,patch)),multiples=(batch_size,1))*stride+gy\n",
    "    # gaussian distribution of FY, shape is the same as FY, value is gaussian for all batches\n",
    "    FY=tf.exp(-tf.square(FY-tf.reshape(py,(-1,patch,1)))/2.0*tf.reshape(sigma,(-1,1,1)))   # modified\n",
    "    # normalized FY, shape=(batch,patch,height), each vector is sumed to 1\n",
    "    FY/=(eps+tf.reduce_sum(FY,axis=2,keep_dims=True))   # modified: add eps for numerical stability\n",
    "    # copy through all channels, shape=(batch,channel,patch,height)\n",
    "    FY=tf.tile(tf.reshape(FY,[-1,1,patch,height]),(1,channel,1,1))\n",
    "    \n",
    "    FX=tf.tile(tf.reshape(tf.range(width,dtype=tf.float32),(1,1,width)),multiples=(batch_size,patch,1))\n",
    "    px=tf.tile(tf.reshape(tf.range(patch,dtype=tf.float32)-(patch-1)//2,(1,patch)),multiples=(batch_size,1))*stride+gx\n",
    "    FX=tf.exp(-tf.square(FX-tf.reshape(px,(-1,patch,1)))/2.0*tf.reshape(sigma,(-1,1,1)))   # modified\n",
    "    FX/=(eps+tf.reduce_sum(FX,axis=2,keep_dims=True))   # modified\n",
    "    FX=tf.tile(tf.reshape(FX,[-1,1,patch,width]),(1,channel,1,1))\n",
    "    return FX,FY\n",
    "\n",
    "def read(image,FX,FY,gamma):\n",
    "    '''\n",
    "    Inputs:\n",
    "    image, shape=(batch,channel,height,width)\n",
    "    filterbank FX, shape=(batch,channel,patch,width)\n",
    "    filterbank FY, shape=(batch,channel,patch,height)\n",
    "    scale intensity gamma, shape=(batch,1)\n",
    "    \n",
    "    Outputs:\n",
    "    encoded patch, shape=(batch,channel*patch*patch)\n",
    "    '''\n",
    "    patch_image=tf.matmul(tf.matmul(FY,X),FX,transpose_b=True)*tf.reshape(gamma,(-1,1,1,1))\n",
    "    patch_image=tf.layers.flatten(patch_image)\n",
    "    return patch_image\n",
    "    \n",
    "def write(pat,batch_size,FX,FY,gamma):\n",
    "    '''\n",
    "    Inputs:\n",
    "    pat, patch decode from hidden, shape=(batch,channel*patch*patch)\n",
    "    filterbank FX, shape=(batch,channel,patch,width)\n",
    "    filterbank FY, shape=(batch,channel,patch,height)\n",
    "    scale intensity gamma, shape=(batch,1)\n",
    "    \n",
    "    Outputs:\n",
    "    decoded image, shape=(batch,channel,height,width)\n",
    "    '''\n",
    "    pat=tf.reshape(pat,(batch_size,channel,patch,patch))\n",
    "    reconstruct_image=tf.matmul(tf.matmul(FY,pat,transpose_a=True),FX)/tf.reshape(gamma,(-1,1,1,1))\n",
    "    return reconstruct_image\n",
    "\n",
    "def logistic_likelihood(original_image,recon_image):\n",
    "    return -(original_image*tf.log(eps+recon_image)+(1.0-original_image)*tf.log(1.0-recon_image))\n",
    "\n",
    "\n",
    "# input\n",
    "X=tf.placeholder(shape=[None,channel,height,width],dtype=tf.float32,name='input_image')\n",
    "batch_size=tf.shape(X)[0]\n",
    "canvas=tf.zeros(shape=[batch_size,channel,height,width],dtype=tf.float32,name='output_canvas')\n",
    "\n",
    "READ_attention_paras=tf.layers.Dense(units=5,name='attention_para_read')   # calculate parameters for READ operation\n",
    "WRITE_attention_paras=tf.layers.Dense(units=5,name='attention_para_write')   # calculate parameters for WRITE operation\n",
    "WRITE_patch=tf.layers.Dense(units=channel*patch*patch,name='patch_write')   # calculate patch_image for WRITE operation\n",
    "encoder_lstm=tf.contrib.rnn.LSTMCell(lstm_hidden_dim)\n",
    "decoder_lstm=tf.contrib.rnn.LSTMCell(lstm_hidden_dim)\n",
    "init_state_encode=encoder_lstm.zero_state(batch_size, tf.float32)   # lstm tuple (c,h)\n",
    "init_state_decode=decoder_lstm.zero_state(batch_size, tf.float32)   # lstm tuple (c,h)\n",
    "state_encode=None\n",
    "state_decode=None\n",
    "encoder_mean=tf.layers.Dense(units=latent_dim,name='encoder_mean')   # calculate mean of z\n",
    "encoder_std=tf.layers.Dense(units=latent_dim,name='encoder_std')   # calculate std of z\n",
    "unit_gaussian=tf.distributions.Normal(loc=tf.zeros(latent_dim),scale=tf.ones(latent_dim),name='unit_norm')\n",
    "\n",
    "read_paras_his=[]\n",
    "write_paras_his=[]\n",
    "canvas_his=[]\n",
    "latent_loss_his=[]\n",
    "likelihood_loss_his=[]\n",
    "\n",
    "for t in range(n_glimpse):\n",
    "    error_image=X-canvas\n",
    "    previous_hidden_decode=init_state_decode[1] if t==0 else state_decode[1]\n",
    "    gx,gy,sigma,stride,gamma=decode_attention_para(previous_hidden_decode,READ_attention_paras)\n",
    "    read_paras_his.append((gx,gy,stride,sigma))\n",
    "    FX,FY=filterbank(batch_size,gx,gy,sigma,stride)\n",
    "    patch_image=read(X,FX,FY,gamma)\n",
    "    patch_error_image=read(error_image,FX,FY,gamma)\n",
    "    encoder_input=tf.concat([patch_image,patch_error_image,previous_hidden_decode],axis=1)\n",
    "    with tf.variable_scope(\"LSTM_encoder\") as vs:\n",
    "        encoder_out,state_encode=encoder_lstm(encoder_input,init_state_encode if t==0 else state_encode)\n",
    "    z_mean=encoder_mean(encoder_out)\n",
    "    z_std=tf.exp(encoder_std(encoder_out))\n",
    "    distrib_encode=tf.distributions.Normal(loc=z_mean,scale=z_std)\n",
    "    Z=distrib_encode.sample()\n",
    "    \n",
    "    latent_loss=tf.reduce_sum(tf.distributions.kl_divergence(distrib_encode,unit_gaussian),axis=1)\n",
    "    latent_loss_his.append(latent_loss)\n",
    "    \n",
    "    with tf.variable_scope(\"LSTM_decoder\") as vs:\n",
    "        decoder_out,state_decode=decoder_lstm(Z,init_state_decode if t==0 else state_decode)\n",
    "    _gx,_gy,_sigma,_stride,_gamma=decode_attention_para(decoder_out,WRITE_attention_paras)\n",
    "    write_paras_his.append((_gx,_gy,_stride,_sigma))\n",
    "    new_patch_image=WRITE_patch(decoder_out)\n",
    "    _FX,_FY=filterbank(batch_size,_gx,_gy,_sigma,_stride)\n",
    "    added_image=write(new_patch_image,batch_size,_FX,_FY,_gamma)\n",
    "    canvas+=added_image\n",
    "    \n",
    "    canvas_his.append(canvas)\n",
    "    \n",
    "total_latent_loss=tf.reduce_mean(latent_loss_his)\n",
    "total_likelihood_loss=tf.reduce_mean(tf.reduce_sum(tf.square(tf.layers.flatten(X)-tf.layers.flatten(canvas)),axis=1))\n",
    "total_loss=total_latent_loss+total_likelihood_loss\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "starter_learning_rate = 1e-3\n",
    "learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,num_train//128, 0.9, staircase=True)\n",
    "optimizier=tf.train.RMSPropOptimizer(learning_rate=starter_learning_rate)\n",
    "# train_step = optimizier.minimize(total_loss,global_step=global_step)\n",
    "train_step = optimizier.minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-08 14:09:06 start epoch 1/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:09:10 iteration 1/429: current training loss = 99.822807 (=3.446402+96.376404)\n",
      "2018-05-08 14:09:16 iteration 50/429: current training loss = 64.820816 (=2.465810+62.355007)\n",
      "2018-05-08 14:09:22 iteration 100/429: current training loss = 54.419647 (=1.494701+52.924946)\n",
      "2018-05-08 14:09:27 iteration 150/429: current training loss = 46.476341 (=1.601865+44.874477)\n",
      "2018-05-08 14:09:32 iteration 200/429: current training loss = 43.925968 (=1.987376+41.938591)\n",
      "2018-05-08 14:09:37 iteration 250/429: current training loss = 40.956562 (=2.275151+38.681412)\n",
      "2018-05-08 14:09:43 iteration 300/429: current training loss = 33.976704 (=2.343101+31.633602)\n",
      "2018-05-08 14:09:48 iteration 350/429: current training loss = 32.114933 (=2.520636+29.594297)\n",
      "2018-05-08 14:09:53 iteration 400/429: current training loss = 32.709564 (=2.688544+30.021019)\n",
      "2018-05-08 14:09:56 iteration 429/429: current training loss = 30.096266 (=2.865751+27.230515)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:10:15 end epoch 1/100: loss_train=31.017169 loss_val=30.939279 loss_test=30.760007\n",
      "\n",
      "2018-05-08 14:10:15 start epoch 2/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:10:15 iteration 1/429: current training loss = 31.085211 (=2.811190+28.274021)\n",
      "2018-05-08 14:10:21 iteration 50/429: current training loss = 30.253695 (=2.965786+27.287909)\n",
      "2018-05-08 14:10:26 iteration 100/429: current training loss = 28.740625 (=2.890053+25.850573)\n",
      "2018-05-08 14:10:32 iteration 150/429: current training loss = 27.072500 (=2.849508+24.222992)\n",
      "2018-05-08 14:10:38 iteration 200/429: current training loss = 26.415977 (=3.003898+23.412079)\n",
      "2018-05-08 14:10:43 iteration 250/429: current training loss = 26.753420 (=2.955783+23.797638)\n",
      "2018-05-08 14:10:49 iteration 300/429: current training loss = 26.694618 (=3.140000+23.554619)\n",
      "2018-05-08 14:10:54 iteration 350/429: current training loss = 25.150484 (=2.887550+22.262934)\n",
      "2018-05-08 14:11:00 iteration 400/429: current training loss = 24.524427 (=3.041131+21.483295)\n",
      "2018-05-08 14:11:04 iteration 429/429: current training loss = 23.483816 (=3.092556+20.391260)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:11:22 end epoch 2/100: loss_train=25.198129 loss_val=25.088973 loss_test=24.880056\n",
      "\n",
      "2018-05-08 14:11:22 start epoch 3/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:11:22 iteration 1/429: current training loss = 25.696655 (=3.089745+22.606911)\n",
      "2018-05-08 14:11:28 iteration 50/429: current training loss = 24.005623 (=3.035926+20.969696)\n",
      "2018-05-08 14:11:34 iteration 100/429: current training loss = 22.432533 (=3.096814+19.335718)\n",
      "2018-05-08 14:11:39 iteration 150/429: current training loss = 23.163797 (=3.119914+20.043882)\n",
      "2018-05-08 14:11:45 iteration 200/429: current training loss = 22.057159 (=3.143465+18.913694)\n",
      "2018-05-08 14:11:51 iteration 250/429: current training loss = 24.533607 (=3.184863+21.348743)\n",
      "2018-05-08 14:11:56 iteration 300/429: current training loss = 22.695398 (=3.348551+19.346848)\n",
      "2018-05-08 14:12:02 iteration 350/429: current training loss = 21.198887 (=2.996261+18.202627)\n",
      "2018-05-08 14:12:07 iteration 400/429: current training loss = 22.226482 (=3.198767+19.027716)\n",
      "2018-05-08 14:12:10 iteration 429/429: current training loss = 21.160357 (=3.146990+18.013367)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:12:28 end epoch 3/100: loss_train=21.727397 loss_val=21.566304 loss_test=21.454042\n",
      "\n",
      "2018-05-08 14:12:28 start epoch 4/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:12:28 iteration 1/429: current training loss = 21.232197 (=3.152485+18.079712)\n",
      "2018-05-08 14:12:33 iteration 50/429: current training loss = 22.121164 (=3.355567+18.765596)\n",
      "2018-05-08 14:12:39 iteration 100/429: current training loss = 22.383949 (=3.308444+19.075504)\n",
      "2018-05-08 14:12:45 iteration 150/429: current training loss = 22.089180 (=3.325864+18.763315)\n",
      "2018-05-08 14:12:50 iteration 200/429: current training loss = 20.969095 (=3.286917+17.682178)\n",
      "2018-05-08 14:12:55 iteration 250/429: current training loss = 21.476965 (=3.383406+18.093559)\n",
      "2018-05-08 14:13:00 iteration 300/429: current training loss = 20.606188 (=3.401310+17.204878)\n",
      "2018-05-08 14:13:06 iteration 350/429: current training loss = 21.223982 (=3.354594+17.869389)\n",
      "2018-05-08 14:13:11 iteration 400/429: current training loss = 19.653786 (=3.635463+16.018322)\n",
      "2018-05-08 14:13:14 iteration 429/429: current training loss = 20.529875 (=3.535715+16.994160)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:13:32 end epoch 4/100: loss_train=19.628999 loss_val=19.483694 loss_test=19.328585\n",
      "\n",
      "2018-05-08 14:13:32 start epoch 5/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:13:32 iteration 1/429: current training loss = 20.066957 (=3.470713+16.596245)\n",
      "2018-05-08 14:13:38 iteration 50/429: current training loss = 18.584946 (=3.348086+15.236860)\n",
      "2018-05-08 14:13:44 iteration 100/429: current training loss = 19.013371 (=3.524257+15.489114)\n",
      "2018-05-08 14:13:50 iteration 150/429: current training loss = 19.105509 (=3.659794+15.445715)\n",
      "2018-05-08 14:13:55 iteration 200/429: current training loss = 19.176048 (=3.806468+15.369579)\n",
      "2018-05-08 14:14:00 iteration 250/429: current training loss = 18.798603 (=3.719034+15.079568)\n",
      "2018-05-08 14:14:06 iteration 300/429: current training loss = 19.164167 (=3.730369+15.433799)\n",
      "2018-05-08 14:14:11 iteration 350/429: current training loss = 18.684479 (=3.743682+14.940796)\n",
      "2018-05-08 14:14:17 iteration 400/429: current training loss = 18.217113 (=3.790072+14.427041)\n",
      "2018-05-08 14:14:20 iteration 429/429: current training loss = 17.632248 (=3.724816+13.907432)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:14:37 end epoch 5/100: loss_train=17.643070 loss_val=17.469778 loss_test=17.422300\n",
      "\n",
      "2018-05-08 14:14:37 start epoch 6/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:14:37 iteration 1/429: current training loss = 17.437532 (=3.663764+13.773768)\n",
      "2018-05-08 14:14:42 iteration 50/429: current training loss = 17.428900 (=3.844475+13.584425)\n",
      "2018-05-08 14:14:48 iteration 100/429: current training loss = 18.562885 (=3.766449+14.796435)\n",
      "2018-05-08 14:14:53 iteration 150/429: current training loss = 16.350819 (=3.611771+12.739047)\n",
      "2018-05-08 14:14:59 iteration 200/429: current training loss = 19.397018 (=4.043052+15.353966)\n",
      "2018-05-08 14:15:04 iteration 250/429: current training loss = 17.141573 (=3.694682+13.446892)\n",
      "2018-05-08 14:15:10 iteration 300/429: current training loss = 16.333351 (=3.616621+12.716731)\n",
      "2018-05-08 14:15:15 iteration 350/429: current training loss = 17.198475 (=3.805890+13.392586)\n",
      "2018-05-08 14:15:20 iteration 400/429: current training loss = 17.527719 (=3.689726+13.837994)\n",
      "2018-05-08 14:15:23 iteration 429/429: current training loss = 16.928968 (=3.712670+13.216298)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:15:41 end epoch 6/100: loss_train=16.694689 loss_val=16.537036 loss_test=16.480842\n",
      "\n",
      "2018-05-08 14:15:41 start epoch 7/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:15:41 iteration 1/429: current training loss = 16.731546 (=3.802895+12.928652)\n",
      "2018-05-08 14:15:46 iteration 50/429: current training loss = 17.371113 (=3.839488+13.531626)\n",
      "2018-05-08 14:15:52 iteration 100/429: current training loss = 16.732367 (=3.872464+12.859901)\n",
      "2018-05-08 14:15:57 iteration 150/429: current training loss = 17.001129 (=3.744097+13.257032)\n",
      "2018-05-08 14:16:03 iteration 200/429: current training loss = 15.739120 (=3.748389+11.990731)\n",
      "2018-05-08 14:16:08 iteration 250/429: current training loss = 16.161364 (=3.836913+12.324451)\n",
      "2018-05-08 14:16:14 iteration 300/429: current training loss = 16.592302 (=3.844780+12.747522)\n",
      "2018-05-08 14:16:19 iteration 350/429: current training loss = 16.201830 (=3.959394+12.242435)\n",
      "2018-05-08 14:16:24 iteration 400/429: current training loss = 15.635313 (=3.727337+11.907976)\n",
      "2018-05-08 14:16:27 iteration 429/429: current training loss = 16.196081 (=4.066482+12.129600)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:16:44 end epoch 7/100: loss_train=15.535836 loss_val=15.365102 loss_test=15.343149\n",
      "\n",
      "2018-05-08 14:16:44 start epoch 8/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:16:44 iteration 1/429: current training loss = 15.975792 (=3.800939+12.174852)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-08 14:16:50 iteration 50/429: current training loss = 16.406328 (=3.873509+12.532819)\n",
      "2018-05-08 14:16:56 iteration 100/429: current training loss = 14.167481 (=3.674333+10.493149)\n",
      "2018-05-08 14:17:01 iteration 150/429: current training loss = 15.257262 (=3.980789+11.276473)\n",
      "2018-05-08 14:17:07 iteration 200/429: current training loss = 15.611237 (=3.877922+11.733315)\n",
      "2018-05-08 14:17:12 iteration 250/429: current training loss = 15.758858 (=3.854396+11.904462)\n",
      "2018-05-08 14:17:17 iteration 300/429: current training loss = 15.870102 (=3.834571+12.035531)\n",
      "2018-05-08 14:17:23 iteration 350/429: current training loss = 15.079950 (=3.760809+11.319141)\n",
      "2018-05-08 14:17:28 iteration 400/429: current training loss = 14.356388 (=3.627188+10.729200)\n",
      "2018-05-08 14:17:31 iteration 429/429: current training loss = 15.178232 (=3.896314+11.281918)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:17:48 end epoch 8/100: loss_train=14.700144 loss_val=14.530088 loss_test=14.545388\n",
      "\n",
      "2018-05-08 14:17:48 start epoch 9/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:17:48 iteration 1/429: current training loss = 15.298243 (=3.954458+11.343784)\n",
      "2018-05-08 14:17:54 iteration 50/429: current training loss = 15.033195 (=3.809696+11.223499)\n",
      "2018-05-08 14:17:59 iteration 100/429: current training loss = 14.963518 (=3.822059+11.141459)\n",
      "2018-05-08 14:18:04 iteration 150/429: current training loss = 14.512060 (=3.680673+10.831387)\n",
      "2018-05-08 14:18:09 iteration 200/429: current training loss = 13.736734 (=3.577136+10.159598)\n",
      "2018-05-08 14:18:15 iteration 250/429: current training loss = 14.724146 (=3.845040+10.879106)\n",
      "2018-05-08 14:18:20 iteration 300/429: current training loss = 14.899364 (=3.928802+10.970561)\n",
      "2018-05-08 14:18:26 iteration 350/429: current training loss = 13.741709 (=3.728113+10.013596)\n",
      "2018-05-08 14:18:31 iteration 400/429: current training loss = 14.206618 (=3.748484+10.458134)\n",
      "2018-05-08 14:18:34 iteration 429/429: current training loss = 14.002213 (=3.735045+10.267168)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:18:52 end epoch 9/100: loss_train=14.048555 loss_val=13.910039 loss_test=13.856358\n",
      "\n",
      "2018-05-08 14:18:52 start epoch 10/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:18:52 iteration 1/429: current training loss = 13.308357 (=3.633878+9.674479)\n",
      "2018-05-08 14:18:57 iteration 50/429: current training loss = 14.162313 (=3.691874+10.470439)\n",
      "2018-05-08 14:19:03 iteration 100/429: current training loss = 13.754044 (=3.760869+9.993175)\n",
      "2018-05-08 14:19:08 iteration 150/429: current training loss = 13.210793 (=3.613417+9.597376)\n",
      "2018-05-08 14:19:14 iteration 200/429: current training loss = 14.266758 (=3.702718+10.564040)\n",
      "2018-05-08 14:19:19 iteration 250/429: current training loss = 13.523214 (=3.568513+9.954701)\n",
      "2018-05-08 14:19:24 iteration 300/429: current training loss = 14.147815 (=3.815736+10.332079)\n",
      "2018-05-08 14:19:30 iteration 350/429: current training loss = 14.351391 (=3.772405+10.578985)\n",
      "2018-05-08 14:19:35 iteration 400/429: current training loss = 13.851257 (=3.817782+10.033475)\n",
      "2018-05-08 14:19:39 iteration 429/429: current training loss = 14.256858 (=3.743787+10.513071)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:19:56 end epoch 10/100: loss_train=13.501642 loss_val=13.330662 loss_test=13.391546\n",
      "\n",
      "2018-05-08 14:19:56 start epoch 11/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:19:57 iteration 1/429: current training loss = 13.255555 (=3.701751+9.553803)\n",
      "2018-05-08 14:20:02 iteration 50/429: current training loss = 13.247346 (=3.743881+9.503466)\n",
      "2018-05-08 14:20:07 iteration 100/429: current training loss = 13.648907 (=3.710742+9.938165)\n",
      "2018-05-08 14:20:13 iteration 150/429: current training loss = 13.716196 (=3.775166+9.941030)\n",
      "2018-05-08 14:20:19 iteration 200/429: current training loss = 13.652301 (=3.752979+9.899322)\n",
      "2018-05-08 14:20:24 iteration 250/429: current training loss = 14.452058 (=3.789891+10.662167)\n",
      "2018-05-08 14:20:30 iteration 300/429: current training loss = 13.837806 (=3.904138+9.933668)\n",
      "2018-05-08 14:20:35 iteration 350/429: current training loss = 14.208703 (=3.752625+10.456078)\n",
      "2018-05-08 14:20:40 iteration 400/429: current training loss = 12.932430 (=3.735185+9.197246)\n",
      "2018-05-08 14:20:43 iteration 429/429: current training loss = 13.912765 (=3.800365+10.112400)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:21:01 end epoch 11/100: loss_train=13.044868 loss_val=12.869959 loss_test=12.941242\n",
      "\n",
      "2018-05-08 14:21:01 start epoch 12/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:21:01 iteration 1/429: current training loss = 12.845150 (=3.686820+9.158331)\n",
      "2018-05-08 14:21:06 iteration 50/429: current training loss = 13.415947 (=3.901392+9.514555)\n",
      "2018-05-08 14:21:12 iteration 100/429: current training loss = 13.266256 (=3.673352+9.592904)\n",
      "2018-05-08 14:21:17 iteration 150/429: current training loss = 12.600895 (=3.639538+8.961357)\n",
      "2018-05-08 14:21:22 iteration 200/429: current training loss = 13.869756 (=3.896816+9.972940)\n",
      "2018-05-08 14:21:28 iteration 250/429: current training loss = 13.654335 (=3.689602+9.964733)\n",
      "2018-05-08 14:21:34 iteration 300/429: current training loss = 13.676199 (=3.669920+10.006279)\n",
      "2018-05-08 14:21:40 iteration 350/429: current training loss = 13.613552 (=3.630365+9.983187)\n",
      "2018-05-08 14:21:46 iteration 400/429: current training loss = 13.235952 (=3.777385+9.458568)\n",
      "2018-05-08 14:21:49 iteration 429/429: current training loss = 13.049252 (=3.669281+9.379972)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:22:06 end epoch 12/100: loss_train=12.541937 loss_val=12.445857 loss_test=12.437210\n",
      "\n",
      "2018-05-08 14:22:06 start epoch 13/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:22:06 iteration 1/429: current training loss = 12.265385 (=3.595371+8.670014)\n",
      "2018-05-08 14:22:12 iteration 50/429: current training loss = 13.312337 (=3.726804+9.585533)\n",
      "2018-05-08 14:22:18 iteration 100/429: current training loss = 12.532622 (=3.690902+8.841721)\n",
      "2018-05-08 14:22:23 iteration 150/429: current training loss = 12.647300 (=3.582732+9.064568)\n",
      "2018-05-08 14:22:28 iteration 200/429: current training loss = 13.858042 (=3.873757+9.984284)\n",
      "2018-05-08 14:22:34 iteration 250/429: current training loss = 12.468689 (=3.605253+8.863437)\n",
      "2018-05-08 14:22:39 iteration 300/429: current training loss = 13.123762 (=3.603765+9.519998)\n",
      "2018-05-08 14:22:44 iteration 350/429: current training loss = 12.410049 (=3.536336+8.873713)\n",
      "2018-05-08 14:22:50 iteration 400/429: current training loss = 12.739697 (=3.797222+8.942475)\n",
      "2018-05-08 14:22:52 iteration 429/429: current training loss = 13.243357 (=3.577008+9.666349)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:23:10 end epoch 13/100: loss_train=13.429424 loss_val=13.311911 loss_test=13.263329\n",
      "\n",
      "2018-05-08 14:23:10 start epoch 14/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:23:10 iteration 1/429: current training loss = 13.917880 (=3.773037+10.144843)\n",
      "2018-05-08 14:23:15 iteration 50/429: current training loss = 12.493529 (=3.535109+8.958421)\n",
      "2018-05-08 14:23:21 iteration 100/429: current training loss = 13.230355 (=3.626064+9.604292)\n",
      "2018-05-08 14:23:26 iteration 150/429: current training loss = 13.550281 (=3.736356+9.813925)\n",
      "2018-05-08 14:23:32 iteration 200/429: current training loss = 13.490647 (=3.848361+9.642286)\n",
      "2018-05-08 14:23:37 iteration 250/429: current training loss = 12.698011 (=3.605789+9.092222)\n",
      "2018-05-08 14:23:43 iteration 300/429: current training loss = 12.435925 (=3.595586+8.840340)\n",
      "2018-05-08 14:23:48 iteration 350/429: current training loss = 13.027552 (=3.708610+9.318941)\n",
      "2018-05-08 14:23:54 iteration 400/429: current training loss = 12.887874 (=3.642571+9.245302)\n",
      "2018-05-08 14:23:57 iteration 429/429: current training loss = 12.281957 (=3.711503+8.570454)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:24:14 end epoch 14/100: loss_train=12.180195 loss_val=12.052906 loss_test=12.068071\n",
      "\n",
      "2018-05-08 14:24:14 start epoch 15/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:24:14 iteration 1/429: current training loss = 11.713657 (=3.533459+8.180199)\n",
      "2018-05-08 14:24:19 iteration 50/429: current training loss = 11.948281 (=3.385324+8.562958)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-08 14:24:25 iteration 100/429: current training loss = 12.148516 (=3.575399+8.573116)\n",
      "2018-05-08 14:24:30 iteration 150/429: current training loss = 12.658076 (=3.602327+9.055750)\n",
      "2018-05-08 14:24:35 iteration 200/429: current training loss = 12.509583 (=3.792895+8.716688)\n",
      "2018-05-08 14:24:40 iteration 250/429: current training loss = 12.670876 (=3.562409+9.108467)\n",
      "2018-05-08 14:24:45 iteration 300/429: current training loss = 12.390611 (=3.473392+8.917218)\n",
      "2018-05-08 14:24:50 iteration 350/429: current training loss = 12.456467 (=3.619895+8.836572)\n",
      "2018-05-08 14:24:56 iteration 400/429: current training loss = 12.390902 (=3.725344+8.665557)\n",
      "2018-05-08 14:24:59 iteration 429/429: current training loss = 12.131765 (=3.647515+8.484250)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:25:16 end epoch 15/100: loss_train=12.080613 loss_val=11.901157 loss_test=11.986913\n",
      "\n",
      "2018-05-08 14:25:16 start epoch 16/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:25:16 iteration 1/429: current training loss = 12.099781 (=3.563629+8.536152)\n",
      "2018-05-08 14:25:21 iteration 50/429: current training loss = 11.806318 (=3.479588+8.326731)\n",
      "2018-05-08 14:25:27 iteration 100/429: current training loss = 11.952854 (=3.596700+8.356153)\n",
      "2018-05-08 14:25:32 iteration 150/429: current training loss = 12.869704 (=3.661637+9.208067)\n",
      "2018-05-08 14:25:38 iteration 200/429: current training loss = 12.744864 (=3.613990+9.130873)\n",
      "2018-05-08 14:25:43 iteration 250/429: current training loss = 11.026591 (=3.393323+7.633268)\n",
      "2018-05-08 14:25:48 iteration 300/429: current training loss = 12.520041 (=3.617902+8.902140)\n",
      "2018-05-08 14:25:53 iteration 350/429: current training loss = 12.306073 (=3.445283+8.860790)\n",
      "2018-05-08 14:25:58 iteration 400/429: current training loss = 11.042480 (=3.442697+7.599782)\n",
      "2018-05-08 14:26:01 iteration 429/429: current training loss = 11.983259 (=3.450971+8.532289)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:26:18 end epoch 16/100: loss_train=11.836784 loss_val=11.683154 loss_test=11.766569\n",
      "\n",
      "2018-05-08 14:26:18 start epoch 17/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:26:18 iteration 1/429: current training loss = 11.608030 (=3.431822+8.176208)\n",
      "2018-05-08 14:26:23 iteration 50/429: current training loss = 12.705538 (=3.572712+9.132825)\n",
      "2018-05-08 14:26:28 iteration 100/429: current training loss = 12.370761 (=3.544967+8.825794)\n",
      "2018-05-08 14:26:33 iteration 150/429: current training loss = 12.754390 (=3.625216+9.129173)\n",
      "2018-05-08 14:26:38 iteration 200/429: current training loss = 11.659742 (=3.428837+8.230906)\n",
      "2018-05-08 14:26:44 iteration 250/429: current training loss = 12.638552 (=3.628795+9.009757)\n",
      "2018-05-08 14:26:49 iteration 300/429: current training loss = 11.073826 (=3.400764+7.673062)\n",
      "2018-05-08 14:26:54 iteration 350/429: current training loss = 12.499454 (=3.707709+8.791745)\n",
      "2018-05-08 14:26:59 iteration 400/429: current training loss = 13.072126 (=3.625108+9.447019)\n",
      "2018-05-08 14:27:02 iteration 429/429: current training loss = 11.672586 (=3.439124+8.233463)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:27:19 end epoch 17/100: loss_train=11.521618 loss_val=11.378417 loss_test=11.487570\n",
      "\n",
      "2018-05-08 14:27:19 start epoch 18/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:27:19 iteration 1/429: current training loss = 11.562757 (=3.514815+8.047942)\n",
      "2018-05-08 14:27:25 iteration 50/429: current training loss = 11.771353 (=3.627371+8.143982)\n",
      "2018-05-08 14:27:30 iteration 100/429: current training loss = 11.642677 (=3.448296+8.194381)\n",
      "2018-05-08 14:27:36 iteration 150/429: current training loss = 11.206486 (=3.484667+7.721819)\n",
      "2018-05-08 14:27:41 iteration 200/429: current training loss = 12.694502 (=3.607521+9.086981)\n",
      "2018-05-08 14:27:46 iteration 250/429: current training loss = 11.727261 (=3.436682+8.290578)\n",
      "2018-05-08 14:27:52 iteration 300/429: current training loss = 12.364169 (=3.491282+8.872887)\n",
      "2018-05-08 14:27:58 iteration 350/429: current training loss = 10.889053 (=3.274143+7.614911)\n",
      "2018-05-08 14:28:03 iteration 400/429: current training loss = 11.358967 (=3.607273+7.751693)\n",
      "2018-05-08 14:28:06 iteration 429/429: current training loss = 11.326097 (=3.413104+7.912994)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:28:23 end epoch 18/100: loss_train=11.371707 loss_val=11.279895 loss_test=11.291470\n",
      "\n",
      "2018-05-08 14:28:23 start epoch 19/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:28:23 iteration 1/429: current training loss = 11.707363 (=3.450682+8.256680)\n",
      "2018-05-08 14:28:28 iteration 50/429: current training loss = 12.251305 (=3.583319+8.667986)\n",
      "2018-05-08 14:28:34 iteration 100/429: current training loss = 11.222532 (=3.461070+7.761462)\n",
      "2018-05-08 14:28:39 iteration 150/429: current training loss = 11.717997 (=3.623020+8.094976)\n",
      "2018-05-08 14:28:45 iteration 200/429: current training loss = 11.562275 (=3.514478+8.047797)\n",
      "2018-05-08 14:28:50 iteration 250/429: current training loss = 10.943144 (=3.464141+7.479002)\n",
      "2018-05-08 14:28:56 iteration 300/429: current training loss = 11.457955 (=3.583533+7.874423)\n",
      "2018-05-08 14:29:01 iteration 350/429: current training loss = 11.702546 (=3.558778+8.143768)\n",
      "2018-05-08 14:29:07 iteration 400/429: current training loss = 11.705196 (=3.523058+8.182138)\n",
      "2018-05-08 14:29:10 iteration 429/429: current training loss = 11.257616 (=3.476298+7.781318)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:29:27 end epoch 19/100: loss_train=11.444837 loss_val=11.366683 loss_test=11.395598\n",
      "\n",
      "2018-05-08 14:29:27 start epoch 20/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:29:27 iteration 1/429: current training loss = 11.505929 (=3.427768+8.078160)\n",
      "2018-05-08 14:29:32 iteration 50/429: current training loss = 11.621696 (=3.246206+8.375490)\n",
      "2018-05-08 14:29:37 iteration 100/429: current training loss = 11.444868 (=3.429161+8.015707)\n",
      "2018-05-08 14:29:42 iteration 150/429: current training loss = 11.265738 (=3.496234+7.769504)\n",
      "2018-05-08 14:29:46 iteration 200/429: current training loss = 10.800178 (=3.324563+7.475615)\n",
      "2018-05-08 14:29:52 iteration 250/429: current training loss = 11.127772 (=3.365088+7.762684)\n",
      "2018-05-08 14:29:57 iteration 300/429: current training loss = 12.101734 (=3.542473+8.559261)\n",
      "2018-05-08 14:30:02 iteration 350/429: current training loss = 11.263397 (=3.457881+7.805516)\n",
      "2018-05-08 14:30:08 iteration 400/429: current training loss = 11.492730 (=3.504707+7.988024)\n",
      "2018-05-08 14:30:11 iteration 429/429: current training loss = 11.602186 (=3.629505+7.972682)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:30:29 end epoch 20/100: loss_train=11.406154 loss_val=11.299860 loss_test=11.327584\n",
      "\n",
      "2018-05-08 14:30:29 start epoch 21/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:30:29 iteration 1/429: current training loss = 11.000731 (=3.378430+7.622302)\n",
      "2018-05-08 14:30:35 iteration 50/429: current training loss = 12.235614 (=3.535731+8.699883)\n",
      "2018-05-08 14:30:41 iteration 100/429: current training loss = 11.543981 (=3.425555+8.118425)\n",
      "2018-05-08 14:30:46 iteration 150/429: current training loss = 12.147875 (=3.552143+8.595733)\n",
      "2018-05-08 14:30:52 iteration 200/429: current training loss = 10.963521 (=3.339851+7.623670)\n",
      "2018-05-08 14:30:57 iteration 250/429: current training loss = 11.345980 (=3.336960+8.009020)\n",
      "2018-05-08 14:31:03 iteration 300/429: current training loss = 12.387239 (=3.557439+8.829800)\n",
      "2018-05-08 14:31:08 iteration 350/429: current training loss = 10.830133 (=3.377193+7.452941)\n",
      "2018-05-08 14:31:14 iteration 400/429: current training loss = 11.175533 (=3.411847+7.763686)\n",
      "2018-05-08 14:31:17 iteration 429/429: current training loss = 10.769546 (=3.532603+7.236943)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:31:34 end epoch 21/100: loss_train=11.097906 loss_val=11.035064 loss_test=11.042200\n",
      "\n",
      "2018-05-08 14:31:34 start epoch 22/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:31:34 iteration 1/429: current training loss = 11.613426 (=3.480745+8.132681)\n",
      "2018-05-08 14:31:39 iteration 50/429: current training loss = 11.176358 (=3.388581+7.787777)\n",
      "2018-05-08 14:31:45 iteration 100/429: current training loss = 10.920362 (=3.359167+7.561195)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-08 14:31:50 iteration 150/429: current training loss = 10.924980 (=3.440863+7.484118)\n",
      "2018-05-08 14:31:55 iteration 200/429: current training loss = 11.255090 (=3.369261+7.885829)\n",
      "2018-05-08 14:32:00 iteration 250/429: current training loss = 10.923490 (=3.371068+7.552422)\n",
      "2018-05-08 14:32:05 iteration 300/429: current training loss = 10.924568 (=3.424950+7.499618)\n",
      "2018-05-08 14:32:11 iteration 350/429: current training loss = 10.302245 (=3.251194+7.051051)\n",
      "2018-05-08 14:32:16 iteration 400/429: current training loss = 11.221402 (=3.467097+7.754306)\n",
      "2018-05-08 14:32:19 iteration 429/429: current training loss = 11.129930 (=3.416262+7.713668)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:32:36 end epoch 22/100: loss_train=10.928938 loss_val=10.831451 loss_test=10.834476\n",
      "\n",
      "2018-05-08 14:32:36 start epoch 23/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:32:36 iteration 1/429: current training loss = 11.255434 (=3.515235+7.740199)\n",
      "2018-05-08 14:32:42 iteration 50/429: current training loss = 11.211248 (=3.487622+7.723626)\n",
      "2018-05-08 14:32:47 iteration 100/429: current training loss = 11.764342 (=3.399299+8.365044)\n",
      "2018-05-08 14:32:53 iteration 150/429: current training loss = 11.384460 (=3.492719+7.891742)\n",
      "2018-05-08 14:32:58 iteration 200/429: current training loss = 11.707148 (=3.575047+8.132101)\n",
      "2018-05-08 14:33:04 iteration 250/429: current training loss = 10.904269 (=3.376941+7.527328)\n",
      "2018-05-08 14:33:09 iteration 300/429: current training loss = 10.320443 (=3.290934+7.029509)\n",
      "2018-05-08 14:33:15 iteration 350/429: current training loss = 11.439976 (=3.368450+8.071526)\n",
      "2018-05-08 14:33:20 iteration 400/429: current training loss = 11.331247 (=3.322938+8.008308)\n",
      "2018-05-08 14:33:23 iteration 429/429: current training loss = 11.598679 (=3.319096+8.279583)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:33:41 end epoch 23/100: loss_train=11.222164 loss_val=11.074251 loss_test=11.180790\n",
      "\n",
      "2018-05-08 14:33:41 start epoch 24/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:33:41 iteration 1/429: current training loss = 11.424900 (=3.390055+8.034844)\n",
      "2018-05-08 14:33:47 iteration 50/429: current training loss = 11.988598 (=3.449317+8.539282)\n",
      "2018-05-08 14:33:52 iteration 100/429: current training loss = 10.644891 (=3.382951+7.261940)\n",
      "2018-05-08 14:33:58 iteration 150/429: current training loss = 12.012984 (=3.579338+8.433646)\n",
      "2018-05-08 14:34:03 iteration 200/429: current training loss = 11.594588 (=3.489090+8.105498)\n",
      "2018-05-08 14:34:08 iteration 250/429: current training loss = 12.144682 (=3.522686+8.621996)\n",
      "2018-05-08 14:34:13 iteration 300/429: current training loss = 9.978674 (=3.245190+6.733483)\n",
      "2018-05-08 14:34:19 iteration 350/429: current training loss = 10.567095 (=3.350762+7.216332)\n",
      "2018-05-08 14:34:24 iteration 400/429: current training loss = 10.669670 (=3.454007+7.215663)\n",
      "2018-05-08 14:34:27 iteration 429/429: current training loss = 10.914827 (=3.483727+7.431100)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:34:45 end epoch 24/100: loss_train=11.084321 loss_val=11.015379 loss_test=11.046639\n",
      "\n",
      "2018-05-08 14:34:45 start epoch 25/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:34:45 iteration 1/429: current training loss = 11.197719 (=3.444989+7.752729)\n",
      "2018-05-08 14:34:50 iteration 50/429: current training loss = 10.776853 (=3.478209+7.298643)\n",
      "2018-05-08 14:34:56 iteration 100/429: current training loss = 11.258608 (=3.559487+7.699121)\n",
      "2018-05-08 14:35:01 iteration 150/429: current training loss = 10.705269 (=3.419043+7.286226)\n",
      "2018-05-08 14:35:06 iteration 200/429: current training loss = 10.533051 (=3.363651+7.169399)\n",
      "2018-05-08 14:35:12 iteration 250/429: current training loss = 9.988051 (=3.250190+6.737861)\n",
      "2018-05-08 14:35:18 iteration 300/429: current training loss = 10.992674 (=3.511393+7.481280)\n",
      "2018-05-08 14:35:23 iteration 350/429: current training loss = 10.855389 (=3.308672+7.546716)\n",
      "2018-05-08 14:35:29 iteration 400/429: current training loss = 11.748476 (=3.557895+8.190580)\n",
      "2018-05-08 14:35:32 iteration 429/429: current training loss = 10.721367 (=3.377141+7.344226)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:35:50 end epoch 25/100: loss_train=11.424789 loss_val=11.323314 loss_test=11.346491\n",
      "\n",
      "2018-05-08 14:35:50 start epoch 26/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:35:50 iteration 1/429: current training loss = 11.938270 (=3.456779+8.481491)\n",
      "2018-05-08 14:35:55 iteration 50/429: current training loss = 11.027910 (=3.276175+7.751736)\n",
      "2018-05-08 14:36:01 iteration 100/429: current training loss = 10.493953 (=3.371817+7.122136)\n",
      "2018-05-08 14:36:06 iteration 150/429: current training loss = 10.198666 (=3.313766+6.884900)\n",
      "2018-05-08 14:36:11 iteration 200/429: current training loss = 11.235291 (=3.336974+7.898316)\n",
      "2018-05-08 14:36:17 iteration 250/429: current training loss = 10.814537 (=3.421686+7.392851)\n",
      "2018-05-08 14:36:22 iteration 300/429: current training loss = 10.876527 (=3.305713+7.570813)\n",
      "2018-05-08 14:36:27 iteration 350/429: current training loss = 10.876503 (=3.410556+7.465947)\n",
      "2018-05-08 14:36:33 iteration 400/429: current training loss = 11.840357 (=3.519367+8.320990)\n",
      "2018-05-08 14:36:36 iteration 429/429: current training loss = 10.990068 (=3.387883+7.602185)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:36:54 end epoch 26/100: loss_train=10.956777 loss_val=10.876786 loss_test=10.874155\n",
      "\n",
      "2018-05-08 14:36:54 start epoch 27/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:36:54 iteration 1/429: current training loss = 10.884259 (=3.368082+7.516178)\n",
      "2018-05-08 14:36:59 iteration 50/429: current training loss = 9.733968 (=3.090876+6.643092)\n",
      "2018-05-08 14:37:05 iteration 100/429: current training loss = 10.642768 (=3.326669+7.316100)\n",
      "2018-05-08 14:37:10 iteration 150/429: current training loss = 9.847466 (=3.156775+6.690691)\n",
      "2018-05-08 14:37:15 iteration 200/429: current training loss = 10.279800 (=3.363313+6.916488)\n",
      "2018-05-08 14:37:21 iteration 250/429: current training loss = 10.253728 (=3.222314+7.031414)\n",
      "2018-05-08 14:37:26 iteration 300/429: current training loss = 10.827359 (=3.363912+7.463447)\n",
      "2018-05-08 14:37:31 iteration 350/429: current training loss = 10.498641 (=3.296125+7.202516)\n",
      "2018-05-08 14:37:37 iteration 400/429: current training loss = 11.089282 (=3.371726+7.717556)\n",
      "2018-05-08 14:37:40 iteration 429/429: current training loss = 10.354165 (=3.477409+6.876756)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:37:57 end epoch 27/100: loss_train=10.102682 loss_val=9.990660 loss_test=10.100434\n",
      "\n",
      "2018-05-08 14:37:57 start epoch 28/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:37:57 iteration 1/429: current training loss = 10.155355 (=3.405998+6.749358)\n",
      "2018-05-08 14:38:02 iteration 50/429: current training loss = 11.522320 (=3.513499+8.008821)\n",
      "2018-05-08 14:38:07 iteration 100/429: current training loss = 11.086949 (=3.298464+7.788486)\n",
      "2018-05-08 14:38:13 iteration 150/429: current training loss = 10.320959 (=3.375955+6.945004)\n",
      "2018-05-08 14:38:18 iteration 200/429: current training loss = 11.392957 (=3.370465+8.022491)\n",
      "2018-05-08 14:38:23 iteration 250/429: current training loss = 10.325448 (=3.241189+7.084259)\n",
      "2018-05-08 14:38:29 iteration 300/429: current training loss = 10.579475 (=3.456011+7.123465)\n",
      "2018-05-08 14:38:34 iteration 350/429: current training loss = 10.437772 (=3.382115+7.055657)\n",
      "2018-05-08 14:38:39 iteration 400/429: current training loss = 10.626575 (=3.390250+7.236324)\n",
      "2018-05-08 14:38:42 iteration 429/429: current training loss = 10.600312 (=3.335917+7.264395)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:39:00 end epoch 28/100: loss_train=10.525561 loss_val=10.448833 loss_test=10.463978\n",
      "\n",
      "2018-05-08 14:39:00 start epoch 29/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:39:00 iteration 1/429: current training loss = 10.552898 (=3.418369+7.134529)\n",
      "2018-05-08 14:39:06 iteration 50/429: current training loss = 10.616809 (=3.283599+7.333210)\n",
      "2018-05-08 14:39:11 iteration 100/429: current training loss = 10.343913 (=3.270482+7.073431)\n",
      "2018-05-08 14:39:16 iteration 150/429: current training loss = 11.111564 (=3.280222+7.831342)\n",
      "2018-05-08 14:39:22 iteration 200/429: current training loss = 9.960520 (=3.189159+6.771361)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-08 14:39:28 iteration 250/429: current training loss = 10.311943 (=3.288332+7.023611)\n",
      "2018-05-08 14:39:33 iteration 300/429: current training loss = 10.622517 (=3.320654+7.301863)\n",
      "2018-05-08 14:39:38 iteration 350/429: current training loss = 10.546897 (=3.489356+7.057541)\n",
      "2018-05-08 14:39:44 iteration 400/429: current training loss = 10.484878 (=3.418944+7.065934)\n",
      "2018-05-08 14:39:47 iteration 429/429: current training loss = 10.246481 (=3.318757+6.927724)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:40:04 end epoch 29/100: loss_train=9.885125 loss_val=9.782084 loss_test=9.843714\n",
      "\n",
      "2018-05-08 14:40:04 start epoch 30/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:40:04 iteration 1/429: current training loss = 9.651613 (=3.224042+6.427570)\n",
      "2018-05-08 14:40:10 iteration 50/429: current training loss = 11.404932 (=3.291097+8.113834)\n",
      "2018-05-08 14:40:15 iteration 100/429: current training loss = 10.105448 (=3.172786+6.932662)\n",
      "2018-05-08 14:40:20 iteration 150/429: current training loss = 10.843303 (=3.430464+7.412839)\n",
      "2018-05-08 14:40:26 iteration 200/429: current training loss = 10.336048 (=3.325317+7.010731)\n",
      "2018-05-08 14:40:31 iteration 250/429: current training loss = 11.243226 (=3.410873+7.832353)\n",
      "2018-05-08 14:40:37 iteration 300/429: current training loss = 9.989082 (=3.251795+6.737287)\n",
      "2018-05-08 14:40:42 iteration 350/429: current training loss = 10.404963 (=3.387642+7.017322)\n",
      "2018-05-08 14:40:48 iteration 400/429: current training loss = 10.196476 (=3.324522+6.871953)\n",
      "2018-05-08 14:40:51 iteration 429/429: current training loss = 10.364536 (=3.310996+7.053540)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:41:08 end epoch 30/100: loss_train=10.490437 loss_val=10.358231 loss_test=10.448782\n",
      "\n",
      "2018-05-08 14:41:08 start epoch 31/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:41:08 iteration 1/429: current training loss = 10.407345 (=3.247983+7.159361)\n",
      "2018-05-08 14:41:14 iteration 50/429: current training loss = 9.787807 (=3.123103+6.664703)\n",
      "2018-05-08 14:41:19 iteration 100/429: current training loss = 10.539745 (=3.234818+7.304927)\n",
      "2018-05-08 14:41:25 iteration 150/429: current training loss = 10.016633 (=3.252246+6.764387)\n",
      "2018-05-08 14:41:31 iteration 200/429: current training loss = 10.270527 (=3.334853+6.935674)\n",
      "2018-05-08 14:41:36 iteration 250/429: current training loss = 9.478832 (=3.108403+6.370430)\n",
      "2018-05-08 14:41:42 iteration 300/429: current training loss = 10.871597 (=3.333832+7.537766)\n",
      "2018-05-08 14:41:48 iteration 350/429: current training loss = 10.773828 (=3.494317+7.279510)\n",
      "2018-05-08 14:41:53 iteration 400/429: current training loss = 10.433061 (=3.422516+7.010545)\n",
      "2018-05-08 14:41:56 iteration 429/429: current training loss = 9.925651 (=3.157295+6.768356)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:42:14 end epoch 31/100: loss_train=10.153748 loss_val=10.088762 loss_test=10.144703\n",
      "\n",
      "2018-05-08 14:42:14 start epoch 32/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:42:14 iteration 1/429: current training loss = 10.166248 (=3.303111+6.863137)\n",
      "2018-05-08 14:42:19 iteration 50/429: current training loss = 10.304307 (=3.339223+6.965084)\n",
      "2018-05-08 14:42:24 iteration 100/429: current training loss = 9.614369 (=3.290932+6.323438)\n",
      "2018-05-08 14:42:29 iteration 150/429: current training loss = 9.608922 (=3.249044+6.359878)\n",
      "2018-05-08 14:42:34 iteration 200/429: current training loss = 10.636151 (=3.455593+7.180558)\n",
      "2018-05-08 14:42:39 iteration 250/429: current training loss = 10.794329 (=3.490423+7.303906)\n",
      "2018-05-08 14:42:44 iteration 300/429: current training loss = 10.482392 (=3.231954+7.250438)\n",
      "2018-05-08 14:42:49 iteration 350/429: current training loss = 10.679731 (=3.382802+7.296929)\n",
      "2018-05-08 14:42:55 iteration 400/429: current training loss = 10.382286 (=3.384256+6.998031)\n",
      "2018-05-08 14:42:58 iteration 429/429: current training loss = 9.842300 (=3.346213+6.496087)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:43:15 end epoch 32/100: loss_train=9.550763 loss_val=9.424585 loss_test=9.504920\n",
      "\n",
      "2018-05-08 14:43:15 start epoch 33/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:43:15 iteration 1/429: current training loss = 9.708799 (=3.295312+6.413488)\n",
      "2018-05-08 14:43:20 iteration 50/429: current training loss = 10.147388 (=3.255492+6.891896)\n",
      "2018-05-08 14:43:26 iteration 100/429: current training loss = 10.194633 (=3.225968+6.968665)\n",
      "2018-05-08 14:43:31 iteration 150/429: current training loss = 9.845595 (=3.323148+6.522447)\n",
      "2018-05-08 14:43:37 iteration 200/429: current training loss = 10.085421 (=3.299767+6.785653)\n",
      "2018-05-08 14:43:42 iteration 250/429: current training loss = 9.969308 (=3.227089+6.742219)\n",
      "2018-05-08 14:43:47 iteration 300/429: current training loss = 8.943693 (=3.150024+5.793668)\n",
      "2018-05-08 14:43:52 iteration 350/429: current training loss = 10.421841 (=3.350327+7.071514)\n",
      "2018-05-08 14:43:58 iteration 400/429: current training loss = 10.105335 (=3.323292+6.782043)\n",
      "2018-05-08 14:44:01 iteration 429/429: current training loss = 9.617813 (=3.220066+6.397747)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:44:18 end epoch 33/100: loss_train=9.934524 loss_val=9.843352 loss_test=9.877737\n",
      "\n",
      "2018-05-08 14:44:18 start epoch 34/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:44:18 iteration 1/429: current training loss = 9.763619 (=3.275172+6.488448)\n",
      "2018-05-08 14:44:24 iteration 50/429: current training loss = 9.500277 (=3.202378+6.297899)\n",
      "2018-05-08 14:44:29 iteration 100/429: current training loss = 10.498067 (=3.438289+7.059778)\n",
      "2018-05-08 14:44:34 iteration 150/429: current training loss = 9.641051 (=3.195170+6.445881)\n",
      "2018-05-08 14:44:40 iteration 200/429: current training loss = 10.339602 (=3.421854+6.917748)\n",
      "2018-05-08 14:44:45 iteration 250/429: current training loss = 9.461987 (=3.216169+6.245818)\n",
      "2018-05-08 14:44:51 iteration 300/429: current training loss = 9.227195 (=3.215266+6.011929)\n",
      "2018-05-08 14:44:56 iteration 350/429: current training loss = 9.551832 (=3.134145+6.417687)\n",
      "2018-05-08 14:45:01 iteration 400/429: current training loss = 9.068075 (=3.140605+5.927470)\n",
      "2018-05-08 14:45:04 iteration 429/429: current training loss = 9.282412 (=3.063064+6.219347)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:45:22 end epoch 34/100: loss_train=9.572315 loss_val=9.477338 loss_test=9.541704\n",
      "\n",
      "2018-05-08 14:45:22 start epoch 35/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:45:22 iteration 1/429: current training loss = 9.493305 (=3.260355+6.232949)\n",
      "2018-05-08 14:45:27 iteration 50/429: current training loss = 10.395482 (=3.266305+7.129177)\n",
      "2018-05-08 14:45:32 iteration 100/429: current training loss = 9.969204 (=3.184094+6.785109)\n",
      "2018-05-08 14:45:38 iteration 150/429: current training loss = 9.496275 (=3.266888+6.229387)\n",
      "2018-05-08 14:45:43 iteration 200/429: current training loss = 10.147430 (=3.440021+6.707410)\n",
      "2018-05-08 14:45:48 iteration 250/429: current training loss = 9.735030 (=3.125030+6.610000)\n",
      "2018-05-08 14:45:53 iteration 300/429: current training loss = 9.649397 (=3.275657+6.373740)\n",
      "2018-05-08 14:45:59 iteration 350/429: current training loss = 9.259981 (=3.134970+6.125011)\n",
      "2018-05-08 14:46:04 iteration 400/429: current training loss = 9.875461 (=3.286053+6.589407)\n",
      "2018-05-08 14:46:07 iteration 429/429: current training loss = 10.269028 (=3.381018+6.888010)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:46:24 end epoch 35/100: loss_train=10.139105 loss_val=10.044992 loss_test=10.110995\n",
      "\n",
      "2018-05-08 14:46:24 start epoch 36/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:46:24 iteration 1/429: current training loss = 10.280782 (=3.318963+6.961819)\n",
      "2018-05-08 14:46:29 iteration 50/429: current training loss = 9.892616 (=3.220608+6.672009)\n",
      "2018-05-08 14:46:34 iteration 100/429: current training loss = 10.065762 (=3.281114+6.784648)\n",
      "2018-05-08 14:46:39 iteration 150/429: current training loss = 10.999658 (=3.312869+7.686789)\n",
      "2018-05-08 14:46:44 iteration 200/429: current training loss = 9.921509 (=3.007212+6.914297)\n",
      "2018-05-08 14:46:49 iteration 250/429: current training loss = 10.484815 (=3.197450+7.287365)\n",
      "2018-05-08 14:46:55 iteration 300/429: current training loss = 10.264618 (=3.248063+7.016555)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-08 14:47:00 iteration 350/429: current training loss = 10.123198 (=3.169740+6.953457)\n",
      "2018-05-08 14:47:05 iteration 400/429: current training loss = 9.813866 (=3.160824+6.653042)\n",
      "2018-05-08 14:47:08 iteration 429/429: current training loss = 10.183477 (=3.335296+6.848181)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:47:24 end epoch 36/100: loss_train=9.952242 loss_val=9.919503 loss_test=9.862512\n",
      "\n",
      "2018-05-08 14:47:24 start epoch 37/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:47:24 iteration 1/429: current training loss = 10.140847 (=3.265924+6.874924)\n",
      "2018-05-08 14:47:30 iteration 50/429: current training loss = 9.468438 (=3.239798+6.228640)\n",
      "2018-05-08 14:47:35 iteration 100/429: current training loss = 9.978903 (=3.347355+6.631548)\n",
      "2018-05-08 14:47:41 iteration 150/429: current training loss = 9.805079 (=3.205887+6.599191)\n",
      "2018-05-08 14:47:47 iteration 200/429: current training loss = 9.480090 (=3.240392+6.239698)\n",
      "2018-05-08 14:47:52 iteration 250/429: current training loss = 9.521410 (=3.165458+6.355952)\n",
      "2018-05-08 14:47:58 iteration 300/429: current training loss = 9.926945 (=3.227128+6.699817)\n",
      "2018-05-08 14:48:04 iteration 350/429: current training loss = 9.482884 (=3.219657+6.263227)\n",
      "2018-05-08 14:48:09 iteration 400/429: current training loss = 9.532003 (=3.140768+6.391235)\n",
      "2018-05-08 14:48:12 iteration 429/429: current training loss = 10.283257 (=3.305218+6.978038)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:48:29 end epoch 37/100: loss_train=9.613844 loss_val=9.510435 loss_test=9.618545\n",
      "\n",
      "2018-05-08 14:48:29 start epoch 38/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:48:29 iteration 1/429: current training loss = 9.324915 (=3.065534+6.259381)\n",
      "2018-05-08 14:48:34 iteration 50/429: current training loss = 9.842800 (=3.220582+6.622218)\n",
      "2018-05-08 14:48:40 iteration 100/429: current training loss = 9.489771 (=3.275154+6.214617)\n",
      "2018-05-08 14:48:45 iteration 150/429: current training loss = 9.644375 (=3.162003+6.482372)\n",
      "2018-05-08 14:48:50 iteration 200/429: current training loss = 11.149932 (=3.435565+7.714367)\n",
      "2018-05-08 14:48:56 iteration 250/429: current training loss = 9.801687 (=3.274374+6.527313)\n",
      "2018-05-08 14:49:01 iteration 300/429: current training loss = 10.033705 (=3.230062+6.803643)\n",
      "2018-05-08 14:49:07 iteration 350/429: current training loss = 8.952025 (=2.999483+5.952542)\n",
      "2018-05-08 14:49:13 iteration 400/429: current training loss = 10.037025 (=3.375169+6.661856)\n",
      "2018-05-08 14:49:16 iteration 429/429: current training loss = 9.876035 (=3.290444+6.585590)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:49:33 end epoch 38/100: loss_train=9.467445 loss_val=9.386224 loss_test=9.466089\n",
      "\n",
      "2018-05-08 14:49:33 start epoch 39/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:49:33 iteration 1/429: current training loss = 9.906173 (=3.325480+6.580693)\n",
      "2018-05-08 14:49:39 iteration 50/429: current training loss = 9.897059 (=3.329588+6.567472)\n",
      "2018-05-08 14:49:44 iteration 100/429: current training loss = 8.942161 (=3.101358+5.840803)\n",
      "2018-05-08 14:49:50 iteration 150/429: current training loss = 9.430143 (=3.206866+6.223278)\n",
      "2018-05-08 14:49:55 iteration 200/429: current training loss = 9.260250 (=3.059635+6.200616)\n",
      "2018-05-08 14:50:00 iteration 250/429: current training loss = 9.427649 (=3.149919+6.277730)\n",
      "2018-05-08 14:50:05 iteration 300/429: current training loss = 9.116582 (=3.184271+5.932311)\n",
      "2018-05-08 14:50:11 iteration 350/429: current training loss = 9.676113 (=3.211768+6.464345)\n",
      "2018-05-08 14:50:16 iteration 400/429: current training loss = 9.058634 (=3.132654+5.925981)\n",
      "2018-05-08 14:50:19 iteration 429/429: current training loss = 9.704548 (=3.212843+6.491705)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:50:34 end epoch 39/100: loss_train=10.141690 loss_val=10.085473 loss_test=10.115222\n",
      "\n",
      "2018-05-08 14:50:34 start epoch 40/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:50:34 iteration 1/429: current training loss = 9.809700 (=3.170389+6.639311)\n",
      "2018-05-08 14:50:40 iteration 50/429: current training loss = 9.964439 (=3.155552+6.808887)\n",
      "2018-05-08 14:50:46 iteration 100/429: current training loss = 10.157109 (=3.352709+6.804400)\n",
      "2018-05-08 14:50:51 iteration 150/429: current training loss = 9.353923 (=3.313813+6.040110)\n",
      "2018-05-08 14:50:57 iteration 200/429: current training loss = 9.120138 (=3.186522+5.933616)\n",
      "2018-05-08 14:51:02 iteration 250/429: current training loss = 10.578934 (=3.336937+7.241997)\n",
      "2018-05-08 14:51:08 iteration 300/429: current training loss = 9.261412 (=3.151236+6.110175)\n",
      "2018-05-08 14:51:13 iteration 350/429: current training loss = 9.595472 (=3.184577+6.410895)\n",
      "2018-05-08 14:51:19 iteration 400/429: current training loss = 9.241993 (=3.155113+6.086880)\n",
      "2018-05-08 14:51:22 iteration 429/429: current training loss = 9.392065 (=3.146398+6.245667)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:51:40 end epoch 40/100: loss_train=9.692666 loss_val=9.686191 loss_test=9.626622\n",
      "\n",
      "2018-05-08 14:51:40 start epoch 41/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:51:40 iteration 1/429: current training loss = 9.697076 (=3.136108+6.560968)\n",
      "2018-05-08 14:51:45 iteration 50/429: current training loss = 9.748263 (=3.221075+6.527188)\n",
      "2018-05-08 14:51:51 iteration 100/429: current training loss = 8.535580 (=3.045501+5.490079)\n",
      "2018-05-08 14:51:57 iteration 150/429: current training loss = 9.416444 (=3.230366+6.186078)\n",
      "2018-05-08 14:52:02 iteration 200/429: current training loss = 9.371649 (=3.241922+6.129726)\n",
      "2018-05-08 14:52:08 iteration 250/429: current training loss = 8.986742 (=3.112811+5.873931)\n",
      "2018-05-08 14:52:13 iteration 300/429: current training loss = 8.906042 (=3.181537+5.724504)\n",
      "2018-05-08 14:52:19 iteration 350/429: current training loss = 9.235368 (=3.042499+6.192869)\n",
      "2018-05-08 14:52:24 iteration 400/429: current training loss = 8.927512 (=3.210162+5.717350)\n",
      "2018-05-08 14:52:27 iteration 429/429: current training loss = 9.592299 (=3.273091+6.319209)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:52:45 end epoch 41/100: loss_train=9.598820 loss_val=9.479936 loss_test=9.616617\n",
      "\n",
      "2018-05-08 14:52:45 start epoch 42/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:52:45 iteration 1/429: current training loss = 10.061884 (=3.273440+6.788445)\n",
      "2018-05-08 14:52:50 iteration 50/429: current training loss = 10.019341 (=3.156652+6.862689)\n",
      "2018-05-08 14:52:56 iteration 100/429: current training loss = 10.168473 (=3.294530+6.873943)\n",
      "2018-05-08 14:53:01 iteration 150/429: current training loss = 9.099598 (=3.171044+5.928553)\n",
      "2018-05-08 14:53:06 iteration 200/429: current training loss = 8.626883 (=3.109309+5.517574)\n",
      "2018-05-08 14:53:11 iteration 250/429: current training loss = 8.871830 (=3.113029+5.758801)\n",
      "2018-05-08 14:53:17 iteration 300/429: current training loss = 9.388358 (=3.195547+6.192811)\n",
      "2018-05-08 14:53:23 iteration 350/429: current training loss = 9.883789 (=3.173229+6.710560)\n",
      "2018-05-08 14:53:28 iteration 400/429: current training loss = 8.929057 (=3.007565+5.921492)\n",
      "2018-05-08 14:53:31 iteration 429/429: current training loss = 9.216556 (=3.119135+6.097421)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:53:49 end epoch 42/100: loss_train=9.198875 loss_val=9.140901 loss_test=9.160034\n",
      "\n",
      "2018-05-08 14:53:49 start epoch 43/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:53:49 iteration 1/429: current training loss = 9.705934 (=3.366237+6.339696)\n",
      "2018-05-08 14:53:55 iteration 50/429: current training loss = 9.070639 (=3.154783+5.915856)\n",
      "2018-05-08 14:54:00 iteration 100/429: current training loss = 8.753824 (=3.035923+5.717901)\n",
      "2018-05-08 14:54:06 iteration 150/429: current training loss = 9.440056 (=3.256847+6.183208)\n",
      "2018-05-08 14:54:11 iteration 200/429: current training loss = 9.291428 (=3.071133+6.220295)\n",
      "2018-05-08 14:54:16 iteration 250/429: current training loss = 9.204109 (=3.124097+6.080012)\n",
      "2018-05-08 14:54:22 iteration 300/429: current training loss = 9.365593 (=3.191569+6.174024)\n",
      "2018-05-08 14:54:27 iteration 350/429: current training loss = 10.258885 (=3.366725+6.892160)\n",
      "2018-05-08 14:54:32 iteration 400/429: current training loss = 8.684546 (=3.050637+5.633908)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-08 14:54:35 iteration 429/429: current training loss = 9.051932 (=3.113802+5.938130)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:54:52 end epoch 43/100: loss_train=9.469177 loss_val=9.486582 loss_test=9.427295\n",
      "\n",
      "2018-05-08 14:54:52 start epoch 44/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:54:52 iteration 1/429: current training loss = 9.771257 (=3.242299+6.528959)\n",
      "2018-05-08 14:54:58 iteration 50/429: current training loss = 9.006730 (=3.197778+5.808952)\n",
      "2018-05-08 14:55:03 iteration 100/429: current training loss = 8.658525 (=3.103809+5.554716)\n",
      "2018-05-08 14:55:08 iteration 150/429: current training loss = 9.129074 (=3.179327+5.949747)\n",
      "2018-05-08 14:55:13 iteration 200/429: current training loss = 9.096211 (=3.158684+5.937528)\n",
      "2018-05-08 14:55:19 iteration 250/429: current training loss = 9.333291 (=3.148308+6.184983)\n",
      "2018-05-08 14:55:24 iteration 300/429: current training loss = 9.379913 (=3.179743+6.200171)\n",
      "2018-05-08 14:55:29 iteration 350/429: current training loss = 8.950748 (=3.090379+5.860369)\n",
      "2018-05-08 14:55:35 iteration 400/429: current training loss = 9.204714 (=3.066500+6.138213)\n",
      "2018-05-08 14:55:38 iteration 429/429: current training loss = 8.819652 (=3.131758+5.687893)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:55:55 end epoch 44/100: loss_train=8.915733 loss_val=8.781833 loss_test=8.897085\n",
      "\n",
      "2018-05-08 14:55:55 start epoch 45/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:55:55 iteration 1/429: current training loss = 8.580803 (=3.184201+5.396602)\n",
      "2018-05-08 14:56:01 iteration 50/429: current training loss = 8.772190 (=3.197076+5.575115)\n",
      "2018-05-08 14:56:06 iteration 100/429: current training loss = 9.251318 (=3.212213+6.039105)\n",
      "2018-05-08 14:56:12 iteration 150/429: current training loss = 9.112095 (=3.185718+5.926377)\n",
      "2018-05-08 14:56:17 iteration 200/429: current training loss = 8.947569 (=3.104885+5.842684)\n",
      "2018-05-08 14:56:23 iteration 250/429: current training loss = 9.680768 (=3.396976+6.283792)\n",
      "2018-05-08 14:56:28 iteration 300/429: current training loss = 8.861249 (=3.155716+5.705533)\n",
      "2018-05-08 14:56:34 iteration 350/429: current training loss = 9.023712 (=3.093385+5.930327)\n",
      "2018-05-08 14:56:39 iteration 400/429: current training loss = 9.658392 (=3.076091+6.582301)\n",
      "2018-05-08 14:56:42 iteration 429/429: current training loss = 9.083960 (=3.210008+5.873951)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:56:59 end epoch 45/100: loss_train=9.037616 loss_val=8.961283 loss_test=9.036642\n",
      "\n",
      "2018-05-08 14:56:59 start epoch 46/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:56:59 iteration 1/429: current training loss = 9.511988 (=3.300517+6.211471)\n",
      "2018-05-08 14:57:05 iteration 50/429: current training loss = 8.576939 (=3.106620+5.470318)\n",
      "2018-05-08 14:57:10 iteration 100/429: current training loss = 8.936696 (=3.303962+5.632734)\n",
      "2018-05-08 14:57:15 iteration 150/429: current training loss = 9.169900 (=3.164687+6.005213)\n",
      "2018-05-08 14:57:21 iteration 200/429: current training loss = 9.768078 (=3.216651+6.551427)\n",
      "2018-05-08 14:57:26 iteration 250/429: current training loss = 8.909794 (=3.161934+5.747860)\n",
      "2018-05-08 14:57:32 iteration 300/429: current training loss = 9.463078 (=3.232121+6.230956)\n",
      "2018-05-08 14:57:37 iteration 350/429: current training loss = 8.712237 (=3.145095+5.567142)\n",
      "2018-05-08 14:57:42 iteration 400/429: current training loss = 8.843043 (=3.227811+5.615232)\n",
      "2018-05-08 14:57:45 iteration 429/429: current training loss = 9.218325 (=3.134270+6.084054)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:58:02 end epoch 46/100: loss_train=9.156160 loss_val=9.098749 loss_test=9.094732\n",
      "\n",
      "2018-05-08 14:58:02 start epoch 47/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:58:03 iteration 1/429: current training loss = 10.163945 (=3.421166+6.742779)\n",
      "2018-05-08 14:58:08 iteration 50/429: current training loss = 8.082714 (=3.002751+5.079962)\n",
      "2018-05-08 14:58:13 iteration 100/429: current training loss = 9.593050 (=3.210464+6.382586)\n",
      "2018-05-08 14:58:18 iteration 150/429: current training loss = 8.686739 (=3.079093+5.607646)\n",
      "2018-05-08 14:58:24 iteration 200/429: current training loss = 8.661318 (=3.141868+5.519450)\n",
      "2018-05-08 14:58:29 iteration 250/429: current training loss = 9.155949 (=3.210114+5.945834)\n",
      "2018-05-08 14:58:35 iteration 300/429: current training loss = 9.970940 (=3.364534+6.606406)\n",
      "2018-05-08 14:58:40 iteration 350/429: current training loss = 9.123358 (=3.223787+5.899571)\n",
      "2018-05-08 14:58:46 iteration 400/429: current training loss = 8.622172 (=3.002872+5.619300)\n",
      "2018-05-08 14:58:49 iteration 429/429: current training loss = 9.199769 (=3.276912+5.922857)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 14:59:07 end epoch 47/100: loss_train=8.832064 loss_val=8.753451 loss_test=8.817890\n",
      "\n",
      "2018-05-08 14:59:07 start epoch 48/100, with learning rate = 0.0010000000\n",
      "2018-05-08 14:59:07 iteration 1/429: current training loss = 8.979857 (=3.204980+5.774878)\n",
      "2018-05-08 14:59:12 iteration 50/429: current training loss = 9.475632 (=3.229040+6.246592)\n",
      "2018-05-08 14:59:18 iteration 100/429: current training loss = 9.064770 (=3.064982+5.999788)\n",
      "2018-05-08 14:59:23 iteration 150/429: current training loss = 9.345985 (=3.304764+6.041221)\n",
      "2018-05-08 14:59:28 iteration 200/429: current training loss = 9.815817 (=3.286761+6.529056)\n",
      "2018-05-08 14:59:33 iteration 250/429: current training loss = 8.018526 (=2.978738+5.039787)\n",
      "2018-05-08 14:59:39 iteration 300/429: current training loss = 9.529806 (=3.220749+6.309057)\n",
      "2018-05-08 14:59:44 iteration 350/429: current training loss = 8.518252 (=3.173672+5.344581)\n",
      "2018-05-08 14:59:49 iteration 400/429: current training loss = 8.966182 (=3.107770+5.858412)\n",
      "2018-05-08 14:59:52 iteration 429/429: current training loss = 8.526457 (=3.053791+5.472666)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:00:10 end epoch 48/100: loss_train=8.806413 loss_val=8.752371 loss_test=8.795201\n",
      "\n",
      "2018-05-08 15:00:10 start epoch 49/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:00:10 iteration 1/429: current training loss = 8.877549 (=3.120342+5.757207)\n",
      "2018-05-08 15:00:15 iteration 50/429: current training loss = 8.814003 (=3.117564+5.696439)\n",
      "2018-05-08 15:00:21 iteration 100/429: current training loss = 9.131365 (=3.140105+5.991260)\n",
      "2018-05-08 15:00:26 iteration 150/429: current training loss = 9.396929 (=3.258042+6.138887)\n",
      "2018-05-08 15:00:32 iteration 200/429: current training loss = 9.452190 (=3.177402+6.274788)\n",
      "2018-05-08 15:00:37 iteration 250/429: current training loss = 8.956440 (=3.175604+5.780835)\n",
      "2018-05-08 15:00:42 iteration 300/429: current training loss = 8.685569 (=3.030406+5.655163)\n",
      "2018-05-08 15:00:47 iteration 350/429: current training loss = 9.686626 (=3.141199+6.545428)\n",
      "2018-05-08 15:00:53 iteration 400/429: current training loss = 9.263372 (=3.013897+6.249475)\n",
      "2018-05-08 15:00:56 iteration 429/429: current training loss = 8.760073 (=2.973382+5.786692)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:01:13 end epoch 49/100: loss_train=8.837919 loss_val=8.756004 loss_test=8.884021\n",
      "\n",
      "2018-05-08 15:01:13 start epoch 50/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:01:13 iteration 1/429: current training loss = 9.021819 (=3.155020+5.866799)\n",
      "2018-05-08 15:01:18 iteration 50/429: current training loss = 8.837889 (=3.123652+5.714237)\n",
      "2018-05-08 15:01:23 iteration 100/429: current training loss = 9.038004 (=3.104260+5.933743)\n",
      "2018-05-08 15:01:28 iteration 150/429: current training loss = 8.564147 (=2.996066+5.568081)\n",
      "2018-05-08 15:01:34 iteration 200/429: current training loss = 8.780553 (=3.127281+5.653272)\n",
      "2018-05-08 15:01:39 iteration 250/429: current training loss = 8.986788 (=3.100966+5.885822)\n",
      "2018-05-08 15:01:45 iteration 300/429: current training loss = 9.257450 (=3.243600+6.013851)\n",
      "2018-05-08 15:01:50 iteration 350/429: current training loss = 8.994704 (=3.117335+5.877370)\n",
      "2018-05-08 15:01:55 iteration 400/429: current training loss = 8.959003 (=3.125625+5.833378)\n",
      "2018-05-08 15:01:58 iteration 429/429: current training loss = 8.342978 (=3.146868+5.196109)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:02:16 end epoch 50/100: loss_train=8.599499 loss_val=8.562223 loss_test=8.586623\n",
      "\n",
      "2018-05-08 15:02:16 start epoch 51/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:02:16 iteration 1/429: current training loss = 8.605496 (=3.149135+5.456362)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-08 15:02:21 iteration 50/429: current training loss = 8.529017 (=3.150762+5.378256)\n",
      "2018-05-08 15:02:26 iteration 100/429: current training loss = 8.553801 (=3.093793+5.460008)\n",
      "2018-05-08 15:02:32 iteration 150/429: current training loss = 8.965555 (=3.106188+5.859367)\n",
      "2018-05-08 15:02:38 iteration 200/429: current training loss = 8.718300 (=3.116835+5.601465)\n",
      "2018-05-08 15:02:43 iteration 250/429: current training loss = 8.751537 (=3.232739+5.518798)\n",
      "2018-05-08 15:02:48 iteration 300/429: current training loss = 9.024573 (=3.186801+5.837772)\n",
      "2018-05-08 15:02:54 iteration 350/429: current training loss = 8.339815 (=3.062914+5.276901)\n",
      "2018-05-08 15:02:59 iteration 400/429: current training loss = 8.697676 (=3.010111+5.687564)\n",
      "2018-05-08 15:03:02 iteration 429/429: current training loss = 8.081510 (=2.992308+5.089201)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:03:19 end epoch 51/100: loss_train=8.744319 loss_val=8.675398 loss_test=8.745482\n",
      "\n",
      "2018-05-08 15:03:19 start epoch 52/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:03:19 iteration 1/429: current training loss = 8.147544 (=2.901517+5.246027)\n",
      "2018-05-08 15:03:25 iteration 50/429: current training loss = 8.233130 (=2.990394+5.242736)\n",
      "2018-05-08 15:03:30 iteration 100/429: current training loss = 8.528356 (=3.058012+5.470344)\n",
      "2018-05-08 15:03:36 iteration 150/429: current training loss = 8.592554 (=3.114215+5.478339)\n",
      "2018-05-08 15:03:41 iteration 200/429: current training loss = 8.485309 (=3.080247+5.405061)\n",
      "2018-05-08 15:03:47 iteration 250/429: current training loss = 8.561578 (=2.975727+5.585851)\n",
      "2018-05-08 15:03:52 iteration 300/429: current training loss = 8.922701 (=3.237194+5.685507)\n",
      "2018-05-08 15:03:58 iteration 350/429: current training loss = 8.840025 (=3.106012+5.734013)\n",
      "2018-05-08 15:04:03 iteration 400/429: current training loss = 8.669889 (=3.153175+5.516714)\n",
      "2018-05-08 15:04:06 iteration 429/429: current training loss = 8.834750 (=3.115679+5.719071)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:04:24 end epoch 52/100: loss_train=8.648851 loss_val=8.575683 loss_test=8.660447\n",
      "\n",
      "2018-05-08 15:04:24 start epoch 53/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:04:24 iteration 1/429: current training loss = 8.966041 (=3.157710+5.808331)\n",
      "2018-05-08 15:04:29 iteration 50/429: current training loss = 9.117437 (=3.166440+5.950997)\n",
      "2018-05-08 15:04:34 iteration 100/429: current training loss = 8.539929 (=2.982775+5.557154)\n",
      "2018-05-08 15:04:39 iteration 150/429: current training loss = 8.773833 (=3.237994+5.535839)\n",
      "2018-05-08 15:04:45 iteration 200/429: current training loss = 8.950530 (=3.185558+5.764972)\n",
      "2018-05-08 15:04:50 iteration 250/429: current training loss = 8.221887 (=3.111717+5.110169)\n",
      "2018-05-08 15:04:55 iteration 300/429: current training loss = 9.829267 (=3.250848+6.578418)\n",
      "2018-05-08 15:05:00 iteration 350/429: current training loss = 8.750656 (=3.185059+5.565598)\n",
      "2018-05-08 15:05:06 iteration 400/429: current training loss = 8.713747 (=3.169677+5.544070)\n",
      "2018-05-08 15:05:09 iteration 429/429: current training loss = 8.429623 (=2.975808+5.453814)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:05:26 end epoch 53/100: loss_train=8.484504 loss_val=8.427761 loss_test=8.490797\n",
      "\n",
      "2018-05-08 15:05:26 start epoch 54/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:05:26 iteration 1/429: current training loss = 8.951454 (=3.156070+5.795384)\n",
      "2018-05-08 15:05:31 iteration 50/429: current training loss = 8.738063 (=3.047354+5.690709)\n",
      "2018-05-08 15:05:37 iteration 100/429: current training loss = 8.699334 (=3.134223+5.565111)\n",
      "2018-05-08 15:05:42 iteration 150/429: current training loss = 8.645811 (=3.005841+5.639971)\n",
      "2018-05-08 15:05:47 iteration 200/429: current training loss = 8.306150 (=2.949662+5.356489)\n",
      "2018-05-08 15:05:52 iteration 250/429: current training loss = 8.763617 (=3.160225+5.603392)\n",
      "2018-05-08 15:05:58 iteration 300/429: current training loss = 8.723145 (=3.115894+5.607250)\n",
      "2018-05-08 15:06:03 iteration 350/429: current training loss = 8.742075 (=3.087676+5.654398)\n",
      "2018-05-08 15:06:09 iteration 400/429: current training loss = 8.966825 (=2.993120+5.973704)\n",
      "2018-05-08 15:06:12 iteration 429/429: current training loss = 9.396715 (=3.161716+6.234999)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:06:30 end epoch 54/100: loss_train=8.648392 loss_val=8.609304 loss_test=8.611447\n",
      "\n",
      "2018-05-08 15:06:30 start epoch 55/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:06:30 iteration 1/429: current training loss = 8.864378 (=3.132296+5.732081)\n",
      "2018-05-08 15:06:35 iteration 50/429: current training loss = 8.949598 (=3.192260+5.757339)\n",
      "2018-05-08 15:06:41 iteration 100/429: current training loss = 8.416327 (=3.108569+5.307757)\n",
      "2018-05-08 15:06:46 iteration 150/429: current training loss = 8.619905 (=3.132242+5.487662)\n",
      "2018-05-08 15:06:51 iteration 200/429: current training loss = 8.209379 (=3.017895+5.191483)\n",
      "2018-05-08 15:06:57 iteration 250/429: current training loss = 8.565746 (=2.963931+5.601815)\n",
      "2018-05-08 15:07:02 iteration 300/429: current training loss = 8.738963 (=3.123189+5.615774)\n",
      "2018-05-08 15:07:07 iteration 350/429: current training loss = 7.993364 (=3.023664+4.969700)\n",
      "2018-05-08 15:07:13 iteration 400/429: current training loss = 9.474607 (=3.077693+6.396914)\n",
      "2018-05-08 15:07:16 iteration 429/429: current training loss = 8.643102 (=3.064012+5.579090)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:07:34 end epoch 55/100: loss_train=9.019931 loss_val=8.987040 loss_test=9.017786\n",
      "\n",
      "2018-05-08 15:07:34 start epoch 56/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:07:34 iteration 1/429: current training loss = 9.431655 (=3.255790+6.175865)\n",
      "2018-05-08 15:07:39 iteration 50/429: current training loss = 8.607621 (=3.063942+5.543679)\n",
      "2018-05-08 15:07:45 iteration 100/429: current training loss = 8.536325 (=2.959419+5.576906)\n",
      "2018-05-08 15:07:50 iteration 150/429: current training loss = 8.461423 (=3.039205+5.422218)\n",
      "2018-05-08 15:07:55 iteration 200/429: current training loss = 8.421434 (=3.100809+5.320625)\n",
      "2018-05-08 15:08:00 iteration 250/429: current training loss = 8.869340 (=3.103129+5.766211)\n",
      "2018-05-08 15:08:05 iteration 300/429: current training loss = 8.403248 (=3.056197+5.347051)\n",
      "2018-05-08 15:08:11 iteration 350/429: current training loss = 8.365926 (=3.021356+5.344570)\n",
      "2018-05-08 15:08:16 iteration 400/429: current training loss = 9.132647 (=3.210091+5.922555)\n",
      "2018-05-08 15:08:19 iteration 429/429: current training loss = 8.430506 (=3.164840+5.265665)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:08:36 end epoch 56/100: loss_train=8.327489 loss_val=8.268064 loss_test=8.334158\n",
      "\n",
      "2018-05-08 15:08:36 start epoch 57/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:08:36 iteration 1/429: current training loss = 8.107966 (=3.116146+4.991820)\n",
      "2018-05-08 15:08:41 iteration 50/429: current training loss = 8.748234 (=3.051148+5.697085)\n",
      "2018-05-08 15:08:46 iteration 100/429: current training loss = 8.901212 (=3.124413+5.776799)\n",
      "2018-05-08 15:08:51 iteration 150/429: current training loss = 8.649683 (=3.061638+5.588046)\n",
      "2018-05-08 15:08:57 iteration 200/429: current training loss = 8.477633 (=3.168431+5.309201)\n",
      "2018-05-08 15:09:02 iteration 250/429: current training loss = 8.393866 (=3.032157+5.361709)\n",
      "2018-05-08 15:09:07 iteration 300/429: current training loss = 8.198370 (=3.016655+5.181715)\n",
      "2018-05-08 15:09:12 iteration 350/429: current training loss = 8.362040 (=2.933177+5.428863)\n",
      "2018-05-08 15:09:18 iteration 400/429: current training loss = 8.397325 (=3.008973+5.388351)\n",
      "2018-05-08 15:09:21 iteration 429/429: current training loss = 8.911764 (=3.187388+5.724377)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:09:38 end epoch 57/100: loss_train=8.503872 loss_val=8.434880 loss_test=8.509461\n",
      "\n",
      "2018-05-08 15:09:38 start epoch 58/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:09:38 iteration 1/429: current training loss = 8.656884 (=3.096777+5.560107)\n",
      "2018-05-08 15:09:43 iteration 50/429: current training loss = 7.784543 (=2.888677+4.895865)\n",
      "2018-05-08 15:09:49 iteration 100/429: current training loss = 8.072096 (=3.006644+5.065452)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-08 15:09:54 iteration 150/429: current training loss = 8.157680 (=3.038695+5.118985)\n",
      "2018-05-08 15:09:59 iteration 200/429: current training loss = 8.796145 (=3.173305+5.622840)\n",
      "2018-05-08 15:10:04 iteration 250/429: current training loss = 8.982359 (=3.198467+5.783892)\n",
      "2018-05-08 15:10:09 iteration 300/429: current training loss = 8.808572 (=3.212960+5.595612)\n",
      "2018-05-08 15:10:15 iteration 350/429: current training loss = 8.734130 (=3.108522+5.625607)\n",
      "2018-05-08 15:10:20 iteration 400/429: current training loss = 8.249292 (=3.001539+5.247753)\n",
      "2018-05-08 15:10:23 iteration 429/429: current training loss = 8.435994 (=3.070491+5.365504)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:10:41 end epoch 58/100: loss_train=8.637941 loss_val=8.620734 loss_test=8.598115\n",
      "\n",
      "2018-05-08 15:10:41 start epoch 59/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:10:41 iteration 1/429: current training loss = 8.875338 (=3.187765+5.687572)\n",
      "2018-05-08 15:10:46 iteration 50/429: current training loss = 8.501001 (=3.135284+5.365718)\n",
      "2018-05-08 15:10:52 iteration 100/429: current training loss = 8.068041 (=3.034893+5.033148)\n",
      "2018-05-08 15:10:57 iteration 150/429: current training loss = 8.636101 (=3.036224+5.599877)\n",
      "2018-05-08 15:11:02 iteration 200/429: current training loss = 8.606173 (=2.951146+5.655027)\n",
      "2018-05-08 15:11:08 iteration 250/429: current training loss = 8.639773 (=3.118525+5.521248)\n",
      "2018-05-08 15:11:13 iteration 300/429: current training loss = 8.834034 (=2.985301+5.848734)\n",
      "2018-05-08 15:11:19 iteration 350/429: current training loss = 8.676620 (=3.054243+5.622378)\n",
      "2018-05-08 15:11:24 iteration 400/429: current training loss = 8.779772 (=3.044921+5.734851)\n",
      "2018-05-08 15:11:27 iteration 429/429: current training loss = 8.506680 (=3.045517+5.461163)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:11:44 end epoch 59/100: loss_train=8.456982 loss_val=8.404446 loss_test=8.492494\n",
      "\n",
      "2018-05-08 15:11:44 start epoch 60/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:11:44 iteration 1/429: current training loss = 8.604913 (=3.144568+5.460344)\n",
      "2018-05-08 15:11:50 iteration 50/429: current training loss = 8.814648 (=3.035044+5.779604)\n",
      "2018-05-08 15:11:56 iteration 100/429: current training loss = 8.317222 (=2.933755+5.383467)\n",
      "2018-05-08 15:12:01 iteration 150/429: current training loss = 8.693121 (=3.132091+5.561029)\n",
      "2018-05-08 15:12:06 iteration 200/429: current training loss = 7.986714 (=2.913411+5.073303)\n",
      "2018-05-08 15:12:11 iteration 250/429: current training loss = 7.698237 (=2.869488+4.828749)\n",
      "2018-05-08 15:12:16 iteration 300/429: current training loss = 8.643411 (=3.164903+5.478508)\n",
      "2018-05-08 15:12:21 iteration 350/429: current training loss = 8.721855 (=3.063464+5.658391)\n",
      "2018-05-08 15:12:27 iteration 400/429: current training loss = 8.101057 (=2.990641+5.110415)\n",
      "2018-05-08 15:12:30 iteration 429/429: current training loss = 8.147877 (=3.001850+5.146027)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:12:47 end epoch 60/100: loss_train=8.379268 loss_val=8.306096 loss_test=8.359106\n",
      "\n",
      "2018-05-08 15:12:47 start epoch 61/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:12:47 iteration 1/429: current training loss = 8.362998 (=3.005951+5.357048)\n",
      "2018-05-08 15:12:53 iteration 50/429: current training loss = 8.591653 (=3.123921+5.467732)\n",
      "2018-05-08 15:12:58 iteration 100/429: current training loss = 8.545609 (=3.121051+5.424558)\n",
      "2018-05-08 15:13:03 iteration 150/429: current training loss = 8.754128 (=3.155960+5.598168)\n",
      "2018-05-08 15:13:09 iteration 200/429: current training loss = 8.756632 (=3.099502+5.657130)\n",
      "2018-05-08 15:13:14 iteration 250/429: current training loss = 8.579210 (=3.137206+5.442004)\n",
      "2018-05-08 15:13:19 iteration 300/429: current training loss = 8.421501 (=3.078451+5.343050)\n",
      "2018-05-08 15:13:24 iteration 350/429: current training loss = 8.635992 (=3.101212+5.534780)\n",
      "2018-05-08 15:13:29 iteration 400/429: current training loss = 8.377583 (=3.095474+5.282108)\n",
      "2018-05-08 15:13:32 iteration 429/429: current training loss = 8.707878 (=3.140188+5.567691)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:13:50 end epoch 61/100: loss_train=8.482275 loss_val=8.403667 loss_test=8.494919\n",
      "\n",
      "2018-05-08 15:13:50 start epoch 62/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:13:50 iteration 1/429: current training loss = 8.465992 (=2.956088+5.509904)\n",
      "2018-05-08 15:13:55 iteration 50/429: current training loss = 8.681286 (=3.099877+5.581409)\n",
      "2018-05-08 15:14:00 iteration 100/429: current training loss = 8.575296 (=3.065904+5.509393)\n",
      "2018-05-08 15:14:06 iteration 150/429: current training loss = 8.640187 (=2.984765+5.655422)\n",
      "2018-05-08 15:14:11 iteration 200/429: current training loss = 8.396072 (=3.150312+5.245760)\n",
      "2018-05-08 15:14:16 iteration 250/429: current training loss = 9.044052 (=3.202879+5.841173)\n",
      "2018-05-08 15:14:21 iteration 300/429: current training loss = 8.888669 (=3.196007+5.692662)\n",
      "2018-05-08 15:14:27 iteration 350/429: current training loss = 8.308309 (=3.109093+5.199215)\n",
      "2018-05-08 15:14:32 iteration 400/429: current training loss = 8.368708 (=3.065122+5.303586)\n",
      "2018-05-08 15:14:35 iteration 429/429: current training loss = 8.621717 (=2.925912+5.695806)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:14:53 end epoch 62/100: loss_train=8.667395 loss_val=8.651427 loss_test=8.672350\n",
      "\n",
      "2018-05-08 15:14:53 start epoch 63/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:14:53 iteration 1/429: current training loss = 8.433831 (=3.007066+5.426765)\n",
      "2018-05-08 15:14:59 iteration 50/429: current training loss = 8.330132 (=3.031404+5.298729)\n",
      "2018-05-08 15:15:05 iteration 100/429: current training loss = 8.564415 (=3.087710+5.476705)\n",
      "2018-05-08 15:15:10 iteration 150/429: current training loss = 8.443789 (=2.918495+5.525293)\n",
      "2018-05-08 15:15:15 iteration 200/429: current training loss = 8.304617 (=3.037605+5.267012)\n",
      "2018-05-08 15:15:21 iteration 250/429: current training loss = 8.514794 (=3.126561+5.388233)\n",
      "2018-05-08 15:15:26 iteration 300/429: current training loss = 8.475782 (=3.051551+5.424231)\n",
      "2018-05-08 15:15:32 iteration 350/429: current training loss = 8.536043 (=2.996833+5.539210)\n",
      "2018-05-08 15:15:37 iteration 400/429: current training loss = 8.154299 (=3.025715+5.128584)\n",
      "2018-05-08 15:15:40 iteration 429/429: current training loss = 8.709384 (=3.140620+5.568764)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:15:57 end epoch 63/100: loss_train=8.448699 loss_val=8.406095 loss_test=8.429119\n",
      "\n",
      "2018-05-08 15:15:57 start epoch 64/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:15:57 iteration 1/429: current training loss = 8.445751 (=3.085046+5.360705)\n",
      "2018-05-08 15:16:02 iteration 50/429: current training loss = 8.602146 (=3.139361+5.462786)\n",
      "2018-05-08 15:16:08 iteration 100/429: current training loss = 8.232874 (=2.996044+5.236829)\n",
      "2018-05-08 15:16:13 iteration 150/429: current training loss = 8.339487 (=3.128797+5.210690)\n",
      "2018-05-08 15:16:18 iteration 200/429: current training loss = 8.281125 (=3.041879+5.239246)\n",
      "2018-05-08 15:16:24 iteration 250/429: current training loss = 8.588891 (=3.140962+5.447929)\n",
      "2018-05-08 15:16:29 iteration 300/429: current training loss = 8.100968 (=3.035660+5.065309)\n",
      "2018-05-08 15:16:34 iteration 350/429: current training loss = 8.435400 (=3.114457+5.320943)\n",
      "2018-05-08 15:16:39 iteration 400/429: current training loss = 8.679525 (=3.077598+5.601928)\n",
      "2018-05-08 15:16:43 iteration 429/429: current training loss = 8.415433 (=3.013409+5.402024)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:17:00 end epoch 64/100: loss_train=8.359575 loss_val=8.281604 loss_test=8.367688\n",
      "\n",
      "2018-05-08 15:17:00 start epoch 65/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:17:00 iteration 1/429: current training loss = 8.277835 (=3.101413+5.176422)\n",
      "2018-05-08 15:17:05 iteration 50/429: current training loss = 8.301888 (=3.158001+5.143887)\n",
      "2018-05-08 15:17:10 iteration 100/429: current training loss = 9.125754 (=3.068999+6.056756)\n",
      "2018-05-08 15:17:16 iteration 150/429: current training loss = 8.929109 (=3.241108+5.688001)\n",
      "2018-05-08 15:17:21 iteration 200/429: current training loss = 8.615983 (=3.166455+5.449529)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-08 15:17:26 iteration 250/429: current training loss = 7.992796 (=3.126994+4.865802)\n",
      "2018-05-08 15:17:32 iteration 300/429: current training loss = 8.365552 (=3.155744+5.209808)\n",
      "2018-05-08 15:17:37 iteration 350/429: current training loss = 8.241072 (=3.108751+5.132321)\n",
      "2018-05-08 15:17:42 iteration 400/429: current training loss = 8.239537 (=3.094984+5.144554)\n",
      "2018-05-08 15:17:45 iteration 429/429: current training loss = 8.332508 (=3.173829+5.158679)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:18:04 end epoch 65/100: loss_train=8.342665 loss_val=8.329698 loss_test=8.321734\n",
      "\n",
      "2018-05-08 15:18:04 start epoch 66/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:18:04 iteration 1/429: current training loss = 8.594543 (=3.145074+5.449470)\n",
      "2018-05-08 15:18:09 iteration 50/429: current training loss = 8.580971 (=3.085137+5.495834)\n",
      "2018-05-08 15:18:15 iteration 100/429: current training loss = 8.477640 (=3.083821+5.393819)\n",
      "2018-05-08 15:18:20 iteration 150/429: current training loss = 8.337262 (=2.984341+5.352921)\n",
      "2018-05-08 15:18:25 iteration 200/429: current training loss = 8.470917 (=3.036574+5.434342)\n",
      "2018-05-08 15:18:31 iteration 250/429: current training loss = 8.964464 (=3.224729+5.739735)\n",
      "2018-05-08 15:18:36 iteration 300/429: current training loss = 8.145132 (=3.022514+5.122618)\n",
      "2018-05-08 15:18:41 iteration 350/429: current training loss = 8.621907 (=3.056807+5.565100)\n",
      "2018-05-08 15:18:46 iteration 400/429: current training loss = 7.947351 (=2.928890+5.018461)\n",
      "2018-05-08 15:18:49 iteration 429/429: current training loss = 8.593941 (=3.120021+5.473920)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:19:07 end epoch 66/100: loss_train=8.435387 loss_val=8.369485 loss_test=8.416886\n",
      "\n",
      "2018-05-08 15:19:07 start epoch 67/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:19:07 iteration 1/429: current training loss = 8.674735 (=3.157387+5.517348)\n",
      "2018-05-08 15:19:12 iteration 50/429: current training loss = 8.421331 (=3.090085+5.331247)\n",
      "2018-05-08 15:19:17 iteration 100/429: current training loss = 8.415568 (=3.032985+5.382584)\n",
      "2018-05-08 15:19:22 iteration 150/429: current training loss = 7.827130 (=3.021027+4.806103)\n",
      "2018-05-08 15:19:27 iteration 200/429: current training loss = 7.982318 (=2.949697+5.032621)\n",
      "2018-05-08 15:19:33 iteration 250/429: current training loss = 8.020088 (=2.982968+5.037119)\n",
      "2018-05-08 15:19:38 iteration 300/429: current training loss = 8.179392 (=3.074595+5.104796)\n",
      "2018-05-08 15:19:44 iteration 350/429: current training loss = 8.164925 (=2.948757+5.216167)\n",
      "2018-05-08 15:19:49 iteration 400/429: current training loss = 8.608552 (=3.110381+5.498171)\n",
      "2018-05-08 15:19:52 iteration 429/429: current training loss = 8.779362 (=3.253802+5.525560)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:20:09 end epoch 67/100: loss_train=8.259976 loss_val=8.219677 loss_test=8.250048\n",
      "\n",
      "2018-05-08 15:20:09 start epoch 68/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:20:10 iteration 1/429: current training loss = 8.668543 (=3.144303+5.524240)\n",
      "2018-05-08 15:20:15 iteration 50/429: current training loss = 8.338913 (=3.108580+5.230333)\n",
      "2018-05-08 15:20:20 iteration 100/429: current training loss = 8.695644 (=3.163224+5.532420)\n",
      "2018-05-08 15:20:25 iteration 150/429: current training loss = 8.049357 (=3.031798+5.017559)\n",
      "2018-05-08 15:20:30 iteration 200/429: current training loss = 8.410051 (=3.164566+5.245486)\n",
      "2018-05-08 15:20:35 iteration 250/429: current training loss = 8.365948 (=2.971195+5.394753)\n",
      "2018-05-08 15:20:41 iteration 300/429: current training loss = 7.888777 (=3.021643+4.867133)\n",
      "2018-05-08 15:20:45 iteration 350/429: current training loss = 8.084498 (=3.071259+5.013239)\n",
      "2018-05-08 15:20:51 iteration 400/429: current training loss = 8.480244 (=3.138615+5.341629)\n",
      "2018-05-08 15:20:54 iteration 429/429: current training loss = 8.612225 (=3.174425+5.437799)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:21:12 end epoch 68/100: loss_train=8.250062 loss_val=8.205053 loss_test=8.226892\n",
      "\n",
      "2018-05-08 15:21:12 start epoch 69/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:21:12 iteration 1/429: current training loss = 8.042097 (=3.009783+5.032314)\n",
      "2018-05-08 15:21:17 iteration 50/429: current training loss = 8.645303 (=3.174110+5.471193)\n",
      "2018-05-08 15:21:22 iteration 100/429: current training loss = 8.172688 (=2.997712+5.174976)\n",
      "2018-05-08 15:21:27 iteration 150/429: current training loss = 8.013875 (=2.950160+5.063715)\n",
      "2018-05-08 15:21:33 iteration 200/429: current training loss = 8.099709 (=3.020143+5.079566)\n",
      "2018-05-08 15:21:38 iteration 250/429: current training loss = 8.452629 (=3.125541+5.327088)\n",
      "2018-05-08 15:21:43 iteration 300/429: current training loss = 8.228095 (=2.987945+5.240150)\n",
      "2018-05-08 15:21:49 iteration 350/429: current training loss = 8.576339 (=3.156769+5.419570)\n",
      "2018-05-08 15:21:54 iteration 400/429: current training loss = 8.074249 (=3.032204+5.042046)\n",
      "2018-05-08 15:21:57 iteration 429/429: current training loss = 8.121841 (=3.005817+5.116025)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:22:15 end epoch 69/100: loss_train=8.357352 loss_val=8.308061 loss_test=8.358265\n",
      "\n",
      "2018-05-08 15:22:15 start epoch 70/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:22:15 iteration 1/429: current training loss = 8.262135 (=3.026849+5.235286)\n",
      "2018-05-08 15:22:20 iteration 50/429: current training loss = 8.685901 (=3.130038+5.555862)\n",
      "2018-05-08 15:22:25 iteration 100/429: current training loss = 8.322968 (=3.071929+5.251039)\n",
      "2018-05-08 15:22:30 iteration 150/429: current training loss = 8.083031 (=3.060982+5.022049)\n",
      "2018-05-08 15:22:36 iteration 200/429: current training loss = 8.180140 (=3.034077+5.146062)\n",
      "2018-05-08 15:22:41 iteration 250/429: current training loss = 8.589760 (=3.011364+5.578396)\n",
      "2018-05-08 15:22:46 iteration 300/429: current training loss = 7.941268 (=2.990597+4.950670)\n",
      "2018-05-08 15:22:51 iteration 350/429: current training loss = 8.458513 (=3.156931+5.301582)\n",
      "2018-05-08 15:22:56 iteration 400/429: current training loss = 8.445474 (=3.146533+5.298940)\n",
      "2018-05-08 15:23:00 iteration 429/429: current training loss = 8.448158 (=3.181466+5.266692)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:23:17 end epoch 70/100: loss_train=8.320849 loss_val=8.245524 loss_test=8.334787\n",
      "\n",
      "2018-05-08 15:23:17 start epoch 71/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:23:17 iteration 1/429: current training loss = 8.305862 (=3.054706+5.251156)\n",
      "2018-05-08 15:23:22 iteration 50/429: current training loss = 7.765715 (=2.966559+4.799156)\n",
      "2018-05-08 15:23:27 iteration 100/429: current training loss = 8.691546 (=3.069524+5.622023)\n",
      "2018-05-08 15:23:32 iteration 150/429: current training loss = 8.381654 (=2.978685+5.402969)\n",
      "2018-05-08 15:23:38 iteration 200/429: current training loss = 7.818647 (=2.949846+4.868802)\n",
      "2018-05-08 15:23:43 iteration 250/429: current training loss = 8.002308 (=3.076257+4.926051)\n",
      "2018-05-08 15:23:48 iteration 300/429: current training loss = 8.510600 (=3.141549+5.369051)\n",
      "2018-05-08 15:23:54 iteration 350/429: current training loss = 7.703080 (=2.918045+4.785036)\n",
      "2018-05-08 15:23:59 iteration 400/429: current training loss = 8.687935 (=3.088862+5.599072)\n",
      "2018-05-08 15:24:02 iteration 429/429: current training loss = 8.143988 (=3.099685+5.044302)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:24:19 end epoch 71/100: loss_train=8.133456 loss_val=8.060749 loss_test=8.145788\n",
      "\n",
      "2018-05-08 15:24:19 start epoch 72/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:24:19 iteration 1/429: current training loss = 8.583498 (=3.112101+5.471397)\n",
      "2018-05-08 15:24:24 iteration 50/429: current training loss = 8.276289 (=3.165965+5.110324)\n",
      "2018-05-08 15:24:30 iteration 100/429: current training loss = 8.031053 (=2.920955+5.110097)\n",
      "2018-05-08 15:24:35 iteration 150/429: current training loss = 7.628098 (=2.991323+4.636775)\n",
      "2018-05-08 15:24:41 iteration 200/429: current training loss = 7.991626 (=2.941774+5.049852)\n",
      "2018-05-08 15:24:47 iteration 250/429: current training loss = 7.666353 (=2.959175+4.707178)\n",
      "2018-05-08 15:24:52 iteration 300/429: current training loss = 8.328370 (=3.111385+5.216985)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-08 15:24:58 iteration 350/429: current training loss = 8.631317 (=3.133512+5.497806)\n",
      "2018-05-08 15:25:04 iteration 400/429: current training loss = 8.284013 (=3.072294+5.211719)\n",
      "2018-05-08 15:25:07 iteration 429/429: current training loss = 8.544214 (=3.221970+5.322245)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:25:24 end epoch 72/100: loss_train=7.916998 loss_val=7.864436 loss_test=7.883429\n",
      "\n",
      "2018-05-08 15:25:24 start epoch 73/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:25:24 iteration 1/429: current training loss = 7.993901 (=3.074472+4.919429)\n",
      "2018-05-08 15:25:30 iteration 50/429: current training loss = 8.267735 (=3.078496+5.189239)\n",
      "2018-05-08 15:25:35 iteration 100/429: current training loss = 8.186326 (=2.983068+5.203258)\n",
      "2018-05-08 15:25:40 iteration 150/429: current training loss = 8.010830 (=3.079725+4.931105)\n",
      "2018-05-08 15:25:46 iteration 200/429: current training loss = 8.362099 (=3.116047+5.246052)\n",
      "2018-05-08 15:25:51 iteration 250/429: current training loss = 7.899249 (=3.038743+4.860506)\n",
      "2018-05-08 15:25:57 iteration 300/429: current training loss = 8.161650 (=3.115088+5.046561)\n",
      "2018-05-08 15:26:02 iteration 350/429: current training loss = 8.214219 (=3.021213+5.193006)\n",
      "2018-05-08 15:26:07 iteration 400/429: current training loss = 8.191063 (=3.119760+5.071302)\n",
      "2018-05-08 15:26:11 iteration 429/429: current training loss = 8.284921 (=3.100984+5.183937)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:26:28 end epoch 73/100: loss_train=7.974650 loss_val=7.929473 loss_test=7.972615\n",
      "\n",
      "2018-05-08 15:26:28 start epoch 74/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:26:28 iteration 1/429: current training loss = 8.163991 (=3.083326+5.080666)\n",
      "2018-05-08 15:26:33 iteration 50/429: current training loss = 8.906910 (=3.050933+5.855977)\n",
      "2018-05-08 15:26:39 iteration 100/429: current training loss = 8.099432 (=3.045899+5.053534)\n",
      "2018-05-08 15:26:44 iteration 150/429: current training loss = 7.985663 (=3.039177+4.946486)\n",
      "2018-05-08 15:26:49 iteration 200/429: current training loss = 8.318077 (=3.013075+5.305002)\n",
      "2018-05-08 15:26:54 iteration 250/429: current training loss = 8.249273 (=3.036301+5.212972)\n",
      "2018-05-08 15:26:59 iteration 300/429: current training loss = 8.364787 (=2.963324+5.401464)\n",
      "2018-05-08 15:27:05 iteration 350/429: current training loss = 7.966785 (=3.002860+4.963925)\n",
      "2018-05-08 15:27:10 iteration 400/429: current training loss = 8.367635 (=3.115758+5.251877)\n",
      "2018-05-08 15:27:13 iteration 429/429: current training loss = 8.614971 (=3.123271+5.491700)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:27:31 end epoch 74/100: loss_train=8.516646 loss_val=8.487302 loss_test=8.470133\n",
      "\n",
      "2018-05-08 15:27:31 start epoch 75/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:27:31 iteration 1/429: current training loss = 8.088263 (=2.959619+5.128643)\n",
      "2018-05-08 15:27:36 iteration 50/429: current training loss = 7.304913 (=2.899356+4.405557)\n",
      "2018-05-08 15:27:41 iteration 100/429: current training loss = 8.175476 (=3.051034+5.124443)\n",
      "2018-05-08 15:27:46 iteration 150/429: current training loss = 8.164993 (=3.042046+5.122948)\n",
      "2018-05-08 15:27:51 iteration 200/429: current training loss = 7.927913 (=2.983155+4.944758)\n",
      "2018-05-08 15:27:57 iteration 250/429: current training loss = 8.180296 (=3.031329+5.148967)\n",
      "2018-05-08 15:28:02 iteration 300/429: current training loss = 8.319706 (=3.164054+5.155652)\n",
      "2018-05-08 15:28:07 iteration 350/429: current training loss = 8.305917 (=3.074816+5.231101)\n",
      "2018-05-08 15:28:13 iteration 400/429: current training loss = 7.846243 (=3.032238+4.814004)\n",
      "2018-05-08 15:28:16 iteration 429/429: current training loss = 8.140875 (=3.084384+5.056491)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:28:33 end epoch 75/100: loss_train=7.905828 loss_val=7.884632 loss_test=7.906501\n",
      "\n",
      "2018-05-08 15:28:33 start epoch 76/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:28:33 iteration 1/429: current training loss = 7.980092 (=3.066770+4.913321)\n",
      "2018-05-08 15:28:38 iteration 50/429: current training loss = 7.858476 (=3.026327+4.832148)\n",
      "2018-05-08 15:28:44 iteration 100/429: current training loss = 8.482403 (=3.122376+5.360027)\n",
      "2018-05-08 15:28:49 iteration 150/429: current training loss = 8.007148 (=2.959554+5.047594)\n",
      "2018-05-08 15:28:54 iteration 200/429: current training loss = 8.149553 (=3.177464+4.972089)\n",
      "2018-05-08 15:28:59 iteration 250/429: current training loss = 8.616478 (=3.146018+5.470460)\n",
      "2018-05-08 15:29:04 iteration 300/429: current training loss = 8.405211 (=3.200172+5.205039)\n",
      "2018-05-08 15:29:10 iteration 350/429: current training loss = 7.696588 (=2.938656+4.757932)\n",
      "2018-05-08 15:29:15 iteration 400/429: current training loss = 8.024066 (=3.087310+4.936756)\n",
      "2018-05-08 15:29:18 iteration 429/429: current training loss = 7.578842 (=3.017946+4.560896)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:29:36 end epoch 76/100: loss_train=8.080097 loss_val=8.032558 loss_test=8.108879\n",
      "\n",
      "2018-05-08 15:29:36 start epoch 77/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:29:36 iteration 1/429: current training loss = 8.128379 (=3.098773+5.029606)\n",
      "2018-05-08 15:29:41 iteration 50/429: current training loss = 7.975889 (=2.969304+5.006585)\n",
      "2018-05-08 15:29:46 iteration 100/429: current training loss = 8.186567 (=3.103093+5.083474)\n",
      "2018-05-08 15:29:52 iteration 150/429: current training loss = 8.330776 (=3.074193+5.256583)\n",
      "2018-05-08 15:29:57 iteration 200/429: current training loss = 7.761432 (=3.015423+4.746009)\n",
      "2018-05-08 15:30:02 iteration 250/429: current training loss = 8.175344 (=2.928772+5.246572)\n",
      "2018-05-08 15:30:07 iteration 300/429: current training loss = 8.372181 (=3.140679+5.231502)\n",
      "2018-05-08 15:30:12 iteration 350/429: current training loss = 8.713343 (=3.100588+5.612754)\n",
      "2018-05-08 15:30:18 iteration 400/429: current training loss = 7.794212 (=2.964897+4.829316)\n",
      "2018-05-08 15:30:21 iteration 429/429: current training loss = 8.631655 (=3.143172+5.488482)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:30:37 end epoch 77/100: loss_train=8.317354 loss_val=8.298424 loss_test=8.320722\n",
      "\n",
      "2018-05-08 15:30:37 start epoch 78/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:30:37 iteration 1/429: current training loss = 8.226692 (=3.045509+5.181183)\n",
      "2018-05-08 15:30:42 iteration 50/429: current training loss = 8.363596 (=3.091690+5.271907)\n",
      "2018-05-08 15:30:47 iteration 100/429: current training loss = 8.352995 (=3.153048+5.199947)\n",
      "2018-05-08 15:30:53 iteration 150/429: current training loss = 8.431611 (=3.015963+5.415648)\n",
      "2018-05-08 15:30:58 iteration 200/429: current training loss = 8.482924 (=3.053853+5.429070)\n",
      "2018-05-08 15:31:03 iteration 250/429: current training loss = 7.896349 (=2.872776+5.023572)\n",
      "2018-05-08 15:31:09 iteration 300/429: current training loss = 7.613064 (=2.934775+4.678289)\n",
      "2018-05-08 15:31:14 iteration 350/429: current training loss = 8.097941 (=3.018646+5.079296)\n",
      "2018-05-08 15:31:19 iteration 400/429: current training loss = 7.402101 (=2.980338+4.421763)\n",
      "2018-05-08 15:31:22 iteration 429/429: current training loss = 8.154656 (=3.060045+5.094612)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:31:40 end epoch 78/100: loss_train=8.378076 loss_val=8.331407 loss_test=8.353830\n",
      "\n",
      "2018-05-08 15:31:40 start epoch 79/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:31:40 iteration 1/429: current training loss = 8.576040 (=3.149033+5.427007)\n",
      "2018-05-08 15:31:45 iteration 50/429: current training loss = 8.240175 (=3.092969+5.147206)\n",
      "2018-05-08 15:31:50 iteration 100/429: current training loss = 8.750466 (=3.108494+5.641973)\n",
      "2018-05-08 15:31:55 iteration 150/429: current training loss = 7.627978 (=2.977913+4.650065)\n",
      "2018-05-08 15:32:00 iteration 200/429: current training loss = 7.991693 (=3.143124+4.848568)\n",
      "2018-05-08 15:32:06 iteration 250/429: current training loss = 8.290293 (=3.070270+5.220023)\n",
      "2018-05-08 15:32:11 iteration 300/429: current training loss = 9.319921 (=3.164211+6.155709)\n",
      "2018-05-08 15:32:16 iteration 350/429: current training loss = 8.282379 (=3.063153+5.219226)\n",
      "2018-05-08 15:32:21 iteration 400/429: current training loss = 8.925526 (=3.144795+5.780730)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-08 15:32:24 iteration 429/429: current training loss = 8.184477 (=3.159100+5.025377)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:32:39 end epoch 79/100: loss_train=7.949992 loss_val=7.896038 loss_test=7.928523\n",
      "\n",
      "2018-05-08 15:32:39 start epoch 80/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:32:40 iteration 1/429: current training loss = 7.741035 (=2.982879+4.758157)\n",
      "2018-05-08 15:32:45 iteration 50/429: current training loss = 8.151285 (=3.147921+5.003364)\n",
      "2018-05-08 15:32:50 iteration 100/429: current training loss = 8.404089 (=3.080443+5.323645)\n",
      "2018-05-08 15:32:55 iteration 150/429: current training loss = 8.438657 (=2.936250+5.502407)\n",
      "2018-05-08 15:33:00 iteration 200/429: current training loss = 8.420632 (=3.130160+5.290472)\n",
      "2018-05-08 15:33:05 iteration 250/429: current training loss = 7.691664 (=2.920068+4.771596)\n",
      "2018-05-08 15:33:10 iteration 300/429: current training loss = 8.165948 (=3.009209+5.156738)\n",
      "2018-05-08 15:33:15 iteration 350/429: current training loss = 7.954789 (=3.103520+4.851269)\n",
      "2018-05-08 15:33:21 iteration 400/429: current training loss = 7.588289 (=2.895462+4.692827)\n",
      "2018-05-08 15:33:24 iteration 429/429: current training loss = 8.179268 (=3.074234+5.105033)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:33:41 end epoch 80/100: loss_train=7.891593 loss_val=7.879694 loss_test=7.918012\n",
      "\n",
      "2018-05-08 15:33:41 start epoch 81/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:33:41 iteration 1/429: current training loss = 7.680945 (=2.927779+4.753166)\n",
      "2018-05-08 15:33:46 iteration 50/429: current training loss = 8.096765 (=3.077206+5.019558)\n",
      "2018-05-08 15:33:51 iteration 100/429: current training loss = 8.190781 (=3.116442+5.074338)\n",
      "2018-05-08 15:33:57 iteration 150/429: current training loss = 7.850036 (=3.060364+4.789672)\n",
      "2018-05-08 15:34:02 iteration 200/429: current training loss = 8.325936 (=3.106221+5.219715)\n",
      "2018-05-08 15:34:08 iteration 250/429: current training loss = 8.155711 (=3.129103+5.026608)\n",
      "2018-05-08 15:34:13 iteration 300/429: current training loss = 8.276086 (=3.058163+5.217923)\n",
      "2018-05-08 15:34:18 iteration 350/429: current training loss = 8.117269 (=3.067891+5.049377)\n",
      "2018-05-08 15:34:24 iteration 400/429: current training loss = 8.439728 (=3.099563+5.340165)\n",
      "2018-05-08 15:34:27 iteration 429/429: current training loss = 8.002140 (=3.026142+4.975998)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:34:44 end epoch 81/100: loss_train=8.118854 loss_val=8.065817 loss_test=8.132412\n",
      "\n",
      "2018-05-08 15:34:44 start epoch 82/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:34:44 iteration 1/429: current training loss = 8.295961 (=3.052906+5.243055)\n",
      "2018-05-08 15:34:50 iteration 50/429: current training loss = 7.829185 (=3.096108+4.733077)\n",
      "2018-05-08 15:34:55 iteration 100/429: current training loss = 7.835421 (=2.927215+4.908206)\n",
      "2018-05-08 15:35:00 iteration 150/429: current training loss = 7.520834 (=2.944478+4.576356)\n",
      "2018-05-08 15:35:05 iteration 200/429: current training loss = 7.984645 (=3.137862+4.846783)\n",
      "2018-05-08 15:35:10 iteration 250/429: current training loss = 8.410200 (=3.095792+5.314408)\n",
      "2018-05-08 15:35:16 iteration 300/429: current training loss = 7.534320 (=2.918986+4.615335)\n",
      "2018-05-08 15:35:21 iteration 350/429: current training loss = 8.362151 (=3.101040+5.261112)\n",
      "2018-05-08 15:35:27 iteration 400/429: current training loss = 8.169853 (=2.989293+5.180560)\n",
      "2018-05-08 15:35:30 iteration 429/429: current training loss = 8.066744 (=3.097359+4.969384)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:35:47 end epoch 82/100: loss_train=8.002604 loss_val=7.940228 loss_test=8.004179\n",
      "\n",
      "2018-05-08 15:35:47 start epoch 83/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:35:47 iteration 1/429: current training loss = 7.761088 (=3.002984+4.758104)\n",
      "2018-05-08 15:35:52 iteration 50/429: current training loss = 8.227596 (=3.014461+5.213136)\n",
      "2018-05-08 15:35:57 iteration 100/429: current training loss = 7.766909 (=2.969794+4.797115)\n",
      "2018-05-08 15:36:02 iteration 150/429: current training loss = 8.062510 (=3.075216+4.987294)\n",
      "2018-05-08 15:36:08 iteration 200/429: current training loss = 7.665679 (=3.002857+4.662823)\n",
      "2018-05-08 15:36:13 iteration 250/429: current training loss = 8.429386 (=2.936691+5.492695)\n",
      "2018-05-08 15:36:19 iteration 300/429: current training loss = 8.297133 (=3.085030+5.212103)\n",
      "2018-05-08 15:36:24 iteration 350/429: current training loss = 8.299252 (=3.155430+5.143822)\n",
      "2018-05-08 15:36:29 iteration 400/429: current training loss = 7.871568 (=2.993006+4.878562)\n",
      "2018-05-08 15:36:33 iteration 429/429: current training loss = 7.984669 (=3.046563+4.938106)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:36:49 end epoch 83/100: loss_train=8.006514 loss_val=7.981991 loss_test=7.967255\n",
      "\n",
      "2018-05-08 15:36:49 start epoch 84/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:36:49 iteration 1/429: current training loss = 7.959213 (=3.095073+4.864140)\n",
      "2018-05-08 15:36:55 iteration 50/429: current training loss = 8.125526 (=3.025917+5.099610)\n",
      "2018-05-08 15:37:00 iteration 100/429: current training loss = 8.000735 (=3.132832+4.867903)\n",
      "2018-05-08 15:37:05 iteration 150/429: current training loss = 8.761384 (=3.086498+5.674886)\n",
      "2018-05-08 15:37:11 iteration 200/429: current training loss = 8.530492 (=3.142752+5.387739)\n",
      "2018-05-08 15:37:16 iteration 250/429: current training loss = 8.022019 (=3.065642+4.956378)\n",
      "2018-05-08 15:37:21 iteration 300/429: current training loss = 8.381203 (=3.136333+5.244869)\n",
      "2018-05-08 15:37:27 iteration 350/429: current training loss = 8.066575 (=3.203022+4.863554)\n",
      "2018-05-08 15:37:32 iteration 400/429: current training loss = 8.100364 (=2.983310+5.117054)\n",
      "2018-05-08 15:37:35 iteration 429/429: current training loss = 8.039222 (=3.077569+4.961652)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:37:51 end epoch 84/100: loss_train=8.036327 loss_val=7.966278 loss_test=8.024675\n",
      "\n",
      "2018-05-08 15:37:51 start epoch 85/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:37:51 iteration 1/429: current training loss = 7.942207 (=3.007392+4.934815)\n",
      "2018-05-08 15:37:56 iteration 50/429: current training loss = 8.218389 (=3.069288+5.149100)\n",
      "2018-05-08 15:38:02 iteration 100/429: current training loss = 8.482967 (=3.056588+5.426380)\n",
      "2018-05-08 15:38:07 iteration 150/429: current training loss = 7.675216 (=2.952007+4.723208)\n",
      "2018-05-08 15:38:12 iteration 200/429: current training loss = 8.049445 (=3.030230+5.019215)\n",
      "2018-05-08 15:38:18 iteration 250/429: current training loss = 7.674851 (=2.948509+4.726343)\n",
      "2018-05-08 15:38:23 iteration 300/429: current training loss = 7.821139 (=2.981807+4.839332)\n",
      "2018-05-08 15:38:29 iteration 350/429: current training loss = 8.144655 (=3.007497+5.137158)\n",
      "2018-05-08 15:38:34 iteration 400/429: current training loss = 8.557782 (=3.090907+5.466875)\n",
      "2018-05-08 15:38:37 iteration 429/429: current training loss = 7.917201 (=3.086574+4.830627)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:38:54 end epoch 85/100: loss_train=7.819577 loss_val=7.809854 loss_test=7.836399\n",
      "\n",
      "2018-05-08 15:38:54 start epoch 86/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:38:55 iteration 1/429: current training loss = 8.104192 (=3.161243+4.942948)\n",
      "2018-05-08 15:39:00 iteration 50/429: current training loss = 8.246650 (=3.027176+5.219473)\n",
      "2018-05-08 15:39:05 iteration 100/429: current training loss = 7.720872 (=2.984407+4.736465)\n",
      "2018-05-08 15:39:11 iteration 150/429: current training loss = 8.010712 (=2.989436+5.021276)\n",
      "2018-05-08 15:39:16 iteration 200/429: current training loss = 7.603679 (=3.008548+4.595130)\n",
      "2018-05-08 15:39:21 iteration 250/429: current training loss = 7.847252 (=2.997852+4.849401)\n",
      "2018-05-08 15:39:26 iteration 300/429: current training loss = 7.607534 (=2.939467+4.668067)\n",
      "2018-05-08 15:39:31 iteration 350/429: current training loss = 8.132099 (=3.162148+4.969952)\n",
      "2018-05-08 15:39:37 iteration 400/429: current training loss = 7.813829 (=2.896230+4.917600)\n",
      "2018-05-08 15:39:40 iteration 429/429: current training loss = 8.067583 (=3.089604+4.977979)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:39:57 end epoch 86/100: loss_train=7.992633 loss_val=7.934210 loss_test=8.006913\n",
      "\n",
      "2018-05-08 15:39:57 start epoch 87/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:39:57 iteration 1/429: current training loss = 8.034426 (=3.043378+4.991048)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-08 15:40:03 iteration 50/429: current training loss = 7.808638 (=2.924785+4.883853)\n",
      "2018-05-08 15:40:08 iteration 100/429: current training loss = 7.877501 (=2.963609+4.913892)\n",
      "2018-05-08 15:40:14 iteration 150/429: current training loss = 8.172396 (=3.074510+5.097886)\n",
      "2018-05-08 15:40:19 iteration 200/429: current training loss = 8.524013 (=2.932582+5.591430)\n",
      "2018-05-08 15:40:24 iteration 250/429: current training loss = 7.973813 (=2.987756+4.986057)\n",
      "2018-05-08 15:40:30 iteration 300/429: current training loss = 8.196159 (=3.029937+5.166222)\n",
      "2018-05-08 15:40:35 iteration 350/429: current training loss = 8.153069 (=3.020303+5.132767)\n",
      "2018-05-08 15:40:40 iteration 400/429: current training loss = 8.450006 (=3.138516+5.311491)\n",
      "2018-05-08 15:40:43 iteration 429/429: current training loss = 8.271781 (=3.108081+5.163700)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:41:00 end epoch 87/100: loss_train=7.982150 loss_val=7.986310 loss_test=7.985382\n",
      "\n",
      "2018-05-08 15:41:00 start epoch 88/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:41:01 iteration 1/429: current training loss = 7.768300 (=2.994466+4.773834)\n",
      "2018-05-08 15:41:06 iteration 50/429: current training loss = 7.716368 (=3.030488+4.685879)\n",
      "2018-05-08 15:41:11 iteration 100/429: current training loss = 8.215239 (=3.109719+5.105520)\n",
      "2018-05-08 15:41:17 iteration 150/429: current training loss = 8.318287 (=3.115702+5.202584)\n",
      "2018-05-08 15:41:22 iteration 200/429: current training loss = 7.282640 (=2.895372+4.387269)\n",
      "2018-05-08 15:41:28 iteration 250/429: current training loss = 8.054468 (=3.004852+5.049616)\n",
      "2018-05-08 15:41:33 iteration 300/429: current training loss = 7.815771 (=3.001132+4.814638)\n",
      "2018-05-08 15:41:38 iteration 350/429: current training loss = 8.480558 (=3.220679+5.259880)\n",
      "2018-05-08 15:41:44 iteration 400/429: current training loss = 8.031535 (=3.076167+4.955369)\n",
      "2018-05-08 15:41:47 iteration 429/429: current training loss = 7.858878 (=3.042707+4.816171)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:42:03 end epoch 88/100: loss_train=7.738808 loss_val=7.692834 loss_test=7.751707\n",
      "\n",
      "2018-05-08 15:42:03 start epoch 89/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:42:04 iteration 1/429: current training loss = 7.655719 (=3.056291+4.599427)\n",
      "2018-05-08 15:42:09 iteration 50/429: current training loss = 7.563548 (=2.894946+4.668602)\n",
      "2018-05-08 15:42:14 iteration 100/429: current training loss = 8.525985 (=3.018712+5.507272)\n",
      "2018-05-08 15:42:20 iteration 150/429: current training loss = 7.443793 (=2.985096+4.458697)\n",
      "2018-05-08 15:42:25 iteration 200/429: current training loss = 7.579766 (=3.023478+4.556288)\n",
      "2018-05-08 15:42:31 iteration 250/429: current training loss = 7.750415 (=3.024448+4.725967)\n",
      "2018-05-08 15:42:36 iteration 300/429: current training loss = 7.572652 (=2.930200+4.642452)\n",
      "2018-05-08 15:42:41 iteration 350/429: current training loss = 8.078286 (=2.939330+5.138956)\n",
      "2018-05-08 15:42:46 iteration 400/429: current training loss = 7.636461 (=2.954817+4.681644)\n",
      "2018-05-08 15:42:49 iteration 429/429: current training loss = 8.384385 (=3.097501+5.286884)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:43:06 end epoch 89/100: loss_train=8.097378 loss_val=8.025011 loss_test=8.096049\n",
      "\n",
      "2018-05-08 15:43:06 start epoch 90/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:43:07 iteration 1/429: current training loss = 7.485143 (=2.867555+4.617588)\n",
      "2018-05-08 15:43:12 iteration 50/429: current training loss = 8.576925 (=3.076737+5.500189)\n",
      "2018-05-08 15:43:17 iteration 100/429: current training loss = 8.696383 (=3.131857+5.564526)\n",
      "2018-05-08 15:43:22 iteration 150/429: current training loss = 7.982105 (=3.039743+4.942363)\n",
      "2018-05-08 15:43:27 iteration 200/429: current training loss = 7.790365 (=2.994784+4.795580)\n",
      "2018-05-08 15:43:33 iteration 250/429: current training loss = 7.756113 (=2.996548+4.759564)\n",
      "2018-05-08 15:43:38 iteration 300/429: current training loss = 8.206313 (=3.069301+5.137012)\n",
      "2018-05-08 15:43:43 iteration 350/429: current training loss = 7.643690 (=2.966712+4.676978)\n",
      "2018-05-08 15:43:48 iteration 400/429: current training loss = 8.048000 (=3.044237+5.003763)\n",
      "2018-05-08 15:43:51 iteration 429/429: current training loss = 7.983473 (=3.054958+4.928514)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:44:08 end epoch 90/100: loss_train=8.029770 loss_val=8.013873 loss_test=8.029670\n",
      "\n",
      "2018-05-08 15:44:08 start epoch 91/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:44:08 iteration 1/429: current training loss = 8.068765 (=3.081188+4.987576)\n",
      "2018-05-08 15:44:14 iteration 50/429: current training loss = 8.132551 (=2.900341+5.232211)\n",
      "2018-05-08 15:44:20 iteration 100/429: current training loss = 8.428721 (=3.223385+5.205337)\n",
      "2018-05-08 15:44:25 iteration 150/429: current training loss = 8.107918 (=2.977582+5.130335)\n",
      "2018-05-08 15:44:30 iteration 200/429: current training loss = 7.979473 (=2.983128+4.996345)\n",
      "2018-05-08 15:44:36 iteration 250/429: current training loss = 7.828197 (=3.044757+4.783440)\n",
      "2018-05-08 15:44:41 iteration 300/429: current training loss = 8.018377 (=3.106328+4.912049)\n",
      "2018-05-08 15:44:47 iteration 350/429: current training loss = 7.545923 (=3.014261+4.531662)\n",
      "2018-05-08 15:44:52 iteration 400/429: current training loss = 8.660528 (=3.090507+5.570021)\n",
      "2018-05-08 15:44:55 iteration 429/429: current training loss = 8.080163 (=2.984797+5.095366)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:45:12 end epoch 91/100: loss_train=7.953631 loss_val=7.904422 loss_test=7.954016\n",
      "\n",
      "2018-05-08 15:45:12 start epoch 92/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:45:12 iteration 1/429: current training loss = 8.058881 (=3.073630+4.985251)\n",
      "2018-05-08 15:45:17 iteration 50/429: current training loss = 7.428547 (=2.750151+4.678396)\n",
      "2018-05-08 15:45:22 iteration 100/429: current training loss = 8.416811 (=3.255213+5.161597)\n",
      "2018-05-08 15:45:28 iteration 150/429: current training loss = 7.347422 (=2.958809+4.388613)\n",
      "2018-05-08 15:45:33 iteration 200/429: current training loss = 7.612205 (=3.081922+4.530283)\n",
      "2018-05-08 15:45:39 iteration 250/429: current training loss = 7.930329 (=3.095110+4.835219)\n",
      "2018-05-08 15:45:44 iteration 300/429: current training loss = 7.846942 (=2.938621+4.908320)\n",
      "2018-05-08 15:45:49 iteration 350/429: current training loss = 7.606734 (=2.950947+4.655787)\n",
      "2018-05-08 15:45:55 iteration 400/429: current training loss = 7.568888 (=2.887928+4.680960)\n",
      "2018-05-08 15:45:58 iteration 429/429: current training loss = 7.984538 (=3.054677+4.929861)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:46:15 end epoch 92/100: loss_train=7.802480 loss_val=7.769542 loss_test=7.839657\n",
      "\n",
      "2018-05-08 15:46:15 start epoch 93/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:46:15 iteration 1/429: current training loss = 8.006964 (=3.073178+4.933786)\n",
      "2018-05-08 15:46:20 iteration 50/429: current training loss = 7.731022 (=2.965632+4.765390)\n",
      "2018-05-08 15:46:26 iteration 100/429: current training loss = 8.535383 (=3.168484+5.366899)\n",
      "2018-05-08 15:46:31 iteration 150/429: current training loss = 7.835906 (=3.065639+4.770267)\n",
      "2018-05-08 15:46:37 iteration 200/429: current training loss = 7.649633 (=3.041672+4.607962)\n",
      "2018-05-08 15:46:42 iteration 250/429: current training loss = 7.835989 (=3.051127+4.784862)\n",
      "2018-05-08 15:46:47 iteration 300/429: current training loss = 7.644076 (=3.008265+4.635812)\n",
      "2018-05-08 15:46:53 iteration 350/429: current training loss = 7.877819 (=2.969562+4.908257)\n",
      "2018-05-08 15:46:58 iteration 400/429: current training loss = 8.009169 (=3.032794+4.976374)\n",
      "2018-05-08 15:47:01 iteration 429/429: current training loss = 8.030848 (=3.064590+4.966257)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:47:18 end epoch 93/100: loss_train=7.772760 loss_val=7.697967 loss_test=7.785674\n",
      "\n",
      "2018-05-08 15:47:18 start epoch 94/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:47:18 iteration 1/429: current training loss = 7.308095 (=2.833704+4.474392)\n",
      "2018-05-08 15:47:23 iteration 50/429: current training loss = 7.448463 (=2.895167+4.553297)\n",
      "2018-05-08 15:47:29 iteration 100/429: current training loss = 7.970179 (=3.031567+4.938612)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-08 15:47:34 iteration 150/429: current training loss = 8.203141 (=3.096294+5.106848)\n",
      "2018-05-08 15:47:39 iteration 200/429: current training loss = 7.460739 (=2.959730+4.501009)\n",
      "2018-05-08 15:47:44 iteration 250/429: current training loss = 7.773832 (=3.004270+4.769562)\n",
      "2018-05-08 15:47:49 iteration 300/429: current training loss = 7.661626 (=2.988707+4.672918)\n",
      "2018-05-08 15:47:54 iteration 350/429: current training loss = 7.911681 (=2.971014+4.940667)\n",
      "2018-05-08 15:48:00 iteration 400/429: current training loss = 8.006619 (=3.092366+4.914253)\n",
      "2018-05-08 15:48:03 iteration 429/429: current training loss = 8.331017 (=3.132666+5.198350)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:48:19 end epoch 94/100: loss_train=8.127334 loss_val=8.069852 loss_test=8.134774\n",
      "\n",
      "2018-05-08 15:48:19 start epoch 95/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:48:19 iteration 1/429: current training loss = 8.406488 (=3.019502+5.386986)\n",
      "2018-05-08 15:48:24 iteration 50/429: current training loss = 7.977238 (=3.034783+4.942454)\n",
      "2018-05-08 15:48:30 iteration 100/429: current training loss = 7.825520 (=2.894927+4.930593)\n",
      "2018-05-08 15:48:35 iteration 150/429: current training loss = 7.923684 (=2.990554+4.933129)\n",
      "2018-05-08 15:48:40 iteration 200/429: current training loss = 7.618165 (=2.950376+4.667789)\n",
      "2018-05-08 15:48:46 iteration 250/429: current training loss = 7.786163 (=2.967915+4.818248)\n",
      "2018-05-08 15:48:51 iteration 300/429: current training loss = 7.732826 (=2.924479+4.808347)\n",
      "2018-05-08 15:48:56 iteration 350/429: current training loss = 8.161997 (=3.038964+5.123033)\n",
      "2018-05-08 15:49:01 iteration 400/429: current training loss = 7.743892 (=3.035716+4.708176)\n",
      "2018-05-08 15:49:04 iteration 429/429: current training loss = 7.984015 (=3.104352+4.879663)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:49:22 end epoch 95/100: loss_train=7.972234 loss_val=7.985128 loss_test=7.978163\n",
      "\n",
      "2018-05-08 15:49:22 start epoch 96/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:49:22 iteration 1/429: current training loss = 7.684077 (=2.919957+4.764120)\n",
      "2018-05-08 15:49:27 iteration 50/429: current training loss = 8.039476 (=3.029269+5.010208)\n",
      "2018-05-08 15:49:33 iteration 100/429: current training loss = 7.777706 (=2.935985+4.841721)\n",
      "2018-05-08 15:49:38 iteration 150/429: current training loss = 7.696973 (=2.972796+4.724177)\n",
      "2018-05-08 15:49:43 iteration 200/429: current training loss = 8.012979 (=3.051237+4.961741)\n",
      "2018-05-08 15:49:49 iteration 250/429: current training loss = 7.700393 (=2.973246+4.727147)\n",
      "2018-05-08 15:49:54 iteration 300/429: current training loss = 7.779776 (=2.981873+4.797903)\n",
      "2018-05-08 15:49:59 iteration 350/429: current training loss = 8.111812 (=3.103097+5.008714)\n",
      "2018-05-08 15:50:05 iteration 400/429: current training loss = 8.068288 (=3.073926+4.994362)\n",
      "2018-05-08 15:50:08 iteration 429/429: current training loss = 7.710653 (=3.054949+4.655704)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:50:24 end epoch 96/100: loss_train=7.690628 loss_val=7.587090 loss_test=7.693980\n",
      "\n",
      "2018-05-08 15:50:24 start epoch 97/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:50:25 iteration 1/429: current training loss = 7.743203 (=3.065086+4.678117)\n",
      "2018-05-08 15:50:30 iteration 50/429: current training loss = 8.494912 (=3.265557+5.229356)\n",
      "2018-05-08 15:50:35 iteration 100/429: current training loss = 7.958846 (=3.154725+4.804121)\n",
      "2018-05-08 15:50:40 iteration 150/429: current training loss = 7.794466 (=2.971099+4.823367)\n",
      "2018-05-08 15:50:45 iteration 200/429: current training loss = 7.694168 (=3.024571+4.669597)\n",
      "2018-05-08 15:50:51 iteration 250/429: current training loss = 7.900826 (=3.133835+4.766991)\n",
      "2018-05-08 15:50:56 iteration 300/429: current training loss = 8.349770 (=3.195088+5.154682)\n",
      "2018-05-08 15:51:01 iteration 350/429: current training loss = 7.571388 (=2.877041+4.694347)\n",
      "2018-05-08 15:51:06 iteration 400/429: current training loss = 8.027257 (=3.097215+4.930042)\n",
      "2018-05-08 15:51:09 iteration 429/429: current training loss = 7.720807 (=3.005082+4.715724)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:51:25 end epoch 97/100: loss_train=7.977238 loss_val=7.960771 loss_test=7.972254\n",
      "\n",
      "2018-05-08 15:51:25 start epoch 98/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:51:26 iteration 1/429: current training loss = 8.232319 (=3.066064+5.166255)\n",
      "2018-05-08 15:51:30 iteration 50/429: current training loss = 8.283200 (=3.132509+5.150692)\n",
      "2018-05-08 15:51:35 iteration 100/429: current training loss = 7.097522 (=2.836868+4.260654)\n",
      "2018-05-08 15:51:41 iteration 150/429: current training loss = 7.589325 (=2.994920+4.594405)\n",
      "2018-05-08 15:51:46 iteration 200/429: current training loss = 7.772361 (=3.053720+4.718641)\n",
      "2018-05-08 15:51:51 iteration 250/429: current training loss = 8.133261 (=3.080338+5.052924)\n",
      "2018-05-08 15:51:56 iteration 300/429: current training loss = 8.209473 (=3.095557+5.113916)\n",
      "2018-05-08 15:52:01 iteration 350/429: current training loss = 7.756755 (=3.128062+4.628694)\n",
      "2018-05-08 15:52:07 iteration 400/429: current training loss = 8.176679 (=3.053624+5.123055)\n",
      "2018-05-08 15:52:10 iteration 429/429: current training loss = 8.278349 (=3.048016+5.230333)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:52:26 end epoch 98/100: loss_train=8.196492 loss_val=8.149144 loss_test=8.180677\n",
      "\n",
      "2018-05-08 15:52:26 start epoch 99/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:52:26 iteration 1/429: current training loss = 8.009193 (=2.950942+5.058251)\n",
      "2018-05-08 15:52:31 iteration 50/429: current training loss = 7.447577 (=3.016785+4.430791)\n",
      "2018-05-08 15:52:36 iteration 100/429: current training loss = 7.903757 (=2.987659+4.916097)\n",
      "2018-05-08 15:52:42 iteration 150/429: current training loss = 8.450339 (=3.044612+5.405727)\n",
      "2018-05-08 15:52:47 iteration 200/429: current training loss = 7.186239 (=2.871384+4.314856)\n",
      "2018-05-08 15:52:52 iteration 250/429: current training loss = 7.425234 (=2.969555+4.455679)\n",
      "2018-05-08 15:52:57 iteration 300/429: current training loss = 7.714561 (=3.035556+4.679005)\n",
      "2018-05-08 15:53:02 iteration 350/429: current training loss = 7.766695 (=3.086231+4.680464)\n",
      "2018-05-08 15:53:07 iteration 400/429: current training loss = 7.632417 (=2.954607+4.677810)\n",
      "2018-05-08 15:53:10 iteration 429/429: current training loss = 7.741303 (=2.986485+4.754818)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:53:27 end epoch 99/100: loss_train=7.635986 loss_val=7.619484 loss_test=7.668797\n",
      "\n",
      "2018-05-08 15:53:27 start epoch 100/100, with learning rate = 0.0010000000\n",
      "2018-05-08 15:53:27 iteration 1/429: current training loss = 7.811190 (=3.061998+4.749192)\n",
      "2018-05-08 15:53:32 iteration 50/429: current training loss = 7.714611 (=2.974083+4.740528)\n",
      "2018-05-08 15:53:37 iteration 100/429: current training loss = 7.724197 (=2.952086+4.772111)\n",
      "2018-05-08 15:53:43 iteration 150/429: current training loss = 8.347982 (=3.107479+5.240503)\n",
      "2018-05-08 15:53:48 iteration 200/429: current training loss = 8.178036 (=3.117351+5.060686)\n",
      "2018-05-08 15:53:53 iteration 250/429: current training loss = 7.516118 (=2.968649+4.547470)\n",
      "2018-05-08 15:53:58 iteration 300/429: current training loss = 7.531027 (=2.938915+4.592112)\n",
      "2018-05-08 15:54:03 iteration 350/429: current training loss = 8.061617 (=3.181292+4.880325)\n",
      "2018-05-08 15:54:09 iteration 400/429: current training loss = 7.885158 (=3.095168+4.789989)\n",
      "2018-05-08 15:54:12 iteration 429/429: current training loss = 7.859218 (=3.108132+4.751085)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-08 15:54:29 end epoch 100/100: loss_train=7.782787 loss_val=7.768027 loss_test=7.789242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size=128\n",
    "max_epoch=100\n",
    "print_every=50\n",
    "num_iteration=num_train//batch_size\n",
    "loss_train_his=[]\n",
    "loss_val_his=[]\n",
    "loss_test_his=[]\n",
    "\n",
    "def eval(dataset,num_iteration):\n",
    "    t_loss=0\n",
    "    for it in range(num_iteration):\n",
    "        images,labels=dataset.next_batch(batch_size)\n",
    "        loss_num = sess.run(total_loss,feed_dict={X:images.reshape((-1,1,28,28))})\n",
    "        t_loss+=loss_num\n",
    "    t_loss/=num_iteration\n",
    "    return t_loss\n",
    "\n",
    "saver=tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(max_epoch):\n",
    "        print(time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())),\n",
    "                  'start epoch %d/%d, with learning rate = %.10f' % (epoch+1,max_epoch,sess.run(learning_rate)))\n",
    "        average_loss=0\n",
    "        average_loss1=0\n",
    "        average_loss2=0\n",
    "        for it in range(num_iteration):\n",
    "            images,labels=mnist.train.next_batch(batch_size)\n",
    "            feed_dict={X:images.reshape((-1,1,28,28))}\n",
    "#             loss_num,l1,l2,temp1,temp2,_=sess.run([total_loss,total_latent_loss,total_likelihood_loss,X,canvas,train_step],feed_dict=feed_dict)\n",
    "            loss_num,l1,l2,_=sess.run([total_loss,total_latent_loss,total_likelihood_loss,train_step],feed_dict=feed_dict)\n",
    "            if it==0 or (it+1)%print_every==0 or it==num_iteration-1:\n",
    "                print(time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())),\n",
    "                      'iteration %d/%d:' % (it+1,num_iteration),'current training loss = %f (=%f+%f)' % (loss_num,l1,l2))\n",
    "        \n",
    "        loss_train=eval(mnist.train,num_train//batch_size)\n",
    "        loss_val=eval(mnist.validation,num_val//batch_size)\n",
    "        loss_test=eval(mnist.test,num_test//batch_size)\n",
    "        loss_train_his.append(loss_train)\n",
    "        loss_val_his.append(loss_val)\n",
    "        loss_test_his.append(loss_test)\n",
    "        \n",
    "        save_path = saver.save(sess, \"parameters/DRAW/DRAW.ckpt\")\n",
    "        print(\"model saved in path: %s\" % save_path)\n",
    "        print(time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())),'end epoch %d/%d:' % (epoch+1,max_epoch),\n",
    "                 'loss_train=%f loss_val=%f loss_test=%f' % (loss_train,loss_val,loss_test))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "ptr,=plt.plot(range(max_epoch),loss_train_his,'r-')\n",
    "pva,=plt.plot(range(max_epoch),loss_val_his,'b-')\n",
    "pte,=plt.plot(range(max_epoch),loss_test_his,'y-')\n",
    "plt.xlabel('training epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('loss on three sets')\n",
    "plt.legend((ptr,pva,pte),('train','validation','test'))\n",
    "# plt.savefig('model-DRAW.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_patch(image,_gx,_gy,_stride,_sigma):\n",
    "    '''\n",
    "    draw the attention boundary on the canvas\n",
    "    width of edge reflects sigma\n",
    "    '''\n",
    "    fig = plt.figure(1)\n",
    "    ax = fig.add_subplot(111, aspect='equal')\n",
    "    plt.imshow(image,vmin=0,vmax=1,cmap='gray')\n",
    "    upper_left_x=_gx-_stride*(patch-1)//2\n",
    "    upper_left_y=_gy-_stride*(patch-1)//2\n",
    "    width=_stride*(patch-1)\n",
    "    height=_stride*(patch-1)\n",
    "    rect = patches.Rectangle((upper_left_x,upper_left_y),width,height,linewidth=_sigma*3.0,edgecolor='r',facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from parameters/DRAW/DRAW.ckpt\n",
      "time = 0\n",
      "gx = 16.272207\n",
      "gy = 12.060698\n",
      "stride = 1.8425845\n",
      "sigma = 0.9578153\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAC8NJREFUeJzt3V/IZHd9x/H3Jxu9icEkSMISY2MleONFLEtulJJSIqkUEi8Uc7XSwnrRgN4ZvDFQhFDU9k6IGNxCjRWiTQilMYhtvCghmyAmcRsTZKtrlixhE02uxN1vL56z9jHZ55nZmTlzZuf7fsEwM2fPnPPds/uZ8+f3O/NLVSGpn8umLkDSNAy/1JThl5oy/FJThl9qyvBLTRl+qSnDLzVl+KWmLl/nypLYnVAaWVVlnvmW2vMnuT3JC0leSnLPMsuStF5ZtG9/kgPAz4HbgJPAU8BdVfWzfT7jnl8a2Tr2/LcAL1XVL6rqd8B3gDuWWJ6kNVom/NcDv9r1/uQw7Y8kOZLkWJJjS6xL0ootc8HvQocWbzusr6r7gfvBw35pkyyz5z8J3LDr/XuBl5crR9K6LBP+p4Cbkrw/yTuBTwOPrKYsSWNb+LC/qn6f5G7gMeAA8EBVPb+yyiSNauGmvoVW5jm/NLq1dPKRdOky/FJThl9qyvBLTRl+qSnDLzVl+KWmDL/UlOGXmjL8UlOGX2rK8EtNGX6pKcMvNWX4paYMv9SU4ZeaMvxSU4ZfasrwS00Zfqkpwy81Zfilpgy/1JThl5oy/FJThl9qyvBLTRl+qamFh+gGSHICeAM4C/y+qg6toihJ41sq/IO/qKpXV7AcSWvkYb/U1LLhL+AHSZ5OcmQVBUlaj2UP+z9SVS8nuRZ4PMn/VNUTu2cYvhT8YpA2TKpqNQtK7gXerKqv7DPPalYmaU9VlXnmW/iwP8kVSa48/xr4GPDcosuTtF7LHPZfB3w/yfnlfLuq/mMlVUka3coO++damYf90uhGP+yXdGkz/FJThl9qyvBLTRl+qSnDLzW1irv6tMWGfhx7uuyyxfcfs5a9bDP0fp+ftex1NoFPxT2/1JThl5oy/FJTnvNvoRPAu1e1sFnnvmfPrmpNl4zfADdOXcQKGP4t9G7gqqmL0MYz/Fvu9akL2CLb9oVq+LfY68DVSy7Dpr7/9xrb9QVg+Lfc5Zfv/0984MCBUdc/K+DLmBXgc+fO7flnZ2dcq7CdX9LWMvxSU4ZfasrwS00Zfqkpwy81Zfilpmzn3wJv62izq317ViecMdvhl7Vsbfv93ffrA7Dnures7d89v9SU4ZeaMvxSU4ZfasrwS00Zfqkpwy81NbOdP8kDwF8Dp6vqQ8O0a4B/ZeenzE4An6qq18Yrs7dl2uqXued9ns+Ped/7rHb+ZfoBbHL/hnWZZ8//LeD2t0y7B/hhVd0E/HB4L+kSMjP8VfUEcOYtk+8Ajg6vjwJ3rrguSSNb9Jz/uqo6BTA8X7u6kiStw+h9+5McAY6MvR5JF2fRPf8rSQ4CDM+n95qxqu6vqkNVdWjBdUkawaLhfwQ4PLw+DDy8mnIkrcvM8Cd5EPhv4INJTib5W+A+4LYkLwK3De8lXUJmnvNX1V17/NFfrrgWjWBWO/6yxmznX2ZAEBihH4D380vaBoZfasrwS00Zfqkpwy81Zfilpvzp7kvAMs1pYw81vczyN/m2WofolrS1DL/UlOGXmjL8UlOGX2rK8EtNGX6pKdv5t8Am9wNYpi1/Vm2zlr3f5zu048/inl9qyvBLTRl+qSnDLzVl+KWmDL/UlOGXmrKdf8ttcjv+ssbs39ChH4B7fqkpwy81Zfilpgy/1JThl5oy/FJThl9qamb4kzyQ5HSS53ZNuzfJr5P8ZHh8fNwye6uqfR9jSrLvY0qztssyjw7m2fN/C7j9AtP/sapuHh7/vtqyJI1tZvir6gngzBpqkbRGy5zz353kp8NpwdUrq0jSWiwa/q8DHwBuBk4BX91rxiRHkhxLcmzBdUkawULhr6pXqupsVZ0DvgHcss+891fVoao6tGiRklZvofAnObjr7SeA5/aaV9JmmnlLb5IHgVuB9yQ5CXwJuDXJzUABJ4DPjlijpBFknW2aSXo0oE7sNeAq4HXgmpHb4pdp61+2n8C67+ffvV03+Qp3Vc21Ye3hJzVl+KWmDL/UlOGXmjL8UlOGX2rKn+7ecss25S4zDPasz4/dzNzl1txFueeXmjL8UlOGX2rK8EtNGX6pKcMvNWX4paZs59e+trWtfFv/XhfDPb/UlOGXmjL8UlOe82+xq9j56alJbdG59VVTF7Bihn/Lbdt/WK2O4d9Cv5m6gC23LdvXX+/VqKYeyXcv29zUN++v97rn16i2OWSXOq/2S00Zfqkpwy81Zfilpgy/1JThl5oy/FJTM8Of5IYkP0pyPMnzST43TL8myeNJXhyeN3nUYklvMbOHX5KDwMGqeibJlcDTwJ3AZ4AzVXVfknuAq6vqCzOWZY8PaWTz9vCbueevqlNV9czw+g3gOHA9cAdwdJjtKDtfCJIuERd1zp/kRuDDwJPAdVV1Cna+IIBrV12cpPHM3bc/ybuAh4DPV9Vv571hI8kR4Mhi5Ukay1x39SV5B/Ao8FhVfW2Y9gJwa1WdGq4L/GdVfXDGcjznl0a2snP+7OzivwkcPx/8wSPA4eH1YeDhiy1S0nTmudr/UeDHwLPAuWHyF9k57/8u8D7gl8Anq+rMjGW555dGNu+e3x/zkLbMyg77JW0nwy81Zfilpgy/1JThl5oy/FJThl9qyvBLTRl+qSnDLzVl+KWmDL/UlOGXmjL8UlOGX2rK8EtNGX6pKcMvNWX4paYMv9SU4ZeaMvxSU4ZfasrwS00Zfqkpwy81Zfilpgy/1JThl5oy/FJTM8Of5IYkP0pyPMnzST43TL83ya+T/GR4fHz8ciWtSqpq/xmSg8DBqnomyZXA08CdwKeAN6vqK3OvLNl/ZZKWVlWZZ77L51jQKeDU8PqNJMeB65crT9LULuqcP8mNwIeBJ4dJdyf5aZIHkly9x2eOJDmW5NhSlUpaqZmH/X+YMXkX8F/Al6vqe0muA14FCvh7dk4N/mbGMjzsl0Y272H/XOFP8g7gUeCxqvraBf78RuDRqvrQjOUYfmlk84Z/nqv9Ab4JHN8d/OFC4HmfAJ672CIlTWeeq/0fBX4MPAucGyZ/EbgLuJmdw/4TwGeHi4P7Lcs9vzSylR72r4rhl8a3ssN+SdvJ8EtNGX6pKcMvNWX4paYMv9SU4ZeaMvxSU4ZfasrwS00Zfqkpwy81Zfilpgy/1NTMH/BcsVeB/931/j3DtE20qbVtal1gbYtaZW1/Mu+Ma72f/20rT45V1aHJCtjHpta2qXWBtS1qqto87JeaMvxSU1OH//6J17+fTa1tU+sCa1vUJLVNes4vaTpT7/klTWSS8Ce5PckLSV5Kcs8UNewlyYkkzw4jD086xNgwDNrpJM/tmnZNkseTvDg8X3CYtIlq24iRm/cZWXrSbbdpI16v/bA/yQHg58BtwEngKeCuqvrZWgvZQ5ITwKGqmrxNOMmfA28C/3x+NKQk/wCcqar7hi/Oq6vqCxtS271c5MjNI9W218jSn2HCbbfKEa9XYYo9/y3AS1X1i6r6HfAd4I4J6th4VfUEcOYtk+8Ajg6vj7Lzn2ft9qhtI1TVqap6Znj9BnB+ZOlJt90+dU1iivBfD/xq1/uTbNaQ3wX8IMnTSY5MXcwFXHd+ZKTh+dqJ63mrmSM3r9NbRpbemG23yIjXqzZF+C80msgmNTl8pKr+DPgr4O+Gw1vN5+vAB9gZxu0U8NUpixlGln4I+HxV/XbKWna7QF2TbLcpwn8SuGHX+/cCL09QxwVV1cvD82ng++ycpmySV84Pkjo8n564nj+oqleq6mxVnQO+wYTbbhhZ+iHgX6rqe8PkybfdheqaartNEf6ngJuSvD/JO4FPA49MUMfbJLliuBBDkiuAj7F5ow8/AhweXh8GHp6wlj+yKSM37zWyNBNvu00b8XqSTj5DU8Y/AQeAB6rqy2sv4gKS/Ck7e3vYuePx21PWluRB4FZ27vp6BfgS8G/Ad4H3Ab8EPllVa7/wtkdtt3KRIzePVNteI0s/yYTbbpUjXq+kHnv4ST3Zw09qyvBLTRl+qSnDLzVl+KWmDL/UlOGXmjL8UlP/B6+qHJnAtHZnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 1\n",
      "gx = 18.312946\n",
      "gy = 10.779136\n",
      "stride = 1.5064144\n",
      "sigma = 1.474413\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 2\n",
      "gx = 19.083847\n",
      "gy = 10.357142\n",
      "stride = 1.2599077\n",
      "sigma = 1.9916598\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 3\n",
      "gx = 17.89137\n",
      "gy = 11.197982\n",
      "stride = 1.4606094\n",
      "sigma = 1.8287644\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 4\n",
      "gx = 16.767298\n",
      "gy = 12.080325\n",
      "stride = 1.6189042\n",
      "sigma = 1.6443621\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 5\n",
      "gx = 15.780218\n",
      "gy = 12.903653\n",
      "stride = 1.7061046\n",
      "sigma = 1.4940453\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 6\n",
      "gx = 14.928063\n",
      "gy = 13.766092\n",
      "stride = 1.744165\n",
      "sigma = 1.4205725\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 7\n",
      "gx = 14.102391\n",
      "gy = 14.749211\n",
      "stride = 1.7353474\n",
      "sigma = 1.3989365\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 8\n",
      "gx = 13.270495\n",
      "gy = 15.817057\n",
      "stride = 1.7561693\n",
      "sigma = 1.411804\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 9\n",
      "gx = 12.389395\n",
      "gy = 16.827385\n",
      "stride = 1.704833\n",
      "sigma = 1.45082\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 10\n",
      "gx = 11.635075\n",
      "gy = 17.9718\n",
      "stride = 1.663097\n",
      "sigma = 1.4791523\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 11\n",
      "gx = 10.854857\n",
      "gy = 19.019873\n",
      "stride = 1.5765716\n",
      "sigma = 1.5107323\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEZFJREFUeJzt3X+MVeWdx/HPV34KooIiIGDlV1ZZ3SgS1KqLP7Bx1QRrgql/uJhtdrqxJttEjcZ/NNk00Y1td/9qAkpKQwUboavRddUQW1ZdFSSoUBSHOltmGWZkEAeGH8Mw3/1jDnRmmPM8l/t7eN6vhMy953ufex4u8+Gce55zzmPuLgDpOavWHQBQG4QfSBThBxJF+IFEEX4gUYQfSBThBxJF+IFEEX4gUcOruTIz43RCoMLc3Qp5XUlbfjO7w8y+MLNGM3uilPcCUF1W7Ln9ZjZM0g5Jt0tqlrRR0v3u/sdAG7b8QIVVY8u/QFKju//J3bskrZG0uIT3A1BFpYR/qqRdfZ43Z8v6MbMGM9tkZptKWBeAMivlgN9guxan7Na7+zJJyyR2+4F6UsqWv1nS9D7Pp0naXVp3AFRLKeHfKGmOmc0ws5GSfiDp1fJ0C0ClFb3b7+7dZvawpDclDZO0wt23la1nACqq6KG+olbGd36g4qpykg+AoYvwA4ki/ECiCD+QKMIPJIrwA4ki/ECiCD+QKMIPJIrwA4ki/ECiCD+QKMIPJIrwA4ki/ECiCD+QKMIPJIrwA4ki/ECiCD+QKMIPJIrwA4ki/ECiCD+QKMIPJIrwA4ki/ECiCD+QKMIPJKroKbolycyaJB2QdFxSt7vPL0enAFReSeHP3OLue8vwPgCqiN1+IFGlht8lvWVmH5tZQzk6BKA6St3tv8Hdd5vZRZLeNrPP3X1D3xdk/ynwHwNQZ8zdy/NGZk9LOujuzwVeU56VAcjl7lbI64re7TezsWY27sRjSd+TtLXY9wNQXaXs9k+S9DszO/E+L7r7f5WlVwAqrmy7/QWtjN3+ijjrrPwduBEjRhTdVpKGDw9vHy644IJgPfT7dezYsWDbWN87OjqC9W+++SZYP1NVfLcfwNBG+IFEEX4gUYQfSBThBxJF+IFEleOqPpRozJgxwfrcuXOD9Tlz5uTWZs+eHWwbG6qL1a+77rpgPTTcFhtmjH0uO3bsCNZffvnl3NqqVauCbVPAlh9IFOEHEkX4gUQRfiBRhB9IFOEHEkX4gUQxzl8FsfHqu+66K1h/9NFHg/XLLrsstzZu3Lhg287OzmD96NGjwXrs7zZ69Ojc2qhRo4Jtzz333GD98ssvD9YvueSS3FpjY2Ow7QcffBCsnwnY8gOJIvxAogg/kCjCDySK8AOJIvxAogg/kCjG+csgdovp0Di8JC1ZsiRYX7BgwWn3qVCxcf7YWHxXV1ewHhrnj31uR44cKWndofeP/b1SwJYfSBThBxJF+IFEEX4gUYQfSBThBxJF+IFERcf5zWyFpLsltbn7FdmyCZJeknSppCZJ97n7GT0fcuge89OnTw+2Xbx4cbB+9dVXF9WnE3p6enJr7e3twbbjx48P1ru7u4P12HkCY8eOza3F7gUQ09TUFKzv3bs3txaa60CStm/fHqy3tbUF60NBIVv+X0m6Y8CyJyStd/c5ktZnzwEMIdHwu/sGSfsGLF4saWX2eKWke8rcLwAVVux3/knu3iJJ2c+LytclANVQ8XP7zaxBUkOl1wPg9BS75W81symSlP3MPfrh7svcfb67zy9yXQAqoNjwvyppafZ4qaRXytMdANUSDb+ZrZb0P5L+ysyazeyHkp6RdLuZfSnp9uw5gCEk+p3f3e/PKd1W5r7UtXPOOSe3tnDhwmDbW2+9NVifNm1asB4ba//2229zaxMnTgy2PXz4cLD+xRdflNQ+dN382WefHWx74YUXllSfMGFCbm3y5MnBtrHzF1avXh2sDwWc4QckivADiSL8QKIIP5Aowg8kivADieLW3ZnQJbuSNGPGjNzavffeG2x75ZVXBuvDh4f/GcwsWD/vvPNyawcPHgy2fe2114L12KWtu3btCtZDQ4GhKbQl6YEHHgjWZ86cGayHhmdj03/HhgJj/2ax4dl6wJYfSBThBxJF+IFEEX4gUYQfSBThBxJF+IFEMc6fCU0lLUm33HJLbu3uu+8Oto2Nte/fvz9Yj126+tVXX+XWVq1aFWy7YsWKYL25uTlYL2U8e9GiRcF66NwKKX7r79B5AC0tLcG2b775ZrAeOy9kKBj6fwMARSH8QKIIP5Aowg8kivADiSL8QKIIP5Aoxvkzsamqb7rppqLfu6OjI1gfMWJEsL5169Zg/aWXXsqtPf/888G2oWmspdKvSw+dP3HxxRcH28au94+1P378eG7tqaeeCrb9/PPPg/XYPRaGArb8QKIIP5Aowg8kivADiSL8QKIIP5Aowg8kKjrOb2YrJN0tqc3dr8iWPS3pHyV9nb3sSXf/z0p1shq6urqC9Z07d+bWPvroo2DbYcOGBeuxa8Pfe++9YP3dd9/NrR05ciTYNjSNtSS1tbUF6zG33ZY/k/tDDz0UbHvttdcG6+4erD/33HO5tXXr1gXb9vT0BOtngkK2/L+SdMcgy3/h7ldlf4Z08IEURbf87r7BzC6tfFeGtu88+6zGNDYOWoueDRapT4qcIbgwcJZeZ2dneNWRvY5jwWrc+Pffz61d0tCgQ7Nmqenxx0tcC4pRyum9D5vZ30vaJOkRd/+mTH0aksY0Nmrcp59W5L3zJ53qFT7JNSJwCmxZfBP4tQjVUHHFHvD7paRZkq6S1CLpZ3kvNLMGM9tkZpuKXBeACigq/O7e6u7H3b1H0nJJCwKvXebu8919frGdBFB+Re32m9kUdz9x+9PvSwpfdpag42PG6NDs2ZJK/84fuyqwvZLf+Y+V9q1/4NWSMw4c0JghMINtCgoZ6lst6WZJF5pZs6SnJN1sZldJcklNkn5UwT4OSYdmz9b25cslVX6ob+3atbm1LVu2BNuOHDkyWC91qO+u73633/Nn339ff813/bpQyNH++wdZ/EIF+lJTsS3kK6+8klvbu3ev/qm9XeP6LmtvPxnKefPmBd97z549wfq2bduC9X379uXWpk6dGmwbuy9/zI033hisP/bYY/2eT3v44X4H+saNGxcdz8+zevXqYH3NmjW5tfb29qLWeSbhDD8gUYQfSBThBxJF+IFEEX4gUYQfSBS37s4cPnw4WP/kk09ya62trVrS3q6+E0q3t7efvGx0w4YNwfc+dOhQsB6bwjtUj51jELq9tSTNmjUrWH/wwQeD9YULF/ZfcN55wdf3tX79+mA9dlvyzZs3F7yugWInZsUuJx4K2PIDiSL8QKIIP5Aowg8kivADiSL8QKIIP5AoxvkzsXHb0Fj87t27T7n1d1dXl3bv3i1JamlpGazZSbGx9thtpEPX5A8fHv4nnjlzZrAeuvW2JC1atChYjzl8+LB27dgxaO2FF8JXjr/zzjtFrzc2js84P4AzFuEHEkX4gUQRfiBRhB9IFOEHEkX4gUQxzl+g0HXxeWO+hY4Fjxo1quh1S+Ex6bFjxwbbXn/99cH6nXfeGaxffHF4psCBU4SP7Onpt8Vp37cv97bor7/+evC9SxGbKyF27sWZgC0/kCjCDySK8AOJIvxAogg/kCjCDySK8AOJio7zm9l0Sb+WNFlSj6Rl7v7vZjZB0kuSLpXUJOk+dz9jJ14PXVPf09MjDRzTdz/ZJjZOH6vHhNpfc801wbaxKbanTZsWrH/99dfB+saNG/uvb/9+XTCg/Ysvvjho246OjuB7x4TuZZDCOH5MIVv+bkmPuPvlkq6T9GMzmyvpCUnr3X2OpPXZcwBDRDT87t7i7puzxwckbZc0VdJiSSuzl62UdE+lOgmg/E7rO7+ZXSrpakkfSprk7i1S738Qki4qd+cAVE7B5/ab2TmS1kr6ibt3xO5x1qddg6SG4roHoFIK2vKb2Qj1Bv837r4uW9xqZlOy+hRJbYO1dfdl7j7f3eeXo8MAyiMafuvdxL8gabu7/7xP6VVJS7PHSyUNfmkWgLpUyG7/DZIekPSZmW3Jlj0p6RlJvzWzH0r6s6QllelifQgN9bm7Bl686/rLJb2hW2tL8ctLY1+xZsyYkVubN29esO3EiROD9dhtw3fu3BmsL1++vN/z2Xv29Bvq6+zs1JYtW1SM0aNHB+sDb6fe15lw6+1SRcPv7u9KyvvtC9/UHUDd4gw/IFGEH0gU4QcSRfiBRBF+IFGEH0gUt+4uUGisfdiwYbLu7n6X9ZrZyUttY9Nkx27dHRuLnzt3bm4tduvu0NTjknTs2LFgPTaN9sDbb5/OpZ+xcfzu7u5gPXaOQurY8gOJIvxAogg/kCjCDySK8AOJIvxAogg/kCjG+QsUGud390Fv3X3imvHYePT5558frE+aNClYnzx5cm4tdovqbdu2BetvvfVWsP7GG28E6zFmphE550HEzjHg9tulYcsPJIrwA4ki/ECiCD+QKMIPJIrwA4ki/ECiGOcvg+7u7lPuA+/uJ8f3Q/ePP9E+5ODBg8H6nj17cmu7du0Ktm1tbQ3Wt27dGqzv378/WD9lToIB19j3/ZwG4t76lcWWH0gU4QcSRfiBRBF+IFEc8KuQKyX9PjuQZZEbSY5oaQnWR7W3B+tnf/llbq0nctAsdvHMoc7OcPvIwcqBB+3+JvhqVBPhr5Bz1Tu9saRTjnCf4ujR0uoHDhTYK+Av2O0HEhUNv5lNN7N3zGy7mW0zs3/Olj9tZv9nZluyP3dWvru1c/z48dw/3d3dYkS6eJ7d+2DgH1RWIbv93ZIecffNZjZO0sdm9nZW+4W7P1e57g0dn5XQNnSjkHLUQ2Ihq/TEF6V8bihNNPzu3iKpJXt8wMy2S5pa6Y4NNQ8FarFwxmb0idVHjhyZW4uFN3Z24dHI8QZmxRm6Tus7v5ldKulqSR9mix42s0/NbIWZjc9p02Bmm8xsU0k9BVBWVuh3KzM7R9IfJP3U3deZ2SRJeyW5pH+RNMXd/yHyHkl+kWPLj2py94K+Bxa05TezEZLWSvqNu6/LVtDq7sfdvUfSckkLiu0sgOor5Gi/SXpB0nZ3/3mf5VP6vOz7ksKXfwGoK9HdfjO7UdJ/q/fA7Il9vCcl3S/pKvXu9jdJ+lF2cDD0Xknu9gPVVOhuf8Hf+cuB8AOVV9bv/ADOPIQfSBThBxJF+IFEEX4gUYQfSBThBxJF+IFEEX4gUYQfSBThBxJF+IFEEX4gUYQfSFS1J+3YK+l/+zy/MFtWj+q1b/XaL4m+FaucfftOoS+s6vX8p6zcbJO7z69ZBwLqtW/12i+JvhWrVn1jtx9IFOEHElXr8C+r8fpD6rVv9dovib4VqyZ9q+l3fgC1U+stP4AaqUn4zewOM/vCzBrN7Ila9CGPmTWZ2WfZzMM1nWIsmwatzcy29lk2wczeNrMvs5+DTpNWo77VxczNgZmla/rZ1duM11Xf7TezYZJ2SLpdUrOkjZLud/c/VrUjOcysSdJ8d6/5mLCZ/a2kg5J+7e5XZMv+VdI+d38m+49zvLs/Xid9e1rSwVrP3JxNKDOl78zSku6R9KBq+NkF+nWfavC51WLLv0BSo7v/yd27JK2RtLgG/ah77r5B0r4BixdLWpk9XqneX56qy+lbXXD3FnffnD0+IOnEzNI1/ewC/aqJWoR/qqRdfZ43q76m/HZJb5nZx2bWUOvODGLSiZmRsp8X1bg/A0Vnbq6mATNL181nV8yM1+VWi/APNptIPQ053ODu8yT9naQfZ7u3KMwvJc1S7zRuLZJ+VsvOZDNLr5X0E3fvqGVf+hqkXzX53GoR/mZJ0/s8nyZpdw36MSh33539bJP0O9Xf7MOtJyZJzX621bg/J9XTzM2DzSytOvjs6mnG61qEf6OkOWY2w8xGSvqBpFdr0I9TmNnY7ECMzGyspO+p/mYfflXS0uzxUkmv1LAv/dTLzM15M0urxp9dvc14XZOTfLKhjH+TNEzSCnf/adU7MQgzm6nerb3Ue8Xji7Xsm5mtlnSzeq/6apX0lKT/kPRbSZdI+rOkJe5e9QNvOX27Wac5c3OF+pY3s/SHquFnV84Zr8vSH87wA9LEGX5Aogg/kCjCDySK8AOJIvxAogg/kCjCDySK8AOJ+n/kubLGeCk3FwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 12\n",
      "gx = 10.0989895\n",
      "gy = 20.115328\n",
      "stride = 1.4861465\n",
      "sigma = 1.5818617\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 13\n",
      "gx = 9.44056\n",
      "gy = 21.343363\n",
      "stride = 1.3841561\n",
      "sigma = 1.753924\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 14\n",
      "gx = 8.878112\n",
      "gy = 22.5689\n",
      "stride = 1.1701251\n",
      "sigma = 2.5014536\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G_batch_size=tf.placeholder(shape=(),dtype=tf.int32,name='batch_size')\n",
    "G_init_state_decode=decoder_lstm.zero_state(G_batch_size, tf.float32)\n",
    "G_state_decode=None\n",
    "G_unit_gaussian=tf.distributions.Normal(loc=tf.zeros((G_batch_size,latent_dim)),scale=tf.ones((G_batch_size,latent_dim)))\n",
    "G_canvas=tf.zeros(shape=[G_batch_size,channel,height,width],dtype=tf.float32)\n",
    "\n",
    "G_canvas_his=[]\n",
    "G_write_paras_his=[]\n",
    "for t in range(n_glimpse):\n",
    "    G_Z=G_unit_gaussian.sample()\n",
    "    with tf.variable_scope(\"LSTM_decoder\") as vs:\n",
    "        decoder_out,G_state_decode=decoder_lstm(G_Z,G_init_state_decode if t==0 else G_state_decode)\n",
    "    _gx,_gy,_sigma,_stride,_gamma=decode_attention_para(decoder_out,WRITE_attention_paras)\n",
    "    G_write_paras_his.append((_gx,_gy,_stride,_sigma))\n",
    "    new_patch_image=WRITE_patch(decoder_out)\n",
    "    _FX,_FY=filterbank(G_batch_size,_gx,_gy,_sigma,_stride)\n",
    "    added_image=write(new_patch_image,G_batch_size,_FX,_FY,_gamma)\n",
    "    G_canvas+=added_image\n",
    "    G_canvas_his.append(G_canvas)\n",
    "\n",
    "saver=tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    saver.restore(sess, \"parameters/DRAW/DRAW.ckpt\")\n",
    "    output,paras=sess.run([G_canvas_his,G_write_paras_his],feed_dict={G_batch_size:1})\n",
    "#     images,labels=mnist.test.next_batch(1)\n",
    "#     plt.imshow(images.reshape(28,28),vmin=0,vmax=1,cmap='gray')\n",
    "#     plt.show()\n",
    "#     output,paras,temp=sess.run([canvas_his,write_paras_his,Z],feed_dict={X:images.reshape(-1,1,28,28)})\n",
    "#     print(temp)\n",
    "    for tt in range(n_glimpse):\n",
    "        print('time =',tt)\n",
    "        new_img=output[tt].reshape(28,28)\n",
    "        para=paras[tt]\n",
    "        print('gx =',para[0][0,0])\n",
    "        print('gy =',para[1][0,0])\n",
    "        print('stride =',para[2][0,0])\n",
    "        print('sigma =',np.sqrt(para[3][0,0]))\n",
    "#         print(np.min(new_img),np.max(new_img))\n",
    "#         print(dd)\n",
    "        draw_patch(new_img,para[0][0,0],para[1][0,0],para[2][0,0],np.sqrt(para[3][0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w,b=WRITE_attention_paras.variables\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     tf.global_variables_initializer().run()\n",
    "#     saver.restore(sess, \"parameters/DRAW/DRAW.ckpt\")\n",
    "#     w_out=sess.run(w)\n",
    "#     b_out=sess.run(b)\n",
    "#     print(w_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
