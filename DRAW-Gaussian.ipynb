{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/train-images-idx3-ubyte.gz\n",
      "Extracting mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"mnist/\", one_hot=True)\n",
    "num_train=mnist.train.num_examples\n",
    "num_val=mnist.validation.num_examples\n",
    "num_test=mnist.test.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predefined parameters\n",
    "channel=1\n",
    "height=28\n",
    "width=28\n",
    "patch=7\n",
    "n_glimpse=15\n",
    "lstm_hidden_dim=256\n",
    "latent_dim=512\n",
    "eps=1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "def decode_attention_para(hidden_decode,paser):\n",
    "    '''\n",
    "    calculate parameters(gx,gy,sigma,stride,gamma) from h_dec\n",
    "    each is (batch,1) tensor\n",
    "    '''\n",
    "    paras=paser(hidden_decode)\n",
    "    gx,gy,sigma,stride,gamma=tf.split(paras,[1,1,1,1,1],axis=1)\n",
    "    gx=(gx+1.0)*(width+1)/2.0\n",
    "    gy=(gy+1.0)*(height+1)/2.0\n",
    "    sigma=tf.exp(sigma)\n",
    "    stride=tf.exp(stride)*(max(width,height)-1.0)/(patch-1.0)\n",
    "    gamma=tf.exp(gamma)\n",
    "    return gx,gy,sigma,stride,gamma\n",
    "\n",
    "\n",
    "def filterbank(batch_size,gx,gy,sigma,stride):\n",
    "    '''\n",
    "    calculate filterbank FX and FY using parameters\n",
    "    shape of FX is (batch,channel,patch,width), each tensor in axis=3 is gaussian distribution centered at gx and scale is sigma\n",
    "    shape of FY is (batch,channel,patch,height), similar to FX\n",
    "    '''\n",
    "    # initialize FY, shape=(batch,patch,height), value is multipling range(height) for (batch*patch) times\n",
    "    FY=tf.tile(tf.reshape(tf.range(height,dtype=tf.float32),(1,1,height)),multiples=(batch_size,patch,1))\n",
    "    # center position, shape=(batch,patch), value is like (-2stride+gy,-stride+gy,gy,stride+gy,2stride+gy) for all batches\n",
    "    py=tf.tile(tf.reshape(tf.range(patch,dtype=tf.float32)-(patch-1)//2,(1,patch)),multiples=(batch_size,1))*stride+gy\n",
    "    # gaussian distribution of FY, shape is the same as FY, value is gaussian for all batches\n",
    "    FY=tf.exp(-tf.square(FY-tf.reshape(py,(-1,patch,1)))/2.0*tf.reshape(sigma,(-1,1,1)))   # modified\n",
    "    # normalized FY, shape=(batch,patch,height), each vector is sumed to 1\n",
    "    FY/=(eps+tf.reduce_sum(FY,axis=2,keep_dims=True))   # modified: add eps for numerical stability\n",
    "    # copy through all channels, shape=(batch,channel,patch,height)\n",
    "    FY=tf.tile(tf.reshape(FY,[-1,1,patch,height]),(1,channel,1,1))\n",
    "    \n",
    "    FX=tf.tile(tf.reshape(tf.range(width,dtype=tf.float32),(1,1,width)),multiples=(batch_size,patch,1))\n",
    "    px=tf.tile(tf.reshape(tf.range(patch,dtype=tf.float32)-(patch-1)//2,(1,patch)),multiples=(batch_size,1))*stride+gx\n",
    "    FX=tf.exp(-tf.square(FX-tf.reshape(px,(-1,patch,1)))/2.0*tf.reshape(sigma,(-1,1,1)))   # modified\n",
    "    FX/=(eps+tf.reduce_sum(FX,axis=2,keep_dims=True))   # modified\n",
    "    FX=tf.tile(tf.reshape(FX,[-1,1,patch,width]),(1,channel,1,1))\n",
    "    return FX,FY\n",
    "\n",
    "def read(image,FX,FY,gamma):\n",
    "    '''\n",
    "    Inputs:\n",
    "    image, shape=(batch,channel,height,width)\n",
    "    filterbank FX, shape=(batch,channel,patch,width)\n",
    "    filterbank FY, shape=(batch,channel,patch,height)\n",
    "    scale intensity gamma, shape=(batch,1)\n",
    "    \n",
    "    Outputs:\n",
    "    encoded patch, shape=(batch,channel*patch*patch)\n",
    "    '''\n",
    "    patch_image=tf.matmul(tf.matmul(FY,X),FX,transpose_b=True)*tf.reshape(gamma,(-1,1,1,1))\n",
    "    patch_image=tf.layers.flatten(patch_image)\n",
    "    return patch_image\n",
    "    \n",
    "def write(pat,batch_size,FX,FY,gamma):\n",
    "    '''\n",
    "    Inputs:\n",
    "    pat, patch decode from hidden, shape=(batch,channel*patch*patch)\n",
    "    filterbank FX, shape=(batch,channel,patch,width)\n",
    "    filterbank FY, shape=(batch,channel,patch,height)\n",
    "    scale intensity gamma, shape=(batch,1)\n",
    "    \n",
    "    Outputs:\n",
    "    decoded image, shape=(batch,channel,height,width)\n",
    "    '''\n",
    "    pat=tf.reshape(pat,(batch_size,channel,patch,patch))\n",
    "    reconstruct_image=tf.matmul(tf.matmul(FY,pat,transpose_a=True),FX)/tf.reshape(gamma,(-1,1,1,1))\n",
    "    return reconstruct_image\n",
    "\n",
    "def logistic_likelihood(original_image,recon_image):\n",
    "    return -(original_image*tf.log(eps+recon_image)+(1.0-original_image)*tf.log(1.0-recon_image))\n",
    "\n",
    "\n",
    "# input\n",
    "X=tf.placeholder(shape=[None,channel,height,width],dtype=tf.float32,name='input_image')\n",
    "batch_size=tf.shape(X)[0]\n",
    "canvas=tf.zeros(shape=[batch_size,channel,height,width],dtype=tf.float32,name='output_canvas')\n",
    "\n",
    "READ_attention_paras=tf.layers.Dense(units=5,name='attention_para_read')   # calculate parameters for READ operation\n",
    "WRITE_attention_paras=tf.layers.Dense(units=5,name='attention_para_write')   # calculate parameters for WRITE operation\n",
    "WRITE_patch=tf.layers.Dense(units=channel*patch*patch,name='patch_write')   # calculate patch_image for WRITE operation\n",
    "encoder_lstm=tf.contrib.rnn.LSTMCell(lstm_hidden_dim)\n",
    "decoder_lstm=tf.contrib.rnn.LSTMCell(lstm_hidden_dim)\n",
    "init_state_encode=encoder_lstm.zero_state(batch_size, tf.float32)   # lstm tuple (c,h)\n",
    "init_state_decode=decoder_lstm.zero_state(batch_size, tf.float32)   # lstm tuple (c,h)\n",
    "state_encode=None\n",
    "state_decode=None\n",
    "encoder_mean=tf.layers.Dense(units=latent_dim,name='encoder_mean')   # calculate mean of z\n",
    "encoder_std=tf.layers.Dense(units=latent_dim,name='encoder_std')   # calculate std of z\n",
    "unit_gaussian=tf.distributions.Normal(loc=tf.zeros(latent_dim),scale=tf.ones(latent_dim),name='unit_norm')\n",
    "\n",
    "read_paras_his=[]\n",
    "write_paras_his=[]\n",
    "canvas_his=[]\n",
    "latent_loss_his=[]\n",
    "likelihood_loss_his=[]\n",
    "\n",
    "for t in range(n_glimpse):\n",
    "    error_image=X-canvas\n",
    "    previous_hidden_decode=init_state_decode[1] if t==0 else state_decode[1]\n",
    "    gx,gy,sigma,stride,gamma=decode_attention_para(previous_hidden_decode,READ_attention_paras)\n",
    "    read_paras_his.append((gx,gy,stride,sigma))\n",
    "    FX,FY=filterbank(batch_size,gx,gy,sigma,stride)\n",
    "    patch_image=read(X,FX,FY,gamma)\n",
    "    patch_error_image=read(error_image,FX,FY,gamma)\n",
    "    encoder_input=tf.concat([patch_image,patch_error_image,previous_hidden_decode],axis=1)\n",
    "    with tf.variable_scope(\"LSTM_encoder\") as vs:\n",
    "        encoder_out,state_encode=encoder_lstm(encoder_input,init_state_encode if t==0 else state_encode)\n",
    "    z_mean=encoder_mean(encoder_out)\n",
    "    z_std=tf.exp(encoder_std(encoder_out))\n",
    "    distrib_encode=tf.distributions.Normal(loc=z_mean,scale=z_std)\n",
    "    Z=distrib_encode.sample()\n",
    "    \n",
    "    latent_loss=tf.reduce_sum(tf.distributions.kl_divergence(distrib_encode,unit_gaussian),axis=1)\n",
    "    latent_loss_his.append(latent_loss)\n",
    "    \n",
    "    with tf.variable_scope(\"LSTM_decoder\") as vs:\n",
    "        decoder_out,state_decode=decoder_lstm(Z,init_state_decode if t==0 else state_decode)\n",
    "    _gx,_gy,_sigma,_stride,_gamma=decode_attention_para(decoder_out,WRITE_attention_paras)\n",
    "    write_paras_his.append((_gx,_gy,_stride,_sigma))\n",
    "    new_patch_image=WRITE_patch(decoder_out)\n",
    "    _FX,_FY=filterbank(batch_size,_gx,_gy,_sigma,_stride)\n",
    "    added_image=write(new_patch_image,batch_size,_FX,_FY,_gamma)\n",
    "    canvas+=added_image\n",
    "    \n",
    "    canvas_his.append(canvas)\n",
    "    \n",
    "total_latent_loss=tf.reduce_mean(latent_loss_his)\n",
    "total_likelihood_loss=tf.reduce_mean(tf.reduce_sum(tf.square(tf.layers.flatten(X)-tf.layers.flatten(canvas)),axis=1))\n",
    "total_loss=total_latent_loss+total_likelihood_loss\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "starter_learning_rate = 4e-3\n",
    "learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,num_train//128, 0.9, staircase=True)\n",
    "optimizier=tf.train.RMSPropOptimizer(learning_rate=starter_learning_rate)\n",
    "train_step = optimizier.minimize(total_loss,global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-07 20:39:16 start epoch 1/100, with learning rate = 0.0040000002\n",
      "2018-05-07 20:39:21 iteration 1/429: current training loss = 97.799622 (=3.290576+94.509048)\n",
      "2018-05-07 20:39:26 iteration 50/429: current training loss = 62.678135 (=1.711605+60.966530)\n",
      "2018-05-07 20:39:31 iteration 100/429: current training loss = 51.812996 (=1.103319+50.709679)\n",
      "2018-05-07 20:39:36 iteration 150/429: current training loss = 45.614059 (=1.382624+44.231434)\n",
      "2018-05-07 20:39:42 iteration 200/429: current training loss = 40.387951 (=1.752927+38.635025)\n",
      "2018-05-07 20:39:47 iteration 250/429: current training loss = 38.836876 (=2.272507+36.564369)\n",
      "2018-05-07 20:39:52 iteration 300/429: current training loss = 34.821175 (=2.327411+32.493763)\n",
      "2018-05-07 20:39:57 iteration 350/429: current training loss = 31.631088 (=2.189521+29.441566)\n",
      "2018-05-07 20:40:02 iteration 400/429: current training loss = 32.664371 (=2.514709+30.149662)\n",
      "2018-05-07 20:40:05 iteration 429/429: current training loss = 34.148708 (=2.617685+31.531025)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 20:40:23 end epoch 1/100: loss_train=35.034771 loss_val=35.169053 loss_test=34.963312\n",
      "\n",
      "2018-05-07 20:40:23 start epoch 2/100, with learning rate = 0.0036000002\n",
      "2018-05-07 20:40:24 iteration 1/429: current training loss = 36.975895 (=2.379570+34.596325)\n",
      "2018-05-07 20:40:29 iteration 50/429: current training loss = 31.628860 (=2.569614+29.059246)\n",
      "2018-05-07 20:40:34 iteration 100/429: current training loss = 29.402742 (=2.837030+26.565712)\n",
      "2018-05-07 20:40:39 iteration 150/429: current training loss = 28.654222 (=2.824451+25.829771)\n",
      "2018-05-07 20:40:45 iteration 200/429: current training loss = 30.610304 (=2.494391+28.115913)\n",
      "2018-05-07 20:40:50 iteration 250/429: current training loss = 30.070751 (=2.903073+27.167679)\n",
      "2018-05-07 20:40:55 iteration 300/429: current training loss = 29.085680 (=2.683665+26.402016)\n",
      "2018-05-07 20:41:00 iteration 350/429: current training loss = 25.302572 (=2.761977+22.540596)\n",
      "2018-05-07 20:41:05 iteration 400/429: current training loss = 28.301264 (=2.990973+25.310291)\n",
      "2018-05-07 20:41:08 iteration 429/429: current training loss = 26.777699 (=2.892802+23.884895)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 20:41:24 end epoch 2/100: loss_train=26.216486 loss_val=26.017560 loss_test=25.934020\n",
      "\n",
      "2018-05-07 20:41:24 start epoch 3/100, with learning rate = 0.0032400000\n",
      "2018-05-07 20:41:25 iteration 1/429: current training loss = 26.413826 (=3.114606+23.299219)\n",
      "2018-05-07 20:41:30 iteration 50/429: current training loss = 26.643644 (=2.995483+23.648161)\n",
      "2018-05-07 20:41:35 iteration 100/429: current training loss = 29.036621 (=2.882668+26.153954)\n",
      "2018-05-07 20:41:40 iteration 150/429: current training loss = 24.781500 (=2.993554+21.787947)\n",
      "2018-05-07 20:41:46 iteration 200/429: current training loss = 24.620731 (=3.335011+21.285721)\n",
      "2018-05-07 20:41:51 iteration 250/429: current training loss = 24.630606 (=3.226711+21.403894)\n",
      "2018-05-07 20:41:56 iteration 300/429: current training loss = 24.422012 (=3.001327+21.420685)\n",
      "2018-05-07 20:42:02 iteration 350/429: current training loss = 23.097992 (=3.104721+19.993271)\n",
      "2018-05-07 20:42:07 iteration 400/429: current training loss = 24.630665 (=3.071439+21.559225)\n",
      "2018-05-07 20:42:10 iteration 429/429: current training loss = 24.784206 (=3.182762+21.601444)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 20:42:27 end epoch 3/100: loss_train=24.183109 loss_val=24.078827 loss_test=23.875684\n",
      "\n",
      "2018-05-07 20:42:27 start epoch 4/100, with learning rate = 0.0029160001\n",
      "2018-05-07 20:42:27 iteration 1/429: current training loss = 25.534962 (=3.334397+22.200565)\n",
      "2018-05-07 20:42:32 iteration 50/429: current training loss = 24.775112 (=3.064413+21.710699)\n",
      "2018-05-07 20:42:38 iteration 100/429: current training loss = 26.055157 (=3.229125+22.826033)\n",
      "2018-05-07 20:42:43 iteration 150/429: current training loss = 24.320654 (=3.185644+21.135010)\n",
      "2018-05-07 20:42:48 iteration 200/429: current training loss = 24.515463 (=3.530491+20.984972)\n",
      "2018-05-07 20:42:53 iteration 250/429: current training loss = 23.535837 (=3.168532+20.367306)\n",
      "2018-05-07 20:42:58 iteration 300/429: current training loss = 24.094116 (=3.280622+20.813496)\n",
      "2018-05-07 20:43:03 iteration 350/429: current training loss = 22.853861 (=3.131126+19.722734)\n",
      "2018-05-07 20:43:08 iteration 400/429: current training loss = 22.525282 (=3.196856+19.328426)\n",
      "2018-05-07 20:43:11 iteration 429/429: current training loss = 23.116144 (=3.158316+19.957829)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 20:43:28 end epoch 4/100: loss_train=22.852934 loss_val=22.680756 loss_test=22.613328\n",
      "\n",
      "2018-05-07 20:43:28 start epoch 5/100, with learning rate = 0.0026243995\n",
      "2018-05-07 20:43:28 iteration 1/429: current training loss = 21.958578 (=3.139759+18.818819)\n",
      "2018-05-07 20:43:33 iteration 50/429: current training loss = 22.012489 (=3.223058+18.789433)\n",
      "2018-05-07 20:43:38 iteration 100/429: current training loss = 21.963051 (=3.337714+18.625336)\n",
      "2018-05-07 20:43:43 iteration 150/429: current training loss = 22.579924 (=2.917360+19.662563)\n",
      "2018-05-07 20:43:48 iteration 200/429: current training loss = 23.687817 (=3.346431+20.341387)\n",
      "2018-05-07 20:43:53 iteration 250/429: current training loss = 22.198240 (=3.286903+18.911337)\n",
      "2018-05-07 20:43:59 iteration 300/429: current training loss = 22.540733 (=3.277519+19.263214)\n",
      "2018-05-07 20:44:04 iteration 350/429: current training loss = 23.372128 (=3.280007+20.092121)\n",
      "2018-05-07 20:44:09 iteration 400/429: current training loss = 23.330465 (=3.237661+20.092804)\n",
      "2018-05-07 20:44:12 iteration 429/429: current training loss = 22.032909 (=3.332591+18.700317)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 20:44:30 end epoch 5/100: loss_train=21.769415 loss_val=21.582299 loss_test=21.481265\n",
      "\n",
      "2018-05-07 20:44:30 start epoch 6/100, with learning rate = 0.0023619598\n",
      "2018-05-07 20:44:30 iteration 1/429: current training loss = 21.911112 (=3.455790+18.455322)\n",
      "2018-05-07 20:44:35 iteration 50/429: current training loss = 22.277115 (=3.428913+18.848202)\n",
      "2018-05-07 20:44:41 iteration 100/429: current training loss = 22.802126 (=3.225887+19.576239)\n",
      "2018-05-07 20:44:46 iteration 150/429: current training loss = 21.242207 (=3.120503+18.121704)\n",
      "2018-05-07 20:44:52 iteration 200/429: current training loss = 23.902538 (=3.228615+20.673923)\n",
      "2018-05-07 20:44:57 iteration 250/429: current training loss = 21.308285 (=3.344513+17.963772)\n",
      "2018-05-07 20:45:02 iteration 300/429: current training loss = 20.665049 (=3.279581+17.385468)\n",
      "2018-05-07 20:45:08 iteration 350/429: current training loss = 21.356104 (=3.338266+18.017838)\n",
      "2018-05-07 20:45:13 iteration 400/429: current training loss = 22.443241 (=3.268912+19.174330)\n",
      "2018-05-07 20:45:16 iteration 429/429: current training loss = 22.479549 (=3.489200+18.990349)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 20:45:33 end epoch 6/100: loss_train=21.582074 loss_val=21.401196 loss_test=21.314387\n",
      "\n",
      "2018-05-07 20:45:33 start epoch 7/100, with learning rate = 0.0021257640\n",
      "2018-05-07 20:45:33 iteration 1/429: current training loss = 22.019682 (=3.329261+18.690422)\n",
      "2018-05-07 20:45:38 iteration 50/429: current training loss = 23.631618 (=3.460181+20.171436)\n",
      "2018-05-07 20:45:43 iteration 100/429: current training loss = 21.213228 (=3.283514+17.929714)\n",
      "2018-05-07 20:45:49 iteration 150/429: current training loss = 21.006144 (=3.316167+17.689976)\n",
      "2018-05-07 20:45:54 iteration 200/429: current training loss = 22.261732 (=3.292744+18.968988)\n",
      "2018-05-07 20:45:59 iteration 250/429: current training loss = 22.223818 (=3.514936+18.708881)\n",
      "2018-05-07 20:46:04 iteration 300/429: current training loss = 21.919703 (=3.338717+18.580986)\n",
      "2018-05-07 20:46:10 iteration 350/429: current training loss = 20.414417 (=3.388686+17.025732)\n",
      "2018-05-07 20:46:15 iteration 400/429: current training loss = 20.563236 (=3.346454+17.216782)\n",
      "2018-05-07 20:46:18 iteration 429/429: current training loss = 21.004608 (=3.389302+17.615305)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 20:46:34 end epoch 7/100: loss_train=20.957824 loss_val=20.860772 loss_test=20.712005\n",
      "\n",
      "2018-05-07 20:46:34 start epoch 8/100, with learning rate = 0.0019131873\n",
      "2018-05-07 20:46:34 iteration 1/429: current training loss = 20.790667 (=3.479853+17.310814)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-07 20:46:40 iteration 50/429: current training loss = 22.650192 (=3.599918+19.050274)\n",
      "2018-05-07 20:46:45 iteration 100/429: current training loss = 20.190762 (=3.357594+16.833168)\n",
      "2018-05-07 20:46:50 iteration 150/429: current training loss = 20.926231 (=3.262198+17.664032)\n",
      "2018-05-07 20:46:55 iteration 200/429: current training loss = 21.448425 (=3.459251+17.989174)\n",
      "2018-05-07 20:47:01 iteration 250/429: current training loss = 20.876438 (=3.669234+17.207205)\n",
      "2018-05-07 20:47:06 iteration 300/429: current training loss = 22.031912 (=3.411911+18.620001)\n",
      "2018-05-07 20:47:11 iteration 350/429: current training loss = 21.411520 (=3.354093+18.057426)\n",
      "2018-05-07 20:47:17 iteration 400/429: current training loss = 23.151600 (=3.456840+19.694759)\n",
      "2018-05-07 20:47:20 iteration 429/429: current training loss = 21.959116 (=3.408160+18.550957)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 20:47:36 end epoch 8/100: loss_train=21.383095 loss_val=21.300689 loss_test=21.040670\n",
      "\n",
      "2018-05-07 20:47:36 start epoch 9/100, with learning rate = 0.0017218685\n",
      "2018-05-07 20:47:36 iteration 1/429: current training loss = 21.825226 (=3.605312+18.219913)\n",
      "2018-05-07 20:47:42 iteration 50/429: current training loss = 21.448915 (=3.486706+17.962210)\n",
      "2018-05-07 20:47:47 iteration 100/429: current training loss = 19.496418 (=3.246629+16.249790)\n",
      "2018-05-07 20:47:52 iteration 150/429: current training loss = 24.194752 (=3.560837+20.633915)\n",
      "2018-05-07 20:47:58 iteration 200/429: current training loss = 19.961859 (=3.406500+16.555359)\n",
      "2018-05-07 20:48:03 iteration 250/429: current training loss = 20.801424 (=3.382412+17.419012)\n",
      "2018-05-07 20:48:08 iteration 300/429: current training loss = 21.973289 (=3.387385+18.585905)\n",
      "2018-05-07 20:48:13 iteration 350/429: current training loss = 21.460117 (=3.369027+18.091089)\n",
      "2018-05-07 20:48:19 iteration 400/429: current training loss = 21.087337 (=3.418141+17.669197)\n",
      "2018-05-07 20:48:22 iteration 429/429: current training loss = 20.533634 (=3.574747+16.958887)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 20:48:38 end epoch 9/100: loss_train=20.598230 loss_val=20.405834 loss_test=20.402267\n",
      "\n",
      "2018-05-07 20:48:38 start epoch 10/100, with learning rate = 0.0015496816\n",
      "2018-05-07 20:48:38 iteration 1/429: current training loss = 20.168705 (=3.189283+16.979422)\n",
      "2018-05-07 20:48:44 iteration 50/429: current training loss = 20.938620 (=3.461120+17.477499)\n",
      "2018-05-07 20:48:49 iteration 100/429: current training loss = 22.497154 (=3.567402+18.929752)\n",
      "2018-05-07 20:48:55 iteration 150/429: current training loss = 20.675329 (=3.475664+17.199665)\n",
      "2018-05-07 20:49:00 iteration 200/429: current training loss = 19.817514 (=3.513216+16.304298)\n",
      "2018-05-07 20:49:05 iteration 250/429: current training loss = 19.917828 (=3.369672+16.548155)\n",
      "2018-05-07 20:49:11 iteration 300/429: current training loss = 20.479626 (=3.527231+16.952394)\n",
      "2018-05-07 20:49:16 iteration 350/429: current training loss = 22.006966 (=3.593380+18.413586)\n",
      "2018-05-07 20:49:21 iteration 400/429: current training loss = 20.053062 (=3.538196+16.514866)\n",
      "2018-05-07 20:49:24 iteration 429/429: current training loss = 21.169968 (=3.504846+17.665121)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 20:49:41 end epoch 10/100: loss_train=20.866174 loss_val=20.765930 loss_test=20.611782\n",
      "\n",
      "2018-05-07 20:49:41 start epoch 11/100, with learning rate = 0.0013947133\n",
      "2018-05-07 20:49:41 iteration 1/429: current training loss = 20.974022 (=3.407581+17.566441)\n",
      "2018-05-07 20:49:46 iteration 50/429: current training loss = 21.232128 (=3.354896+17.877232)\n",
      "2018-05-07 20:49:51 iteration 100/429: current training loss = 19.961706 (=3.646579+16.315128)\n",
      "2018-05-07 20:49:57 iteration 150/429: current training loss = 20.548840 (=3.374227+17.174612)\n",
      "2018-05-07 20:50:02 iteration 200/429: current training loss = 19.750618 (=3.522483+16.228136)\n",
      "2018-05-07 20:50:07 iteration 250/429: current training loss = 20.207653 (=3.348234+16.859419)\n",
      "2018-05-07 20:50:13 iteration 300/429: current training loss = 20.875114 (=3.702058+17.173058)\n",
      "2018-05-07 20:50:18 iteration 350/429: current training loss = 19.062910 (=3.467063+15.595846)\n",
      "2018-05-07 20:50:24 iteration 400/429: current training loss = 20.362801 (=3.490129+16.872673)\n",
      "2018-05-07 20:50:27 iteration 429/429: current training loss = 19.927496 (=3.543654+16.383842)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 20:50:43 end epoch 11/100: loss_train=19.958247 loss_val=19.810371 loss_test=19.639669\n",
      "\n",
      "2018-05-07 20:50:43 start epoch 12/100, with learning rate = 0.0012552420\n",
      "2018-05-07 20:50:43 iteration 1/429: current training loss = 19.707325 (=3.627178+16.080147)\n",
      "2018-05-07 20:50:49 iteration 50/429: current training loss = 20.760338 (=3.660532+17.099806)\n",
      "2018-05-07 20:50:54 iteration 100/429: current training loss = 20.944597 (=3.627944+17.316654)\n",
      "2018-05-07 20:50:59 iteration 150/429: current training loss = 21.060036 (=3.614293+17.445742)\n",
      "2018-05-07 20:51:05 iteration 200/429: current training loss = 19.929855 (=3.624364+16.305492)\n",
      "2018-05-07 20:51:10 iteration 250/429: current training loss = 21.189741 (=3.548236+17.641504)\n",
      "2018-05-07 20:51:15 iteration 300/429: current training loss = 19.898523 (=3.536879+16.361645)\n",
      "2018-05-07 20:51:21 iteration 350/429: current training loss = 20.225092 (=3.614164+16.610928)\n",
      "2018-05-07 20:51:26 iteration 400/429: current training loss = 19.399403 (=3.581548+15.817854)\n",
      "2018-05-07 20:51:29 iteration 429/429: current training loss = 19.381958 (=3.531761+15.850197)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 20:51:46 end epoch 12/100: loss_train=20.229816 loss_val=20.051149 loss_test=20.040019\n",
      "\n",
      "2018-05-07 20:51:46 start epoch 13/100, with learning rate = 0.0011297178\n",
      "2018-05-07 20:51:46 iteration 1/429: current training loss = 20.126766 (=3.627041+16.499725)\n",
      "2018-05-07 20:51:52 iteration 50/429: current training loss = 19.342215 (=3.945968+15.396246)\n",
      "2018-05-07 20:51:57 iteration 100/429: current training loss = 19.300636 (=3.505647+15.794991)\n",
      "2018-05-07 20:52:02 iteration 150/429: current training loss = 18.575863 (=3.649763+14.926100)\n",
      "2018-05-07 20:52:08 iteration 200/429: current training loss = 19.348951 (=3.464704+15.884247)\n",
      "2018-05-07 20:52:13 iteration 250/429: current training loss = 19.496510 (=3.612196+15.884314)\n",
      "2018-05-07 20:52:18 iteration 300/429: current training loss = 20.540936 (=3.786992+16.753944)\n",
      "2018-05-07 20:52:24 iteration 350/429: current training loss = 20.201237 (=3.748574+16.452662)\n",
      "2018-05-07 20:52:29 iteration 400/429: current training loss = 19.011211 (=3.426016+15.585195)\n",
      "2018-05-07 20:52:32 iteration 429/429: current training loss = 20.680420 (=3.516912+17.163509)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 20:52:49 end epoch 13/100: loss_train=21.498382 loss_val=21.257690 loss_test=21.273695\n",
      "\n",
      "2018-05-07 20:52:49 start epoch 14/100, with learning rate = 0.0010167459\n",
      "2018-05-07 20:52:49 iteration 1/429: current training loss = 21.065638 (=3.593534+17.472103)\n",
      "2018-05-07 20:52:54 iteration 50/429: current training loss = 19.519966 (=3.506622+16.013344)\n",
      "2018-05-07 20:52:59 iteration 100/429: current training loss = 19.836132 (=3.712801+16.123331)\n",
      "2018-05-07 20:53:04 iteration 150/429: current training loss = 19.478504 (=3.560318+15.918186)\n",
      "2018-05-07 20:53:10 iteration 200/429: current training loss = 20.048637 (=3.927117+16.121521)\n",
      "2018-05-07 20:53:15 iteration 250/429: current training loss = 20.337082 (=3.494226+16.842855)\n",
      "2018-05-07 20:53:20 iteration 300/429: current training loss = 19.560661 (=3.681602+15.879061)\n",
      "2018-05-07 20:53:26 iteration 350/429: current training loss = 19.847946 (=3.385197+16.462749)\n",
      "2018-05-07 20:53:31 iteration 400/429: current training loss = 18.757151 (=3.701070+15.056082)\n",
      "2018-05-07 20:53:34 iteration 429/429: current training loss = 19.405317 (=3.787855+15.617462)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 20:53:50 end epoch 14/100: loss_train=19.069676 loss_val=18.897042 loss_test=18.842414\n",
      "\n",
      "2018-05-07 20:53:50 start epoch 15/100, with learning rate = 0.0009150714\n",
      "2018-05-07 20:53:51 iteration 1/429: current training loss = 18.379881 (=3.636269+14.743611)\n",
      "2018-05-07 20:53:56 iteration 50/429: current training loss = 18.311310 (=3.599312+14.711998)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-07 20:54:01 iteration 100/429: current training loss = 19.456722 (=3.809013+15.647708)\n",
      "2018-05-07 20:54:06 iteration 150/429: current training loss = 19.319117 (=3.679306+15.639811)\n",
      "2018-05-07 20:54:12 iteration 200/429: current training loss = 18.186138 (=3.521261+14.664877)\n",
      "2018-05-07 20:54:17 iteration 250/429: current training loss = 19.520113 (=3.672088+15.848025)\n",
      "2018-05-07 20:54:22 iteration 300/429: current training loss = 18.368420 (=3.573988+14.794432)\n",
      "2018-05-07 20:54:28 iteration 350/429: current training loss = 17.679321 (=3.483840+14.195481)\n",
      "2018-05-07 20:54:34 iteration 400/429: current training loss = 18.928278 (=3.830883+15.097395)\n",
      "2018-05-07 20:54:37 iteration 429/429: current training loss = 19.124153 (=3.564986+15.559168)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 20:54:53 end epoch 15/100: loss_train=19.521045 loss_val=19.423805 loss_test=19.333286\n",
      "\n",
      "2018-05-07 20:54:53 start epoch 16/100, with learning rate = 0.0008235642\n",
      "2018-05-07 20:54:53 iteration 1/429: current training loss = 19.329184 (=3.527251+15.801931)\n",
      "2018-05-07 20:54:59 iteration 50/429: current training loss = 19.561344 (=3.867099+15.694246)\n",
      "2018-05-07 20:55:04 iteration 100/429: current training loss = 18.065962 (=3.458930+14.607031)\n",
      "2018-05-07 20:55:09 iteration 150/429: current training loss = 19.088972 (=3.782149+15.306824)\n",
      "2018-05-07 20:55:14 iteration 200/429: current training loss = 19.599609 (=4.135328+15.464282)\n",
      "2018-05-07 20:55:20 iteration 250/429: current training loss = 19.438501 (=3.426589+16.011913)\n",
      "2018-05-07 20:55:25 iteration 300/429: current training loss = 17.969990 (=3.529884+14.440105)\n",
      "2018-05-07 20:55:30 iteration 350/429: current training loss = 19.206898 (=3.416030+15.790867)\n",
      "2018-05-07 20:55:35 iteration 400/429: current training loss = 18.293787 (=4.016817+14.276970)\n",
      "2018-05-07 20:55:38 iteration 429/429: current training loss = 18.265171 (=3.851676+14.413496)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 20:55:55 end epoch 16/100: loss_train=18.662016 loss_val=18.468518 loss_test=18.415443\n",
      "\n",
      "2018-05-07 20:55:55 start epoch 17/100, with learning rate = 0.0007412078\n",
      "2018-05-07 20:55:55 iteration 1/429: current training loss = 17.967152 (=3.629171+14.337980)\n",
      "2018-05-07 20:56:00 iteration 50/429: current training loss = 18.411837 (=3.591283+14.820553)\n",
      "2018-05-07 20:56:06 iteration 100/429: current training loss = 18.741457 (=3.771396+14.970061)\n",
      "2018-05-07 20:56:12 iteration 150/429: current training loss = 18.716629 (=3.650100+15.066530)\n",
      "2018-05-07 20:56:17 iteration 200/429: current training loss = 17.236954 (=3.601054+13.635899)\n",
      "2018-05-07 20:56:23 iteration 250/429: current training loss = 19.415529 (=3.567304+15.848226)\n",
      "2018-05-07 20:56:28 iteration 300/429: current training loss = 18.200323 (=3.567212+14.633112)\n",
      "2018-05-07 20:56:34 iteration 350/429: current training loss = 18.799692 (=3.736663+15.063028)\n",
      "2018-05-07 20:56:39 iteration 400/429: current training loss = 18.259468 (=3.858689+14.400780)\n",
      "2018-05-07 20:56:42 iteration 429/429: current training loss = 19.487589 (=3.834944+15.652645)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 20:56:59 end epoch 17/100: loss_train=20.034827 loss_val=20.164704 loss_test=19.690009\n",
      "\n",
      "2018-05-07 20:56:59 start epoch 18/100, with learning rate = 0.0006670870\n",
      "2018-05-07 20:56:59 iteration 1/429: current training loss = 19.756147 (=3.712830+16.043318)\n",
      "2018-05-07 20:57:04 iteration 50/429: current training loss = 18.812073 (=3.762347+15.049726)\n",
      "2018-05-07 20:57:10 iteration 100/429: current training loss = 19.225679 (=3.724236+15.501443)\n",
      "2018-05-07 20:57:15 iteration 150/429: current training loss = 19.360016 (=3.683820+15.676197)\n",
      "2018-05-07 20:57:20 iteration 200/429: current training loss = 18.407835 (=3.682573+14.725262)\n",
      "2018-05-07 20:57:25 iteration 250/429: current training loss = 18.444324 (=3.593060+14.851265)\n",
      "2018-05-07 20:57:30 iteration 300/429: current training loss = 18.306526 (=3.514022+14.792504)\n",
      "2018-05-07 20:57:35 iteration 350/429: current training loss = 17.707058 (=3.780547+13.926512)\n",
      "2018-05-07 20:57:41 iteration 400/429: current training loss = 18.016573 (=3.763478+14.253096)\n",
      "2018-05-07 20:57:44 iteration 429/429: current training loss = 17.636965 (=3.524744+14.112221)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 20:58:00 end epoch 18/100: loss_train=18.057900 loss_val=17.876607 loss_test=17.835042\n",
      "\n",
      "2018-05-07 20:58:00 start epoch 19/100, with learning rate = 0.0006003783\n",
      "2018-05-07 20:58:00 iteration 1/429: current training loss = 18.141150 (=3.711713+14.429436)\n",
      "2018-05-07 20:58:06 iteration 50/429: current training loss = 18.120388 (=3.956395+14.163994)\n",
      "2018-05-07 20:58:11 iteration 100/429: current training loss = 18.578989 (=3.764048+14.814941)\n",
      "2018-05-07 20:58:16 iteration 150/429: current training loss = 19.370663 (=4.321886+15.048776)\n",
      "2018-05-07 20:58:21 iteration 200/429: current training loss = 18.974447 (=3.671327+15.303120)\n",
      "2018-05-07 20:58:26 iteration 250/429: current training loss = 18.682402 (=3.805520+14.876882)\n",
      "2018-05-07 20:58:32 iteration 300/429: current training loss = 17.064032 (=3.590492+13.473539)\n",
      "2018-05-07 20:58:37 iteration 350/429: current training loss = 16.340927 (=3.676348+12.664579)\n",
      "2018-05-07 20:58:42 iteration 400/429: current training loss = 17.559931 (=3.713211+13.846720)\n",
      "2018-05-07 20:58:45 iteration 429/429: current training loss = 16.277729 (=3.452146+12.825584)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 20:59:02 end epoch 19/100: loss_train=18.761388 loss_val=18.495996 loss_test=18.601326\n",
      "\n",
      "2018-05-07 20:59:02 start epoch 20/100, with learning rate = 0.0005403405\n",
      "2018-05-07 20:59:02 iteration 1/429: current training loss = 18.903622 (=3.729972+15.173651)\n",
      "2018-05-07 20:59:07 iteration 50/429: current training loss = 17.631794 (=3.702831+13.928963)\n",
      "2018-05-07 20:59:12 iteration 100/429: current training loss = 18.329096 (=3.809763+14.519333)\n",
      "2018-05-07 20:59:18 iteration 150/429: current training loss = 16.986778 (=3.824989+13.161789)\n",
      "2018-05-07 20:59:23 iteration 200/429: current training loss = 16.413662 (=3.735620+12.678041)\n",
      "2018-05-07 20:59:28 iteration 250/429: current training loss = 16.576473 (=3.575131+13.001342)\n",
      "2018-05-07 20:59:34 iteration 300/429: current training loss = 19.861471 (=3.913283+15.948188)\n",
      "2018-05-07 20:59:39 iteration 350/429: current training loss = 17.495787 (=3.547577+13.948210)\n",
      "2018-05-07 20:59:44 iteration 400/429: current training loss = 17.264238 (=3.826331+13.437908)\n",
      "2018-05-07 20:59:48 iteration 429/429: current training loss = 18.198116 (=4.111650+14.086466)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:00:04 end epoch 20/100: loss_train=17.949032 loss_val=17.814222 loss_test=17.712877\n",
      "\n",
      "2018-05-07 21:00:04 start epoch 21/100, with learning rate = 0.0004863063\n",
      "2018-05-07 21:00:04 iteration 1/429: current training loss = 16.966488 (=3.626553+13.339934)\n",
      "2018-05-07 21:00:09 iteration 50/429: current training loss = 17.481632 (=3.833539+13.648094)\n",
      "2018-05-07 21:00:15 iteration 100/429: current training loss = 17.306786 (=3.794526+13.512260)\n",
      "2018-05-07 21:00:20 iteration 150/429: current training loss = 17.919058 (=3.908896+14.010161)\n",
      "2018-05-07 21:00:25 iteration 200/429: current training loss = 17.326891 (=3.584328+13.742563)\n",
      "2018-05-07 21:00:31 iteration 250/429: current training loss = 16.861965 (=3.718856+13.143110)\n",
      "2018-05-07 21:00:36 iteration 300/429: current training loss = 17.570642 (=3.932942+13.637701)\n",
      "2018-05-07 21:00:41 iteration 350/429: current training loss = 16.963198 (=3.742577+13.220621)\n",
      "2018-05-07 21:00:47 iteration 400/429: current training loss = 18.115446 (=3.772427+14.343019)\n",
      "2018-05-07 21:00:50 iteration 429/429: current training loss = 17.356369 (=3.889942+13.466427)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:01:06 end epoch 21/100: loss_train=16.953582 loss_val=16.845823 loss_test=16.814478\n",
      "\n",
      "2018-05-07 21:01:06 start epoch 22/100, with learning rate = 0.0004376757\n",
      "2018-05-07 21:01:06 iteration 1/429: current training loss = 16.778845 (=3.666419+13.112427)\n",
      "2018-05-07 21:01:12 iteration 50/429: current training loss = 17.342743 (=3.552138+13.790604)\n",
      "2018-05-07 21:01:17 iteration 100/429: current training loss = 16.126980 (=3.695431+12.431549)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-07 21:01:22 iteration 150/429: current training loss = 17.186100 (=3.810364+13.375737)\n",
      "2018-05-07 21:01:27 iteration 200/429: current training loss = 17.278881 (=3.707981+13.570901)\n",
      "2018-05-07 21:01:32 iteration 250/429: current training loss = 15.999903 (=3.704995+12.294908)\n",
      "2018-05-07 21:01:37 iteration 300/429: current training loss = 16.859171 (=3.814773+13.044397)\n",
      "2018-05-07 21:01:42 iteration 350/429: current training loss = 16.883080 (=3.778796+13.104282)\n",
      "2018-05-07 21:01:47 iteration 400/429: current training loss = 17.239651 (=3.663492+13.576159)\n",
      "2018-05-07 21:01:50 iteration 429/429: current training loss = 17.744560 (=3.811439+13.933121)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:02:06 end epoch 22/100: loss_train=16.988652 loss_val=16.868324 loss_test=16.782372\n",
      "\n",
      "2018-05-07 21:02:06 start epoch 23/100, with learning rate = 0.0003939081\n",
      "2018-05-07 21:02:06 iteration 1/429: current training loss = 16.558752 (=3.934663+12.624089)\n",
      "2018-05-07 21:02:11 iteration 50/429: current training loss = 16.496367 (=3.755614+12.740753)\n",
      "2018-05-07 21:02:17 iteration 100/429: current training loss = 17.180746 (=4.120296+13.060450)\n",
      "2018-05-07 21:02:22 iteration 150/429: current training loss = 17.128395 (=3.992212+13.136183)\n",
      "2018-05-07 21:02:27 iteration 200/429: current training loss = 17.061340 (=3.666580+13.394760)\n",
      "2018-05-07 21:02:32 iteration 250/429: current training loss = 17.144186 (=3.807142+13.337044)\n",
      "2018-05-07 21:02:37 iteration 300/429: current training loss = 17.864857 (=3.665035+14.199821)\n",
      "2018-05-07 21:02:42 iteration 350/429: current training loss = 16.856022 (=4.130923+12.725100)\n",
      "2018-05-07 21:02:48 iteration 400/429: current training loss = 16.457077 (=3.695017+12.762060)\n",
      "2018-05-07 21:02:51 iteration 429/429: current training loss = 18.950172 (=3.871422+15.078751)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:03:07 end epoch 23/100: loss_train=18.780556 loss_val=18.665882 loss_test=18.566274\n",
      "\n",
      "2018-05-07 21:03:07 start epoch 24/100, with learning rate = 0.0003545173\n",
      "2018-05-07 21:03:07 iteration 1/429: current training loss = 17.967783 (=3.661469+14.306314)\n",
      "2018-05-07 21:03:13 iteration 50/429: current training loss = 16.947899 (=3.897533+13.050365)\n",
      "2018-05-07 21:03:18 iteration 100/429: current training loss = 16.215342 (=3.868674+12.346668)\n",
      "2018-05-07 21:03:23 iteration 150/429: current training loss = 17.176203 (=3.810655+13.365547)\n",
      "2018-05-07 21:03:28 iteration 200/429: current training loss = 16.854502 (=3.687824+13.166678)\n",
      "2018-05-07 21:03:33 iteration 250/429: current training loss = 15.832541 (=3.674948+12.157594)\n",
      "2018-05-07 21:03:39 iteration 300/429: current training loss = 16.361370 (=3.684670+12.676699)\n",
      "2018-05-07 21:03:44 iteration 350/429: current training loss = 17.429831 (=4.021863+13.407968)\n",
      "2018-05-07 21:03:49 iteration 400/429: current training loss = 17.278849 (=3.776502+13.502346)\n",
      "2018-05-07 21:03:52 iteration 429/429: current training loss = 16.092163 (=3.757084+12.335079)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:04:09 end epoch 24/100: loss_train=16.516970 loss_val=16.336277 loss_test=16.338805\n",
      "\n",
      "2018-05-07 21:04:09 start epoch 25/100, with learning rate = 0.0003190656\n",
      "2018-05-07 21:04:09 iteration 1/429: current training loss = 15.794903 (=3.587793+12.207109)\n",
      "2018-05-07 21:04:14 iteration 50/429: current training loss = 16.337000 (=3.904615+12.432385)\n",
      "2018-05-07 21:04:19 iteration 100/429: current training loss = 16.151306 (=3.841336+12.309971)\n",
      "2018-05-07 21:04:24 iteration 150/429: current training loss = 15.345179 (=3.746283+11.598895)\n",
      "2018-05-07 21:04:30 iteration 200/429: current training loss = 17.047649 (=3.852037+13.195612)\n",
      "2018-05-07 21:04:35 iteration 250/429: current training loss = 16.083891 (=3.653667+12.430223)\n",
      "2018-05-07 21:04:40 iteration 300/429: current training loss = 17.143923 (=3.913689+13.230234)\n",
      "2018-05-07 21:04:46 iteration 350/429: current training loss = 15.293062 (=3.676081+11.616982)\n",
      "2018-05-07 21:04:51 iteration 400/429: current training loss = 16.525309 (=3.528480+12.996828)\n",
      "2018-05-07 21:04:54 iteration 429/429: current training loss = 14.791180 (=3.516462+11.274718)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:05:10 end epoch 25/100: loss_train=15.938811 loss_val=15.757822 loss_test=15.768088\n",
      "\n",
      "2018-05-07 21:05:10 start epoch 26/100, with learning rate = 0.0002871590\n",
      "2018-05-07 21:05:10 iteration 1/429: current training loss = 16.000191 (=3.807783+12.192408)\n",
      "2018-05-07 21:05:16 iteration 50/429: current training loss = 16.583664 (=3.852405+12.731258)\n",
      "2018-05-07 21:05:21 iteration 100/429: current training loss = 15.934803 (=3.838287+12.096516)\n",
      "2018-05-07 21:05:26 iteration 150/429: current training loss = 15.458857 (=3.867318+11.591538)\n",
      "2018-05-07 21:05:31 iteration 200/429: current training loss = 16.241877 (=3.911258+12.330619)\n",
      "2018-05-07 21:05:36 iteration 250/429: current training loss = 16.119759 (=3.973013+12.146746)\n",
      "2018-05-07 21:05:41 iteration 300/429: current training loss = 16.265791 (=3.696421+12.569370)\n",
      "2018-05-07 21:05:46 iteration 350/429: current training loss = 17.021151 (=3.833566+13.187585)\n",
      "2018-05-07 21:05:51 iteration 400/429: current training loss = 16.217949 (=3.743325+12.474625)\n",
      "2018-05-07 21:05:55 iteration 429/429: current training loss = 15.875610 (=3.743912+12.131698)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:06:11 end epoch 26/100: loss_train=16.812028 loss_val=16.667347 loss_test=16.594510\n",
      "\n",
      "2018-05-07 21:06:11 start epoch 27/100, with learning rate = 0.0002584431\n",
      "2018-05-07 21:06:11 iteration 1/429: current training loss = 16.183960 (=3.646237+12.537723)\n",
      "2018-05-07 21:06:16 iteration 50/429: current training loss = 16.130974 (=3.967711+12.163262)\n",
      "2018-05-07 21:06:21 iteration 100/429: current training loss = 15.951992 (=3.590272+12.361720)\n",
      "2018-05-07 21:06:26 iteration 150/429: current training loss = 17.167496 (=4.274870+12.892626)\n",
      "2018-05-07 21:06:32 iteration 200/429: current training loss = 17.881504 (=3.867440+14.014065)\n",
      "2018-05-07 21:06:37 iteration 250/429: current training loss = 16.901960 (=3.918240+12.983721)\n",
      "2018-05-07 21:06:42 iteration 300/429: current training loss = 16.373549 (=3.699954+12.673594)\n",
      "2018-05-07 21:06:47 iteration 350/429: current training loss = 15.585629 (=3.738697+11.846931)\n",
      "2018-05-07 21:06:53 iteration 400/429: current training loss = 16.253817 (=3.795407+12.458410)\n",
      "2018-05-07 21:06:56 iteration 429/429: current training loss = 15.968555 (=3.811357+12.157199)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:07:12 end epoch 27/100: loss_train=15.979727 loss_val=15.711314 loss_test=15.842417\n",
      "\n",
      "2018-05-07 21:07:12 start epoch 28/100, with learning rate = 0.0002325988\n",
      "2018-05-07 21:07:12 iteration 1/429: current training loss = 16.492588 (=3.943721+12.548867)\n",
      "2018-05-07 21:07:17 iteration 50/429: current training loss = 15.428614 (=3.612630+11.815983)\n",
      "2018-05-07 21:07:22 iteration 100/429: current training loss = 16.173437 (=3.771147+12.402289)\n",
      "2018-05-07 21:07:28 iteration 150/429: current training loss = 14.993570 (=3.707667+11.285904)\n",
      "2018-05-07 21:07:33 iteration 200/429: current training loss = 15.574007 (=3.776349+11.797658)\n",
      "2018-05-07 21:07:38 iteration 250/429: current training loss = 15.484867 (=3.707351+11.777516)\n",
      "2018-05-07 21:07:43 iteration 300/429: current training loss = 15.802001 (=3.958529+11.843472)\n",
      "2018-05-07 21:07:49 iteration 350/429: current training loss = 17.496557 (=3.621017+13.875540)\n",
      "2018-05-07 21:07:54 iteration 400/429: current training loss = 16.034460 (=3.876684+12.157775)\n",
      "2018-05-07 21:07:57 iteration 429/429: current training loss = 16.276251 (=3.929196+12.347054)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:08:13 end epoch 28/100: loss_train=15.982601 loss_val=15.860671 loss_test=15.797667\n",
      "\n",
      "2018-05-07 21:08:13 start epoch 29/100, with learning rate = 0.0002093389\n",
      "2018-05-07 21:08:14 iteration 1/429: current training loss = 15.728963 (=3.855447+11.873516)\n",
      "2018-05-07 21:08:19 iteration 50/429: current training loss = 16.348091 (=3.709743+12.638348)\n",
      "2018-05-07 21:08:24 iteration 100/429: current training loss = 16.185686 (=3.813930+12.371756)\n",
      "2018-05-07 21:08:29 iteration 150/429: current training loss = 15.684337 (=3.689835+11.994501)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-07 21:08:34 iteration 200/429: current training loss = 16.300158 (=3.945786+12.354371)\n",
      "2018-05-07 21:08:39 iteration 250/429: current training loss = 15.463728 (=3.730349+11.733379)\n",
      "2018-05-07 21:08:44 iteration 300/429: current training loss = 16.233763 (=3.980274+12.253489)\n",
      "2018-05-07 21:08:50 iteration 350/429: current training loss = 16.193956 (=3.990902+12.203053)\n",
      "2018-05-07 21:08:55 iteration 400/429: current training loss = 16.298458 (=4.007404+12.291054)\n",
      "2018-05-07 21:08:58 iteration 429/429: current training loss = 15.816265 (=3.836352+11.979914)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:09:14 end epoch 29/100: loss_train=16.011284 loss_val=15.764002 loss_test=15.856667\n",
      "\n",
      "2018-05-07 21:09:14 start epoch 30/100, with learning rate = 0.0001884050\n",
      "2018-05-07 21:09:15 iteration 1/429: current training loss = 16.105824 (=3.835018+12.270805)\n",
      "2018-05-07 21:09:20 iteration 50/429: current training loss = 15.913661 (=3.737663+12.175999)\n",
      "2018-05-07 21:09:25 iteration 100/429: current training loss = 16.542850 (=4.004265+12.538587)\n",
      "2018-05-07 21:09:31 iteration 150/429: current training loss = 15.244832 (=3.855428+11.389403)\n",
      "2018-05-07 21:09:36 iteration 200/429: current training loss = 15.616422 (=3.740350+11.876072)\n",
      "2018-05-07 21:09:41 iteration 250/429: current training loss = 15.067335 (=3.376858+11.690476)\n",
      "2018-05-07 21:09:46 iteration 300/429: current training loss = 15.791685 (=4.073459+11.718225)\n",
      "2018-05-07 21:09:52 iteration 350/429: current training loss = 15.508571 (=3.846462+11.662108)\n",
      "2018-05-07 21:09:57 iteration 400/429: current training loss = 15.863316 (=3.855599+12.007717)\n",
      "2018-05-07 21:10:00 iteration 429/429: current training loss = 15.674208 (=3.737694+11.936514)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:10:17 end epoch 30/100: loss_train=15.294665 loss_val=15.111426 loss_test=15.147876\n",
      "\n",
      "2018-05-07 21:10:17 start epoch 31/100, with learning rate = 0.0001695645\n",
      "2018-05-07 21:10:17 iteration 1/429: current training loss = 14.404438 (=3.490968+10.913469)\n",
      "2018-05-07 21:10:22 iteration 50/429: current training loss = 15.877269 (=3.974751+11.902517)\n",
      "2018-05-07 21:10:28 iteration 100/429: current training loss = 15.911495 (=3.836569+12.074926)\n",
      "2018-05-07 21:10:33 iteration 150/429: current training loss = 15.853447 (=3.930833+11.922613)\n",
      "2018-05-07 21:10:38 iteration 200/429: current training loss = 15.035119 (=3.602470+11.432649)\n",
      "2018-05-07 21:10:44 iteration 250/429: current training loss = 15.885447 (=3.710581+12.174866)\n",
      "2018-05-07 21:10:49 iteration 300/429: current training loss = 15.764338 (=3.887887+11.876451)\n",
      "2018-05-07 21:10:54 iteration 350/429: current training loss = 15.195804 (=3.711883+11.483921)\n",
      "2018-05-07 21:11:00 iteration 400/429: current training loss = 15.197762 (=3.741287+11.456474)\n",
      "2018-05-07 21:11:03 iteration 429/429: current training loss = 15.007190 (=3.746579+11.260611)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:11:19 end epoch 31/100: loss_train=14.798772 loss_val=14.643197 loss_test=14.628954\n",
      "\n",
      "2018-05-07 21:11:19 start epoch 32/100, with learning rate = 0.0001526080\n",
      "2018-05-07 21:11:20 iteration 1/429: current training loss = 15.232219 (=4.042380+11.189838)\n",
      "2018-05-07 21:11:25 iteration 50/429: current training loss = 15.014043 (=3.639598+11.374445)\n",
      "2018-05-07 21:11:30 iteration 100/429: current training loss = 16.185028 (=3.791138+12.393890)\n",
      "2018-05-07 21:11:36 iteration 150/429: current training loss = 14.533640 (=3.762596+10.771044)\n",
      "2018-05-07 21:11:41 iteration 200/429: current training loss = 15.665378 (=3.724120+11.941257)\n",
      "2018-05-07 21:11:46 iteration 250/429: current training loss = 15.142609 (=3.653312+11.489297)\n",
      "2018-05-07 21:11:51 iteration 300/429: current training loss = 15.708097 (=3.892896+11.815200)\n",
      "2018-05-07 21:11:57 iteration 350/429: current training loss = 15.845170 (=3.907197+11.937973)\n",
      "2018-05-07 21:12:03 iteration 400/429: current training loss = 16.628422 (=3.799316+12.829105)\n",
      "2018-05-07 21:12:06 iteration 429/429: current training loss = 15.991216 (=3.959392+12.031824)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:12:23 end epoch 32/100: loss_train=15.522930 loss_val=15.310222 loss_test=15.356990\n",
      "\n",
      "2018-05-07 21:12:23 start epoch 33/100, with learning rate = 0.0001373472\n",
      "2018-05-07 21:12:23 iteration 1/429: current training loss = 14.668017 (=3.553828+11.114190)\n",
      "2018-05-07 21:12:28 iteration 50/429: current training loss = 14.575237 (=3.868675+10.706563)\n",
      "2018-05-07 21:12:34 iteration 100/429: current training loss = 15.090770 (=3.768709+11.322061)\n",
      "2018-05-07 21:12:39 iteration 150/429: current training loss = 15.397313 (=3.775466+11.621847)\n",
      "2018-05-07 21:12:44 iteration 200/429: current training loss = 14.399943 (=3.508492+10.891451)\n",
      "2018-05-07 21:12:50 iteration 250/429: current training loss = 15.194851 (=3.634634+11.560217)\n",
      "2018-05-07 21:12:55 iteration 300/429: current training loss = 15.623462 (=4.005115+11.618347)\n",
      "2018-05-07 21:13:00 iteration 350/429: current training loss = 17.769764 (=3.685039+14.084724)\n",
      "2018-05-07 21:13:06 iteration 400/429: current training loss = 14.977297 (=3.882577+11.094720)\n",
      "2018-05-07 21:13:09 iteration 429/429: current training loss = 15.112823 (=3.580108+11.532715)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:13:24 end epoch 33/100: loss_train=15.021729 loss_val=14.855121 loss_test=14.887611\n",
      "\n",
      "2018-05-07 21:13:24 start epoch 34/100, with learning rate = 0.0001236125\n",
      "2018-05-07 21:13:24 iteration 1/429: current training loss = 14.968023 (=3.753896+11.214128)\n",
      "2018-05-07 21:13:29 iteration 50/429: current training loss = 14.370369 (=3.546016+10.824352)\n",
      "2018-05-07 21:13:34 iteration 100/429: current training loss = 15.029729 (=3.758943+11.270785)\n",
      "2018-05-07 21:13:40 iteration 150/429: current training loss = 14.244615 (=3.763982+10.480633)\n",
      "2018-05-07 21:13:45 iteration 200/429: current training loss = 14.040108 (=3.748637+10.291471)\n",
      "2018-05-07 21:13:50 iteration 250/429: current training loss = 15.634462 (=3.741411+11.893051)\n",
      "2018-05-07 21:13:56 iteration 300/429: current training loss = 14.976126 (=3.762385+11.213741)\n",
      "2018-05-07 21:14:01 iteration 350/429: current training loss = 14.968708 (=3.865801+11.102907)\n",
      "2018-05-07 21:14:07 iteration 400/429: current training loss = 15.599572 (=3.792023+11.807549)\n",
      "2018-05-07 21:14:10 iteration 429/429: current training loss = 15.064150 (=3.874042+11.190107)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:14:27 end epoch 34/100: loss_train=15.654654 loss_val=15.604905 loss_test=15.514516\n",
      "\n",
      "2018-05-07 21:14:27 start epoch 35/100, with learning rate = 0.0001112513\n",
      "2018-05-07 21:14:27 iteration 1/429: current training loss = 15.364326 (=3.781837+11.582488)\n",
      "2018-05-07 21:14:32 iteration 50/429: current training loss = 15.822622 (=3.886591+11.936031)\n",
      "2018-05-07 21:14:37 iteration 100/429: current training loss = 15.423172 (=3.772527+11.650645)\n",
      "2018-05-07 21:14:42 iteration 150/429: current training loss = 15.792883 (=3.935351+11.857532)\n",
      "2018-05-07 21:14:48 iteration 200/429: current training loss = 15.037002 (=3.691241+11.345760)\n",
      "2018-05-07 21:14:53 iteration 250/429: current training loss = 14.226158 (=3.972042+10.254116)\n",
      "2018-05-07 21:14:58 iteration 300/429: current training loss = 14.318583 (=3.592504+10.726078)\n",
      "2018-05-07 21:15:03 iteration 350/429: current training loss = 14.466085 (=3.737076+10.729009)\n",
      "2018-05-07 21:15:09 iteration 400/429: current training loss = 14.923188 (=3.615300+11.307888)\n",
      "2018-05-07 21:15:12 iteration 429/429: current training loss = 15.363353 (=3.759028+11.604325)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:15:29 end epoch 35/100: loss_train=15.192716 loss_val=14.942450 loss_test=15.011556\n",
      "\n",
      "2018-05-07 21:15:29 start epoch 36/100, with learning rate = 0.0001001261\n",
      "2018-05-07 21:15:29 iteration 1/429: current training loss = 14.844369 (=3.796451+11.047918)\n",
      "2018-05-07 21:15:34 iteration 50/429: current training loss = 14.958513 (=3.787898+11.170616)\n",
      "2018-05-07 21:15:39 iteration 100/429: current training loss = 14.808489 (=3.826403+10.982085)\n",
      "2018-05-07 21:15:44 iteration 150/429: current training loss = 15.012814 (=3.934329+11.078485)\n",
      "2018-05-07 21:15:50 iteration 200/429: current training loss = 15.002817 (=3.715514+11.287303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-07 21:15:55 iteration 250/429: current training loss = 14.884924 (=3.838690+11.046234)\n",
      "2018-05-07 21:16:01 iteration 300/429: current training loss = 15.684202 (=3.762218+11.921984)\n",
      "2018-05-07 21:16:06 iteration 350/429: current training loss = 14.096942 (=3.844551+10.252391)\n",
      "2018-05-07 21:16:12 iteration 400/429: current training loss = 14.666457 (=3.738774+10.927684)\n",
      "2018-05-07 21:16:15 iteration 429/429: current training loss = 13.650477 (=3.660531+9.989946)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:16:32 end epoch 36/100: loss_train=14.410589 loss_val=14.277654 loss_test=14.236142\n",
      "\n",
      "2018-05-07 21:16:32 start epoch 37/100, with learning rate = 0.0000901135\n",
      "2018-05-07 21:16:33 iteration 1/429: current training loss = 14.339235 (=3.766475+10.572760)\n",
      "2018-05-07 21:16:38 iteration 50/429: current training loss = 14.497865 (=3.712247+10.785618)\n",
      "2018-05-07 21:16:43 iteration 100/429: current training loss = 15.751986 (=3.875671+11.876314)\n",
      "2018-05-07 21:16:48 iteration 150/429: current training loss = 14.774540 (=3.735553+11.038986)\n",
      "2018-05-07 21:16:54 iteration 200/429: current training loss = 14.369450 (=3.819782+10.549667)\n",
      "2018-05-07 21:16:59 iteration 250/429: current training loss = 14.847170 (=3.842421+11.004749)\n",
      "2018-05-07 21:17:05 iteration 300/429: current training loss = 15.665140 (=3.866623+11.798517)\n",
      "2018-05-07 21:17:10 iteration 350/429: current training loss = 15.203364 (=3.798203+11.405161)\n",
      "2018-05-07 21:17:15 iteration 400/429: current training loss = 14.931292 (=3.732195+11.199097)\n",
      "2018-05-07 21:17:18 iteration 429/429: current training loss = 13.908809 (=3.769179+10.139630)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:17:35 end epoch 37/100: loss_train=14.012611 loss_val=13.858188 loss_test=13.876790\n",
      "\n",
      "2018-05-07 21:17:35 start epoch 38/100, with learning rate = 0.0000811022\n",
      "2018-05-07 21:17:35 iteration 1/429: current training loss = 14.841567 (=3.905631+10.935936)\n",
      "2018-05-07 21:17:40 iteration 50/429: current training loss = 15.474930 (=3.925125+11.549805)\n",
      "2018-05-07 21:17:46 iteration 100/429: current training loss = 14.901778 (=3.846159+11.055619)\n",
      "2018-05-07 21:17:51 iteration 150/429: current training loss = 15.257002 (=3.778126+11.478876)\n",
      "2018-05-07 21:17:57 iteration 200/429: current training loss = 15.265791 (=3.825351+11.440439)\n",
      "2018-05-07 21:18:02 iteration 250/429: current training loss = 15.170238 (=3.755168+11.415070)\n",
      "2018-05-07 21:18:07 iteration 300/429: current training loss = 14.270718 (=3.891231+10.379486)\n",
      "2018-05-07 21:18:13 iteration 350/429: current training loss = 14.987005 (=3.809436+11.177569)\n",
      "2018-05-07 21:18:18 iteration 400/429: current training loss = 14.733985 (=3.776567+10.957417)\n",
      "2018-05-07 21:18:21 iteration 429/429: current training loss = 16.986538 (=3.651042+13.335496)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:18:39 end epoch 38/100: loss_train=16.787960 loss_val=16.589123 loss_test=16.486893\n",
      "\n",
      "2018-05-07 21:18:39 start epoch 39/100, with learning rate = 0.0000729919\n",
      "2018-05-07 21:18:39 iteration 1/429: current training loss = 16.667055 (=3.734901+12.932154)\n",
      "2018-05-07 21:18:44 iteration 50/429: current training loss = 15.176991 (=3.839341+11.337649)\n",
      "2018-05-07 21:18:49 iteration 100/429: current training loss = 13.917799 (=3.508184+10.409615)\n",
      "2018-05-07 21:18:55 iteration 150/429: current training loss = 14.796768 (=3.750715+11.046053)\n",
      "2018-05-07 21:19:00 iteration 200/429: current training loss = 13.891004 (=3.579736+10.311268)\n",
      "2018-05-07 21:19:05 iteration 250/429: current training loss = 15.200378 (=3.713299+11.487080)\n",
      "2018-05-07 21:19:10 iteration 300/429: current training loss = 15.891065 (=3.782565+12.108500)\n",
      "2018-05-07 21:19:16 iteration 350/429: current training loss = 15.940704 (=3.760752+12.179953)\n",
      "2018-05-07 21:19:21 iteration 400/429: current training loss = 14.448658 (=3.769488+10.679171)\n",
      "2018-05-07 21:19:24 iteration 429/429: current training loss = 14.041454 (=3.484982+10.556472)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:19:41 end epoch 39/100: loss_train=14.679436 loss_val=14.631312 loss_test=14.443191\n",
      "\n",
      "2018-05-07 21:19:41 start epoch 40/100, with learning rate = 0.0000656928\n",
      "2018-05-07 21:19:41 iteration 1/429: current training loss = 15.073182 (=3.882606+11.190577)\n",
      "2018-05-07 21:19:46 iteration 50/429: current training loss = 13.870044 (=3.723149+10.146894)\n",
      "2018-05-07 21:19:51 iteration 100/429: current training loss = 14.993463 (=3.801481+11.191982)\n",
      "2018-05-07 21:19:57 iteration 150/429: current training loss = 13.929082 (=3.619519+10.309563)\n",
      "2018-05-07 21:20:02 iteration 200/429: current training loss = 14.984144 (=3.780325+11.203819)\n",
      "2018-05-07 21:20:08 iteration 250/429: current training loss = 14.448278 (=3.542260+10.906018)\n",
      "2018-05-07 21:20:13 iteration 300/429: current training loss = 13.843314 (=3.635005+10.208309)\n",
      "2018-05-07 21:20:18 iteration 350/429: current training loss = 15.159517 (=3.802522+11.356995)\n",
      "2018-05-07 21:20:24 iteration 400/429: current training loss = 14.272121 (=3.840254+10.431868)\n",
      "2018-05-07 21:20:27 iteration 429/429: current training loss = 14.569666 (=3.742012+10.827654)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:20:43 end epoch 40/100: loss_train=14.415803 loss_val=14.245618 loss_test=14.327030\n",
      "\n",
      "2018-05-07 21:20:43 start epoch 41/100, with learning rate = 0.0000591235\n",
      "2018-05-07 21:20:44 iteration 1/429: current training loss = 14.967488 (=3.832168+11.135321)\n",
      "2018-05-07 21:20:49 iteration 50/429: current training loss = 13.996246 (=3.679325+10.316921)\n",
      "2018-05-07 21:20:54 iteration 100/429: current training loss = 13.648293 (=3.776271+9.872021)\n",
      "2018-05-07 21:21:00 iteration 150/429: current training loss = 15.752758 (=3.698123+12.054636)\n",
      "2018-05-07 21:21:05 iteration 200/429: current training loss = 14.488528 (=3.646761+10.841767)\n",
      "2018-05-07 21:21:10 iteration 250/429: current training loss = 14.098566 (=3.865912+10.232654)\n",
      "2018-05-07 21:21:16 iteration 300/429: current training loss = 14.971030 (=3.810168+11.160862)\n",
      "2018-05-07 21:21:21 iteration 350/429: current training loss = 14.503272 (=3.948241+10.555031)\n",
      "2018-05-07 21:21:26 iteration 400/429: current training loss = 13.600946 (=3.595925+10.005021)\n",
      "2018-05-07 21:21:30 iteration 429/429: current training loss = 16.183926 (=4.012660+12.171267)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:21:46 end epoch 41/100: loss_train=15.532527 loss_val=15.293225 loss_test=15.400845\n",
      "\n",
      "2018-05-07 21:21:46 start epoch 42/100, with learning rate = 0.0000532111\n",
      "2018-05-07 21:21:47 iteration 1/429: current training loss = 15.218752 (=3.599154+11.619597)\n",
      "2018-05-07 21:21:52 iteration 50/429: current training loss = 13.538318 (=3.696772+9.841546)\n",
      "2018-05-07 21:21:58 iteration 100/429: current training loss = 14.018988 (=3.849899+10.169088)\n",
      "2018-05-07 21:22:03 iteration 150/429: current training loss = 13.119766 (=3.633702+9.486064)\n",
      "2018-05-07 21:22:09 iteration 200/429: current training loss = 14.370342 (=3.889451+10.480892)\n",
      "2018-05-07 21:22:14 iteration 250/429: current training loss = 13.741941 (=3.687188+10.054753)\n",
      "2018-05-07 21:22:19 iteration 300/429: current training loss = 14.730911 (=3.727809+11.003102)\n",
      "2018-05-07 21:22:24 iteration 350/429: current training loss = 13.992206 (=3.854323+10.137882)\n",
      "2018-05-07 21:22:30 iteration 400/429: current training loss = 13.948199 (=3.697358+10.250841)\n",
      "2018-05-07 21:22:33 iteration 429/429: current training loss = 13.528066 (=3.737429+9.790636)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:22:48 end epoch 42/100: loss_train=13.293378 loss_val=13.111286 loss_test=13.194034\n",
      "\n",
      "2018-05-07 21:22:48 start epoch 43/100, with learning rate = 0.0000478900\n",
      "2018-05-07 21:22:49 iteration 1/429: current training loss = 13.614993 (=3.834820+9.780173)\n",
      "2018-05-07 21:22:54 iteration 50/429: current training loss = 13.508707 (=3.690249+9.818459)\n",
      "2018-05-07 21:22:59 iteration 100/429: current training loss = 15.197582 (=3.772289+11.425293)\n",
      "2018-05-07 21:23:05 iteration 150/429: current training loss = 15.538844 (=3.581167+11.957677)\n",
      "2018-05-07 21:23:10 iteration 200/429: current training loss = 14.995805 (=3.720965+11.274840)\n",
      "2018-05-07 21:23:15 iteration 250/429: current training loss = 14.470860 (=3.613724+10.857136)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-07 21:23:21 iteration 300/429: current training loss = 15.096468 (=3.780708+11.315760)\n",
      "2018-05-07 21:23:26 iteration 350/429: current training loss = 14.155653 (=3.755028+10.400625)\n",
      "2018-05-07 21:23:32 iteration 400/429: current training loss = 15.830568 (=3.882593+11.947975)\n",
      "2018-05-07 21:23:35 iteration 429/429: current training loss = 14.294953 (=3.764469+10.530484)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:23:52 end epoch 43/100: loss_train=13.949487 loss_val=13.794281 loss_test=13.861787\n",
      "\n",
      "2018-05-07 21:23:52 start epoch 44/100, with learning rate = 0.0000431010\n",
      "2018-05-07 21:23:52 iteration 1/429: current training loss = 14.020244 (=3.662758+10.357486)\n",
      "2018-05-07 21:23:57 iteration 50/429: current training loss = 14.310224 (=3.754706+10.555517)\n",
      "2018-05-07 21:24:02 iteration 100/429: current training loss = 13.463942 (=3.585412+9.878530)\n",
      "2018-05-07 21:24:07 iteration 150/429: current training loss = 14.696445 (=3.712057+10.984388)\n",
      "2018-05-07 21:24:13 iteration 200/429: current training loss = 14.764535 (=3.778672+10.985863)\n",
      "2018-05-07 21:24:18 iteration 250/429: current training loss = 14.567826 (=3.730413+10.837414)\n",
      "2018-05-07 21:24:23 iteration 300/429: current training loss = 13.949562 (=3.703346+10.246216)\n",
      "2018-05-07 21:24:29 iteration 350/429: current training loss = 13.721420 (=3.740840+9.980579)\n",
      "2018-05-07 21:24:34 iteration 400/429: current training loss = 14.263963 (=3.661938+10.602024)\n",
      "2018-05-07 21:24:37 iteration 429/429: current training loss = 14.692864 (=3.600272+11.092592)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:24:54 end epoch 44/100: loss_train=13.855626 loss_val=13.659403 loss_test=13.739235\n",
      "\n",
      "2018-05-07 21:24:54 start epoch 45/100, with learning rate = 0.0000387909\n",
      "2018-05-07 21:24:54 iteration 1/429: current training loss = 13.198219 (=3.587824+9.610395)\n",
      "2018-05-07 21:24:59 iteration 50/429: current training loss = 13.275284 (=3.610521+9.664762)\n",
      "2018-05-07 21:25:05 iteration 100/429: current training loss = 14.182569 (=3.733720+10.448849)\n",
      "2018-05-07 21:25:10 iteration 150/429: current training loss = 13.636944 (=3.607321+10.029623)\n",
      "2018-05-07 21:25:15 iteration 200/429: current training loss = 14.942783 (=3.796094+11.146689)\n",
      "2018-05-07 21:25:21 iteration 250/429: current training loss = 13.690710 (=3.856464+9.834246)\n",
      "2018-05-07 21:25:26 iteration 300/429: current training loss = 14.018132 (=3.735738+10.282394)\n",
      "2018-05-07 21:25:32 iteration 350/429: current training loss = 14.243494 (=3.723233+10.520262)\n",
      "2018-05-07 21:25:37 iteration 400/429: current training loss = 14.562313 (=3.833703+10.728611)\n",
      "2018-05-07 21:25:40 iteration 429/429: current training loss = 14.138786 (=3.680765+10.458021)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:25:57 end epoch 45/100: loss_train=14.110086 loss_val=13.962430 loss_test=14.008130\n",
      "\n",
      "2018-05-07 21:25:57 start epoch 46/100, with learning rate = 0.0000349118\n",
      "2018-05-07 21:25:57 iteration 1/429: current training loss = 14.273805 (=3.635741+10.638063)\n",
      "2018-05-07 21:26:02 iteration 50/429: current training loss = 13.938367 (=3.789046+10.149321)\n",
      "2018-05-07 21:26:08 iteration 100/429: current training loss = 15.417193 (=3.618595+11.798598)\n",
      "2018-05-07 21:26:13 iteration 150/429: current training loss = 13.869095 (=3.702022+10.167072)\n",
      "2018-05-07 21:26:18 iteration 200/429: current training loss = 15.052770 (=3.878857+11.173912)\n",
      "2018-05-07 21:26:24 iteration 250/429: current training loss = 13.066582 (=3.537937+9.528645)\n",
      "2018-05-07 21:26:29 iteration 300/429: current training loss = 14.476027 (=3.828923+10.647104)\n",
      "2018-05-07 21:26:35 iteration 350/429: current training loss = 14.194706 (=3.600989+10.593717)\n",
      "2018-05-07 21:26:40 iteration 400/429: current training loss = 14.097903 (=3.645762+10.452141)\n",
      "2018-05-07 21:26:43 iteration 429/429: current training loss = 13.408146 (=3.677020+9.731126)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:27:00 end epoch 46/100: loss_train=13.531977 loss_val=13.358906 loss_test=13.385282\n",
      "\n",
      "2018-05-07 21:27:00 start epoch 47/100, with learning rate = 0.0000314206\n",
      "2018-05-07 21:27:00 iteration 1/429: current training loss = 13.130906 (=3.675859+9.455048)\n",
      "2018-05-07 21:27:05 iteration 50/429: current training loss = 13.500030 (=3.539719+9.960311)\n",
      "2018-05-07 21:27:11 iteration 100/429: current training loss = 14.023909 (=3.695210+10.328699)\n",
      "2018-05-07 21:27:16 iteration 150/429: current training loss = 14.671683 (=3.720907+10.950776)\n",
      "2018-05-07 21:27:22 iteration 200/429: current training loss = 13.917353 (=3.526578+10.390774)\n",
      "2018-05-07 21:27:27 iteration 250/429: current training loss = 13.658648 (=3.662417+9.996231)\n",
      "2018-05-07 21:27:32 iteration 300/429: current training loss = 14.146760 (=3.764652+10.382108)\n",
      "2018-05-07 21:27:38 iteration 350/429: current training loss = 15.099743 (=3.977643+11.122100)\n",
      "2018-05-07 21:27:43 iteration 400/429: current training loss = 14.451530 (=3.957929+10.493601)\n",
      "2018-05-07 21:27:46 iteration 429/429: current training loss = 12.887335 (=3.600409+9.286926)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:28:03 end epoch 47/100: loss_train=13.676484 loss_val=13.584327 loss_test=13.561124\n",
      "\n",
      "2018-05-07 21:28:03 start epoch 48/100, with learning rate = 0.0000282786\n",
      "2018-05-07 21:28:03 iteration 1/429: current training loss = 13.284642 (=3.480202+9.804440)\n",
      "2018-05-07 21:28:09 iteration 50/429: current training loss = 13.074442 (=3.673134+9.401308)\n",
      "2018-05-07 21:28:14 iteration 100/429: current training loss = 13.903187 (=3.595308+10.307878)\n",
      "2018-05-07 21:28:20 iteration 150/429: current training loss = 13.683350 (=3.816603+9.866747)\n",
      "2018-05-07 21:28:25 iteration 200/429: current training loss = 14.234151 (=3.738595+10.495556)\n",
      "2018-05-07 21:28:30 iteration 250/429: current training loss = 13.576878 (=3.474434+10.102444)\n",
      "2018-05-07 21:28:36 iteration 300/429: current training loss = 13.515834 (=3.692670+9.823164)\n",
      "2018-05-07 21:28:41 iteration 350/429: current training loss = 14.720173 (=3.751240+10.968933)\n",
      "2018-05-07 21:28:46 iteration 400/429: current training loss = 14.390546 (=3.713331+10.677216)\n",
      "2018-05-07 21:28:50 iteration 429/429: current training loss = 12.959119 (=3.706796+9.252323)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:29:07 end epoch 48/100: loss_train=13.245510 loss_val=13.050884 loss_test=13.129763\n",
      "\n",
      "2018-05-07 21:29:07 start epoch 49/100, with learning rate = 0.0000254507\n",
      "2018-05-07 21:29:07 iteration 1/429: current training loss = 12.279089 (=3.440191+8.838899)\n",
      "2018-05-07 21:29:12 iteration 50/429: current training loss = 14.592015 (=3.737568+10.854447)\n",
      "2018-05-07 21:29:18 iteration 100/429: current training loss = 14.254187 (=3.712928+10.541259)\n",
      "2018-05-07 21:29:23 iteration 150/429: current training loss = 13.995377 (=3.727917+10.267460)\n",
      "2018-05-07 21:29:29 iteration 200/429: current training loss = 13.799410 (=3.681708+10.117702)\n",
      "2018-05-07 21:29:34 iteration 250/429: current training loss = 14.156822 (=3.671293+10.485529)\n",
      "2018-05-07 21:29:39 iteration 300/429: current training loss = 14.674818 (=3.872855+10.801964)\n",
      "2018-05-07 21:29:45 iteration 350/429: current training loss = 13.992594 (=3.658884+10.333710)\n",
      "2018-05-07 21:29:50 iteration 400/429: current training loss = 14.465663 (=3.612176+10.853487)\n",
      "2018-05-07 21:29:53 iteration 429/429: current training loss = 13.881012 (=3.763411+10.117601)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:30:10 end epoch 49/100: loss_train=13.716132 loss_val=13.641543 loss_test=13.537384\n",
      "\n",
      "2018-05-07 21:30:10 start epoch 50/100, with learning rate = 0.0000229056\n",
      "2018-05-07 21:30:10 iteration 1/429: current training loss = 14.696205 (=3.847910+10.848295)\n",
      "2018-05-07 21:30:16 iteration 50/429: current training loss = 13.942038 (=3.991066+9.950971)\n",
      "2018-05-07 21:30:21 iteration 100/429: current training loss = 14.206475 (=3.746844+10.459631)\n",
      "2018-05-07 21:30:27 iteration 150/429: current training loss = 13.570833 (=3.716638+9.854195)\n",
      "2018-05-07 21:30:32 iteration 200/429: current training loss = 13.327650 (=3.748034+9.579617)\n",
      "2018-05-07 21:30:38 iteration 250/429: current training loss = 13.127203 (=3.589143+9.538060)\n",
      "2018-05-07 21:30:43 iteration 300/429: current training loss = 13.913458 (=3.824349+10.089109)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-07 21:30:48 iteration 350/429: current training loss = 14.143049 (=3.556506+10.586543)\n",
      "2018-05-07 21:30:54 iteration 400/429: current training loss = 13.491028 (=3.736314+9.754714)\n",
      "2018-05-07 21:30:57 iteration 429/429: current training loss = 14.885636 (=3.900192+10.985444)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:31:14 end epoch 50/100: loss_train=13.763987 loss_val=13.646576 loss_test=13.610478\n",
      "\n",
      "2018-05-07 21:31:14 start epoch 51/100, with learning rate = 0.0000206151\n",
      "2018-05-07 21:31:14 iteration 1/429: current training loss = 14.481356 (=3.910647+10.570708)\n",
      "2018-05-07 21:31:20 iteration 50/429: current training loss = 13.759510 (=3.741669+10.017841)\n",
      "2018-05-07 21:31:25 iteration 100/429: current training loss = 14.700426 (=3.520496+11.179930)\n",
      "2018-05-07 21:31:31 iteration 150/429: current training loss = 13.826759 (=3.645691+10.181068)\n",
      "2018-05-07 21:31:36 iteration 200/429: current training loss = 13.177267 (=3.607770+9.569497)\n",
      "2018-05-07 21:31:41 iteration 250/429: current training loss = 14.316134 (=3.827850+10.488284)\n",
      "2018-05-07 21:31:47 iteration 300/429: current training loss = 13.565258 (=3.779673+9.785585)\n",
      "2018-05-07 21:31:52 iteration 350/429: current training loss = 13.768287 (=3.617886+10.150400)\n",
      "2018-05-07 21:31:57 iteration 400/429: current training loss = 12.710762 (=3.488375+9.222387)\n",
      "2018-05-07 21:32:00 iteration 429/429: current training loss = 13.718784 (=3.731612+9.987172)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:32:17 end epoch 51/100: loss_train=13.403282 loss_val=13.214650 loss_test=13.261823\n",
      "\n",
      "2018-05-07 21:32:17 start epoch 52/100, with learning rate = 0.0000185536\n",
      "2018-05-07 21:32:17 iteration 1/429: current training loss = 13.852374 (=3.790488+10.061886)\n",
      "2018-05-07 21:32:22 iteration 50/429: current training loss = 13.324783 (=3.699285+9.625499)\n",
      "2018-05-07 21:32:28 iteration 100/429: current training loss = 12.731309 (=3.499978+9.231331)\n",
      "2018-05-07 21:32:33 iteration 150/429: current training loss = 13.941744 (=3.793236+10.148508)\n",
      "2018-05-07 21:32:39 iteration 200/429: current training loss = 13.391505 (=3.523903+9.867602)\n",
      "2018-05-07 21:32:44 iteration 250/429: current training loss = 13.051850 (=3.485905+9.565945)\n",
      "2018-05-07 21:32:50 iteration 300/429: current training loss = 15.211683 (=3.758553+11.453130)\n",
      "2018-05-07 21:32:55 iteration 350/429: current training loss = 14.938699 (=3.812116+11.126583)\n",
      "2018-05-07 21:33:00 iteration 400/429: current training loss = 14.654900 (=3.758375+10.896524)\n",
      "2018-05-07 21:33:04 iteration 429/429: current training loss = 12.965375 (=3.623729+9.341646)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:33:20 end epoch 52/100: loss_train=13.013614 loss_val=12.929089 loss_test=12.931772\n",
      "\n",
      "2018-05-07 21:33:20 start epoch 53/100, with learning rate = 0.0000166982\n",
      "2018-05-07 21:33:20 iteration 1/429: current training loss = 13.046732 (=3.700029+9.346703)\n",
      "2018-05-07 21:33:26 iteration 50/429: current training loss = 14.099470 (=3.600376+10.499094)\n",
      "2018-05-07 21:33:31 iteration 100/429: current training loss = 13.141604 (=3.620614+9.520990)\n",
      "2018-05-07 21:33:36 iteration 150/429: current training loss = 13.127001 (=3.564632+9.562368)\n",
      "2018-05-07 21:33:42 iteration 200/429: current training loss = 14.436221 (=3.767763+10.668458)\n",
      "2018-05-07 21:33:47 iteration 250/429: current training loss = 13.760659 (=3.658442+10.102218)\n",
      "2018-05-07 21:33:52 iteration 300/429: current training loss = 13.097554 (=3.555411+9.542143)\n",
      "2018-05-07 21:33:58 iteration 350/429: current training loss = 13.632791 (=3.513103+10.119687)\n",
      "2018-05-07 21:34:03 iteration 400/429: current training loss = 14.121390 (=3.700606+10.420785)\n",
      "2018-05-07 21:34:06 iteration 429/429: current training loss = 14.097597 (=3.767050+10.330547)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:34:23 end epoch 53/100: loss_train=13.904543 loss_val=13.726829 loss_test=13.744822\n",
      "\n",
      "2018-05-07 21:34:23 start epoch 54/100, with learning rate = 0.0000150284\n",
      "2018-05-07 21:34:23 iteration 1/429: current training loss = 14.155795 (=3.683717+10.472078)\n",
      "2018-05-07 21:34:28 iteration 50/429: current training loss = 13.697551 (=3.801080+9.896471)\n",
      "2018-05-07 21:34:33 iteration 100/429: current training loss = 12.741870 (=3.532567+9.209303)\n",
      "2018-05-07 21:34:39 iteration 150/429: current training loss = 13.527058 (=3.739372+9.787685)\n",
      "2018-05-07 21:34:44 iteration 200/429: current training loss = 13.387028 (=3.760521+9.626507)\n",
      "2018-05-07 21:34:49 iteration 250/429: current training loss = 13.785226 (=3.577097+10.208129)\n",
      "2018-05-07 21:34:54 iteration 300/429: current training loss = 12.911727 (=3.545684+9.366043)\n",
      "2018-05-07 21:35:00 iteration 350/429: current training loss = 13.664465 (=3.664409+10.000056)\n",
      "2018-05-07 21:35:05 iteration 400/429: current training loss = 13.609587 (=3.730588+9.878998)\n",
      "2018-05-07 21:35:08 iteration 429/429: current training loss = 13.335669 (=3.668000+9.667669)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:35:25 end epoch 54/100: loss_train=13.925918 loss_val=13.744342 loss_test=13.807684\n",
      "\n",
      "2018-05-07 21:35:25 start epoch 55/100, with learning rate = 0.0000135255\n",
      "2018-05-07 21:35:26 iteration 1/429: current training loss = 13.964619 (=3.727508+10.237111)\n",
      "2018-05-07 21:35:31 iteration 50/429: current training loss = 14.015116 (=3.848106+10.167009)\n",
      "2018-05-07 21:35:36 iteration 100/429: current training loss = 14.331800 (=3.727411+10.604389)\n",
      "2018-05-07 21:35:41 iteration 150/429: current training loss = 14.196516 (=3.724507+10.472010)\n",
      "2018-05-07 21:35:46 iteration 200/429: current training loss = 13.897131 (=3.552239+10.344892)\n",
      "2018-05-07 21:35:52 iteration 250/429: current training loss = 14.272684 (=3.602818+10.669867)\n",
      "2018-05-07 21:35:57 iteration 300/429: current training loss = 12.775688 (=3.631166+9.144522)\n",
      "2018-05-07 21:36:02 iteration 350/429: current training loss = 14.707893 (=3.731697+10.976196)\n",
      "2018-05-07 21:36:08 iteration 400/429: current training loss = 13.341764 (=3.789507+9.552258)\n",
      "2018-05-07 21:36:11 iteration 429/429: current training loss = 13.257929 (=3.696488+9.561441)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:36:28 end epoch 55/100: loss_train=13.216161 loss_val=13.066485 loss_test=13.074732\n",
      "\n",
      "2018-05-07 21:36:28 start epoch 56/100, with learning rate = 0.0000121730\n",
      "2018-05-07 21:36:28 iteration 1/429: current training loss = 13.286711 (=3.682435+9.604276)\n",
      "2018-05-07 21:36:33 iteration 50/429: current training loss = 12.875919 (=3.513772+9.362146)\n",
      "2018-05-07 21:36:39 iteration 100/429: current training loss = 13.776304 (=3.738982+10.037323)\n",
      "2018-05-07 21:36:44 iteration 150/429: current training loss = 13.936810 (=3.687551+10.249258)\n",
      "2018-05-07 21:36:49 iteration 200/429: current training loss = 13.332316 (=3.487242+9.845074)\n",
      "2018-05-07 21:36:54 iteration 250/429: current training loss = 12.517585 (=3.513018+9.004566)\n",
      "2018-05-07 21:36:59 iteration 300/429: current training loss = 13.217301 (=3.663243+9.554058)\n",
      "2018-05-07 21:37:05 iteration 350/429: current training loss = 14.636805 (=3.735438+10.901367)\n",
      "2018-05-07 21:37:10 iteration 400/429: current training loss = 13.245842 (=3.552838+9.693005)\n",
      "2018-05-07 21:37:13 iteration 429/429: current training loss = 12.838963 (=3.525660+9.313303)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:37:30 end epoch 56/100: loss_train=13.069059 loss_val=12.896041 loss_test=12.989778\n",
      "\n",
      "2018-05-07 21:37:30 start epoch 57/100, with learning rate = 0.0000109557\n",
      "2018-05-07 21:37:30 iteration 1/429: current training loss = 13.195819 (=3.699256+9.496563)\n",
      "2018-05-07 21:37:35 iteration 50/429: current training loss = 13.210387 (=3.782244+9.428143)\n",
      "2018-05-07 21:37:41 iteration 100/429: current training loss = 15.282785 (=3.577115+11.705670)\n",
      "2018-05-07 21:37:46 iteration 150/429: current training loss = 14.101277 (=3.687196+10.414082)\n",
      "2018-05-07 21:37:51 iteration 200/429: current training loss = 13.159603 (=3.695213+9.464390)\n",
      "2018-05-07 21:37:57 iteration 250/429: current training loss = 13.148350 (=3.730212+9.418138)\n",
      "2018-05-07 21:38:02 iteration 300/429: current training loss = 14.487969 (=3.730520+10.757449)\n",
      "2018-05-07 21:38:07 iteration 350/429: current training loss = 12.974185 (=3.547143+9.427042)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-07 21:38:12 iteration 400/429: current training loss = 13.380455 (=3.717961+9.662494)\n",
      "2018-05-07 21:38:16 iteration 429/429: current training loss = 12.814107 (=3.544407+9.269700)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:38:32 end epoch 57/100: loss_train=13.203319 loss_val=13.065985 loss_test=13.123236\n",
      "\n",
      "2018-05-07 21:38:32 start epoch 58/100, with learning rate = 0.0000098601\n",
      "2018-05-07 21:38:32 iteration 1/429: current training loss = 12.476351 (=3.485799+8.990552)\n",
      "2018-05-07 21:38:37 iteration 50/429: current training loss = 13.719126 (=3.554783+10.164343)\n",
      "2018-05-07 21:38:43 iteration 100/429: current training loss = 14.394481 (=3.900144+10.494336)\n",
      "2018-05-07 21:38:48 iteration 150/429: current training loss = 12.130797 (=3.417747+8.713050)\n",
      "2018-05-07 21:38:53 iteration 200/429: current training loss = 13.945768 (=3.676619+10.269150)\n",
      "2018-05-07 21:38:58 iteration 250/429: current training loss = 13.225389 (=3.623260+9.602130)\n",
      "2018-05-07 21:39:04 iteration 300/429: current training loss = 13.530507 (=3.709826+9.820681)\n",
      "2018-05-07 21:39:09 iteration 350/429: current training loss = 14.698959 (=3.768102+10.930858)\n",
      "2018-05-07 21:39:15 iteration 400/429: current training loss = 14.184155 (=3.532982+10.651173)\n",
      "2018-05-07 21:39:18 iteration 429/429: current training loss = 12.419334 (=3.626914+8.792420)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:39:34 end epoch 58/100: loss_train=12.725751 loss_val=12.602056 loss_test=12.633714\n",
      "\n",
      "2018-05-07 21:39:34 start epoch 59/100, with learning rate = 0.0000088741\n",
      "2018-05-07 21:39:34 iteration 1/429: current training loss = 12.287449 (=3.598021+8.689428)\n",
      "2018-05-07 21:39:40 iteration 50/429: current training loss = 11.872920 (=3.447042+8.425879)\n",
      "2018-05-07 21:39:45 iteration 100/429: current training loss = 14.570270 (=3.642339+10.927931)\n",
      "2018-05-07 21:39:50 iteration 150/429: current training loss = 13.674690 (=3.693831+9.980860)\n",
      "2018-05-07 21:39:55 iteration 200/429: current training loss = 13.129516 (=3.524362+9.605154)\n",
      "2018-05-07 21:40:01 iteration 250/429: current training loss = 13.158237 (=3.562249+9.595987)\n",
      "2018-05-07 21:40:06 iteration 300/429: current training loss = 13.703658 (=3.786138+9.917521)\n",
      "2018-05-07 21:40:12 iteration 350/429: current training loss = 12.400021 (=3.493600+8.906421)\n",
      "2018-05-07 21:40:17 iteration 400/429: current training loss = 13.637794 (=3.804176+9.833618)\n",
      "2018-05-07 21:40:20 iteration 429/429: current training loss = 13.206018 (=3.520718+9.685301)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:40:37 end epoch 59/100: loss_train=13.232229 loss_val=13.037759 loss_test=13.102532\n",
      "\n",
      "2018-05-07 21:40:37 start epoch 60/100, with learning rate = 0.0000079867\n",
      "2018-05-07 21:40:37 iteration 1/429: current training loss = 13.371822 (=3.586197+9.785625)\n",
      "2018-05-07 21:40:42 iteration 50/429: current training loss = 13.491810 (=3.731297+9.760512)\n",
      "2018-05-07 21:40:48 iteration 100/429: current training loss = 13.205777 (=3.482237+9.723540)\n",
      "2018-05-07 21:40:53 iteration 150/429: current training loss = 13.273056 (=3.464811+9.808245)\n",
      "2018-05-07 21:40:58 iteration 200/429: current training loss = 13.712441 (=3.599002+10.113440)\n",
      "2018-05-07 21:41:04 iteration 250/429: current training loss = 12.948077 (=3.553452+9.394626)\n",
      "2018-05-07 21:41:09 iteration 300/429: current training loss = 13.664483 (=3.741227+9.923256)\n",
      "2018-05-07 21:41:14 iteration 350/429: current training loss = 13.120532 (=3.700625+9.419907)\n",
      "2018-05-07 21:41:19 iteration 400/429: current training loss = 13.142519 (=3.664481+9.478039)\n",
      "2018-05-07 21:41:22 iteration 429/429: current training loss = 14.234421 (=3.536025+10.698396)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:41:39 end epoch 60/100: loss_train=14.114510 loss_val=14.018795 loss_test=14.044304\n",
      "\n",
      "2018-05-07 21:41:39 start epoch 61/100, with learning rate = 0.0000071880\n",
      "2018-05-07 21:41:39 iteration 1/429: current training loss = 14.633880 (=3.743767+10.890112)\n",
      "2018-05-07 21:41:45 iteration 50/429: current training loss = 13.285317 (=3.718514+9.566803)\n",
      "2018-05-07 21:41:50 iteration 100/429: current training loss = 13.518168 (=3.806282+9.711886)\n",
      "2018-05-07 21:41:55 iteration 150/429: current training loss = 13.674357 (=3.835336+9.839021)\n",
      "2018-05-07 21:42:01 iteration 200/429: current training loss = 13.639009 (=3.851657+9.787352)\n",
      "2018-05-07 21:42:06 iteration 250/429: current training loss = 13.135481 (=3.544848+9.590633)\n",
      "2018-05-07 21:42:12 iteration 300/429: current training loss = 14.343414 (=3.639155+10.704260)\n",
      "2018-05-07 21:42:17 iteration 350/429: current training loss = 13.854508 (=3.531474+10.323034)\n",
      "2018-05-07 21:42:22 iteration 400/429: current training loss = 13.845458 (=3.636920+10.208538)\n",
      "2018-05-07 21:42:25 iteration 429/429: current training loss = 12.798264 (=3.651181+9.147083)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:42:42 end epoch 61/100: loss_train=13.502897 loss_val=13.357548 loss_test=13.313557\n",
      "\n",
      "2018-05-07 21:42:42 start epoch 62/100, with learning rate = 0.0000064692\n",
      "2018-05-07 21:42:42 iteration 1/429: current training loss = 13.151567 (=3.508370+9.643197)\n",
      "2018-05-07 21:42:47 iteration 50/429: current training loss = 14.011971 (=3.668095+10.343877)\n",
      "2018-05-07 21:42:53 iteration 100/429: current training loss = 13.616072 (=3.490280+10.125792)\n",
      "2018-05-07 21:42:58 iteration 150/429: current training loss = 12.219189 (=3.536476+8.682713)\n",
      "2018-05-07 21:43:03 iteration 200/429: current training loss = 13.583697 (=3.612375+9.971322)\n",
      "2018-05-07 21:43:08 iteration 250/429: current training loss = 13.473812 (=3.653353+9.820458)\n",
      "2018-05-07 21:43:13 iteration 300/429: current training loss = 12.958434 (=3.424053+9.534381)\n",
      "2018-05-07 21:43:19 iteration 350/429: current training loss = 13.783297 (=3.762659+10.020638)\n",
      "2018-05-07 21:43:24 iteration 400/429: current training loss = 14.075851 (=3.743691+10.332160)\n",
      "2018-05-07 21:43:27 iteration 429/429: current training loss = 12.759833 (=3.619209+9.140624)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:43:44 end epoch 62/100: loss_train=12.676232 loss_val=12.561009 loss_test=12.575351\n",
      "\n",
      "2018-05-07 21:43:44 start epoch 63/100, with learning rate = 0.0000058223\n",
      "2018-05-07 21:43:44 iteration 1/429: current training loss = 13.189246 (=3.719978+9.469269)\n",
      "2018-05-07 21:43:49 iteration 50/429: current training loss = 13.271748 (=3.866559+9.405189)\n",
      "2018-05-07 21:43:54 iteration 100/429: current training loss = 12.149345 (=3.455820+8.693525)\n",
      "2018-05-07 21:44:00 iteration 150/429: current training loss = 13.318460 (=3.702883+9.615577)\n",
      "2018-05-07 21:44:05 iteration 200/429: current training loss = 13.706412 (=3.613278+10.093134)\n",
      "2018-05-07 21:44:10 iteration 250/429: current training loss = 13.426389 (=3.625254+9.801135)\n",
      "2018-05-07 21:44:15 iteration 300/429: current training loss = 13.461969 (=3.629645+9.832324)\n",
      "2018-05-07 21:44:21 iteration 350/429: current training loss = 13.559140 (=3.639140+9.920000)\n",
      "2018-05-07 21:44:26 iteration 400/429: current training loss = 12.994744 (=3.766088+9.228657)\n",
      "2018-05-07 21:44:29 iteration 429/429: current training loss = 12.923402 (=3.500598+9.422804)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:44:46 end epoch 63/100: loss_train=13.475413 loss_val=13.294052 loss_test=13.347930\n",
      "\n",
      "2018-05-07 21:44:46 start epoch 64/100, with learning rate = 0.0000052401\n",
      "2018-05-07 21:44:46 iteration 1/429: current training loss = 13.792119 (=3.689628+10.102491)\n",
      "2018-05-07 21:44:51 iteration 50/429: current training loss = 13.410448 (=3.593895+9.816553)\n",
      "2018-05-07 21:44:56 iteration 100/429: current training loss = 13.288036 (=3.649696+9.638340)\n",
      "2018-05-07 21:45:01 iteration 150/429: current training loss = 13.229031 (=3.598937+9.630094)\n",
      "2018-05-07 21:45:07 iteration 200/429: current training loss = 12.906925 (=3.511561+9.395365)\n",
      "2018-05-07 21:45:12 iteration 250/429: current training loss = 12.562930 (=3.501965+9.060966)\n",
      "2018-05-07 21:45:18 iteration 300/429: current training loss = 12.531511 (=3.626316+8.905195)\n",
      "2018-05-07 21:45:23 iteration 350/429: current training loss = 13.167625 (=3.729419+9.438206)\n",
      "2018-05-07 21:45:28 iteration 400/429: current training loss = 13.058361 (=3.569377+9.488984)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-07 21:45:31 iteration 429/429: current training loss = 13.011031 (=3.587477+9.423553)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:45:48 end epoch 64/100: loss_train=13.342147 loss_val=13.160899 loss_test=13.235514\n",
      "\n",
      "2018-05-07 21:45:48 start epoch 65/100, with learning rate = 0.0000047161\n",
      "2018-05-07 21:45:49 iteration 1/429: current training loss = 13.160900 (=3.574306+9.586595)\n",
      "2018-05-07 21:45:54 iteration 50/429: current training loss = 13.299488 (=3.607235+9.692253)\n",
      "2018-05-07 21:45:59 iteration 100/429: current training loss = 13.613239 (=3.499800+10.113440)\n",
      "2018-05-07 21:46:04 iteration 150/429: current training loss = 13.723974 (=3.738960+9.985014)\n",
      "2018-05-07 21:46:10 iteration 200/429: current training loss = 12.362755 (=3.481567+8.881187)\n",
      "2018-05-07 21:46:15 iteration 250/429: current training loss = 13.790338 (=3.614350+10.175987)\n",
      "2018-05-07 21:46:20 iteration 300/429: current training loss = 13.483358 (=3.697666+9.785692)\n",
      "2018-05-07 21:46:25 iteration 350/429: current training loss = 13.477171 (=3.835885+9.641287)\n",
      "2018-05-07 21:46:31 iteration 400/429: current training loss = 12.604577 (=3.555486+9.049091)\n",
      "2018-05-07 21:46:34 iteration 429/429: current training loss = 13.334294 (=3.544146+9.790148)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:46:51 end epoch 65/100: loss_train=13.193145 loss_val=13.071174 loss_test=13.131943\n",
      "\n",
      "2018-05-07 21:46:51 start epoch 66/100, with learning rate = 0.0000042445\n",
      "2018-05-07 21:46:51 iteration 1/429: current training loss = 12.773339 (=3.515480+9.257859)\n",
      "2018-05-07 21:46:56 iteration 50/429: current training loss = 12.430603 (=3.398757+9.031846)\n",
      "2018-05-07 21:47:01 iteration 100/429: current training loss = 13.236635 (=3.657192+9.579443)\n",
      "2018-05-07 21:47:06 iteration 150/429: current training loss = 13.395321 (=3.655438+9.739883)\n",
      "2018-05-07 21:47:11 iteration 200/429: current training loss = 13.669627 (=3.807786+9.861841)\n",
      "2018-05-07 21:47:16 iteration 250/429: current training loss = 12.554898 (=3.517041+9.037857)\n",
      "2018-05-07 21:47:22 iteration 300/429: current training loss = 12.366341 (=3.573743+8.792597)\n",
      "2018-05-07 21:47:27 iteration 350/429: current training loss = 13.031838 (=3.596310+9.435528)\n",
      "2018-05-07 21:47:32 iteration 400/429: current training loss = 12.972865 (=3.650841+9.322024)\n",
      "2018-05-07 21:47:35 iteration 429/429: current training loss = 13.172082 (=3.736138+9.435944)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:47:52 end epoch 66/100: loss_train=13.115897 loss_val=12.994047 loss_test=13.008848\n",
      "\n",
      "2018-05-07 21:47:52 start epoch 67/100, with learning rate = 0.0000038200\n",
      "2018-05-07 21:47:52 iteration 1/429: current training loss = 12.860767 (=3.509304+9.351463)\n",
      "2018-05-07 21:47:58 iteration 50/429: current training loss = 13.128849 (=3.724465+9.404384)\n",
      "2018-05-07 21:48:03 iteration 100/429: current training loss = 11.805999 (=3.529644+8.276355)\n",
      "2018-05-07 21:48:08 iteration 150/429: current training loss = 13.078312 (=3.485943+9.592369)\n",
      "2018-05-07 21:48:13 iteration 200/429: current training loss = 12.735207 (=3.506371+9.228835)\n",
      "2018-05-07 21:48:19 iteration 250/429: current training loss = 12.489411 (=3.485679+9.003733)\n",
      "2018-05-07 21:48:24 iteration 300/429: current training loss = 13.045746 (=3.761194+9.284552)\n",
      "2018-05-07 21:48:29 iteration 350/429: current training loss = 12.570332 (=3.430198+9.140133)\n",
      "2018-05-07 21:48:35 iteration 400/429: current training loss = 14.341476 (=3.625995+10.715482)\n",
      "2018-05-07 21:48:38 iteration 429/429: current training loss = 12.524355 (=3.602580+8.921776)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:48:55 end epoch 67/100: loss_train=12.814309 loss_val=12.660951 loss_test=12.722476\n",
      "\n",
      "2018-05-07 21:48:55 start epoch 68/100, with learning rate = 0.0000034380\n",
      "2018-05-07 21:48:55 iteration 1/429: current training loss = 12.867266 (=3.654789+9.212477)\n",
      "2018-05-07 21:49:00 iteration 50/429: current training loss = 12.735582 (=3.711109+9.024473)\n",
      "2018-05-07 21:49:06 iteration 100/429: current training loss = 12.580671 (=3.627878+8.952793)\n",
      "2018-05-07 21:49:11 iteration 150/429: current training loss = 13.537728 (=3.771415+9.766314)\n",
      "2018-05-07 21:49:16 iteration 200/429: current training loss = 13.188667 (=3.533191+9.655476)\n",
      "2018-05-07 21:49:22 iteration 250/429: current training loss = 12.767863 (=3.430390+9.337473)\n",
      "2018-05-07 21:49:27 iteration 300/429: current training loss = 12.614473 (=3.564451+9.050022)\n",
      "2018-05-07 21:49:32 iteration 350/429: current training loss = 12.677474 (=3.565215+9.112259)\n",
      "2018-05-07 21:49:37 iteration 400/429: current training loss = 12.895010 (=3.697624+9.197386)\n",
      "2018-05-07 21:49:40 iteration 429/429: current training loss = 13.393064 (=3.553182+9.839882)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:49:57 end epoch 68/100: loss_train=13.008874 loss_val=12.868038 loss_test=12.866168\n",
      "\n",
      "2018-05-07 21:49:57 start epoch 69/100, with learning rate = 0.0000030942\n",
      "2018-05-07 21:49:57 iteration 1/429: current training loss = 13.083742 (=3.520417+9.563325)\n",
      "2018-05-07 21:50:02 iteration 50/429: current training loss = 13.402894 (=3.662557+9.740337)\n",
      "2018-05-07 21:50:08 iteration 100/429: current training loss = 14.127654 (=3.583249+10.544405)\n",
      "2018-05-07 21:50:13 iteration 150/429: current training loss = 13.175830 (=3.874826+9.301003)\n",
      "2018-05-07 21:50:19 iteration 200/429: current training loss = 13.308832 (=3.726730+9.582103)\n",
      "2018-05-07 21:50:24 iteration 250/429: current training loss = 12.265967 (=3.571582+8.694386)\n",
      "2018-05-07 21:50:29 iteration 300/429: current training loss = 12.637806 (=3.634273+9.003532)\n",
      "2018-05-07 21:50:34 iteration 350/429: current training loss = 13.243300 (=3.728900+9.514400)\n",
      "2018-05-07 21:50:40 iteration 400/429: current training loss = 12.925260 (=3.631960+9.293300)\n",
      "2018-05-07 21:50:43 iteration 429/429: current training loss = 13.681481 (=3.528755+10.152726)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:50:59 end epoch 69/100: loss_train=14.165281 loss_val=14.017470 loss_test=14.023973\n",
      "\n",
      "2018-05-07 21:50:59 start epoch 70/100, with learning rate = 0.0000027848\n",
      "2018-05-07 21:50:59 iteration 1/429: current training loss = 13.742014 (=3.394916+10.347097)\n",
      "2018-05-07 21:51:04 iteration 50/429: current training loss = 13.354570 (=3.689765+9.664804)\n",
      "2018-05-07 21:51:10 iteration 100/429: current training loss = 14.526810 (=3.692417+10.834393)\n",
      "2018-05-07 21:51:15 iteration 150/429: current training loss = 13.703237 (=3.580518+10.122719)\n",
      "2018-05-07 21:51:20 iteration 200/429: current training loss = 12.755233 (=3.762084+8.993149)\n",
      "2018-05-07 21:51:25 iteration 250/429: current training loss = 13.370356 (=3.775780+9.594576)\n",
      "2018-05-07 21:51:30 iteration 300/429: current training loss = 12.914104 (=3.496119+9.417986)\n",
      "2018-05-07 21:51:36 iteration 350/429: current training loss = 11.752467 (=3.568257+8.184211)\n",
      "2018-05-07 21:51:41 iteration 400/429: current training loss = 13.108403 (=3.491349+9.617054)\n",
      "2018-05-07 21:51:44 iteration 429/429: current training loss = 13.523811 (=3.498350+10.025461)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:52:00 end epoch 70/100: loss_train=12.757676 loss_val=12.583905 loss_test=12.636008\n",
      "\n",
      "2018-05-07 21:52:00 start epoch 71/100, with learning rate = 0.0000025063\n",
      "2018-05-07 21:52:01 iteration 1/429: current training loss = 12.994418 (=3.647826+9.346592)\n",
      "2018-05-07 21:52:06 iteration 50/429: current training loss = 12.659492 (=3.549990+9.109501)\n",
      "2018-05-07 21:52:11 iteration 100/429: current training loss = 13.755308 (=3.568873+10.186435)\n",
      "2018-05-07 21:52:17 iteration 150/429: current training loss = 13.261171 (=3.758757+9.502414)\n",
      "2018-05-07 21:52:22 iteration 200/429: current training loss = 13.192863 (=3.717431+9.475431)\n",
      "2018-05-07 21:52:27 iteration 250/429: current training loss = 12.959854 (=3.676337+9.283518)\n",
      "2018-05-07 21:52:33 iteration 300/429: current training loss = 12.531370 (=3.490368+9.041002)\n",
      "2018-05-07 21:52:38 iteration 350/429: current training loss = 12.219979 (=3.563591+8.656388)\n",
      "2018-05-07 21:52:43 iteration 400/429: current training loss = 13.253121 (=3.432125+9.820996)\n",
      "2018-05-07 21:52:46 iteration 429/429: current training loss = 12.214417 (=3.425279+8.789139)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:53:03 end epoch 71/100: loss_train=13.021373 loss_val=12.943674 loss_test=12.839419\n",
      "\n",
      "2018-05-07 21:53:03 start epoch 72/100, with learning rate = 0.0000022557\n",
      "2018-05-07 21:53:03 iteration 1/429: current training loss = 12.485822 (=3.502898+8.982924)\n",
      "2018-05-07 21:53:08 iteration 50/429: current training loss = 12.839542 (=3.693433+9.146110)\n",
      "2018-05-07 21:53:13 iteration 100/429: current training loss = 12.333582 (=3.547084+8.786497)\n",
      "2018-05-07 21:53:18 iteration 150/429: current training loss = 11.684921 (=3.500354+8.184567)\n",
      "2018-05-07 21:53:24 iteration 200/429: current training loss = 12.917336 (=3.565749+9.351586)\n",
      "2018-05-07 21:53:29 iteration 250/429: current training loss = 13.337608 (=3.557591+9.780018)\n",
      "2018-05-07 21:53:34 iteration 300/429: current training loss = 13.679910 (=3.404045+10.275865)\n",
      "2018-05-07 21:53:39 iteration 350/429: current training loss = 12.946597 (=3.596486+9.350111)\n",
      "2018-05-07 21:53:45 iteration 400/429: current training loss = 12.027720 (=3.539602+8.488119)\n",
      "2018-05-07 21:53:48 iteration 429/429: current training loss = 13.769013 (=3.604518+10.164495)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:54:05 end epoch 72/100: loss_train=13.314127 loss_val=13.170580 loss_test=13.244476\n",
      "\n",
      "2018-05-07 21:54:05 start epoch 73/100, with learning rate = 0.0000020301\n",
      "2018-05-07 21:54:05 iteration 1/429: current training loss = 13.281966 (=3.556305+9.725661)\n",
      "2018-05-07 21:54:10 iteration 50/429: current training loss = 13.947360 (=3.791035+10.156324)\n",
      "2018-05-07 21:54:15 iteration 100/429: current training loss = 13.072442 (=3.630388+9.442054)\n",
      "2018-05-07 21:54:20 iteration 150/429: current training loss = 12.681462 (=3.615037+9.066425)\n",
      "2018-05-07 21:54:26 iteration 200/429: current training loss = 12.743620 (=3.608965+9.134655)\n",
      "2018-05-07 21:54:31 iteration 250/429: current training loss = 12.863905 (=3.670160+9.193745)\n",
      "2018-05-07 21:54:36 iteration 300/429: current training loss = 13.395631 (=3.715407+9.680223)\n",
      "2018-05-07 21:54:42 iteration 350/429: current training loss = 11.663025 (=3.441935+8.221090)\n",
      "2018-05-07 21:54:47 iteration 400/429: current training loss = 12.587075 (=3.591048+8.996027)\n",
      "2018-05-07 21:54:50 iteration 429/429: current training loss = 12.927009 (=3.549887+9.377121)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:55:07 end epoch 73/100: loss_train=12.788250 loss_val=12.702269 loss_test=12.691771\n",
      "\n",
      "2018-05-07 21:55:07 start epoch 74/100, with learning rate = 0.0000018271\n",
      "2018-05-07 21:55:07 iteration 1/429: current training loss = 12.927689 (=3.564609+9.363080)\n",
      "2018-05-07 21:55:12 iteration 50/429: current training loss = 12.859623 (=3.603997+9.255627)\n",
      "2018-05-07 21:55:17 iteration 100/429: current training loss = 12.577155 (=3.610277+8.966878)\n",
      "2018-05-07 21:55:22 iteration 150/429: current training loss = 12.534842 (=3.561397+8.973446)\n",
      "2018-05-07 21:55:28 iteration 200/429: current training loss = 12.344299 (=3.486416+8.857883)\n",
      "2018-05-07 21:55:33 iteration 250/429: current training loss = 12.594578 (=3.520975+9.073603)\n",
      "2018-05-07 21:55:39 iteration 300/429: current training loss = 11.865004 (=3.539255+8.325748)\n",
      "2018-05-07 21:55:44 iteration 350/429: current training loss = 13.191871 (=3.465986+9.725885)\n",
      "2018-05-07 21:55:50 iteration 400/429: current training loss = 12.785521 (=3.599033+9.186487)\n",
      "2018-05-07 21:55:53 iteration 429/429: current training loss = 13.027259 (=3.583268+9.443991)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:56:09 end epoch 74/100: loss_train=12.623937 loss_val=12.466403 loss_test=12.512998\n",
      "\n",
      "2018-05-07 21:56:09 start epoch 75/100, with learning rate = 0.0000016444\n",
      "2018-05-07 21:56:09 iteration 1/429: current training loss = 11.872522 (=3.522018+8.350504)\n",
      "2018-05-07 21:56:14 iteration 50/429: current training loss = 14.046503 (=3.644574+10.401929)\n",
      "2018-05-07 21:56:19 iteration 100/429: current training loss = 13.328127 (=3.505436+9.822691)\n",
      "2018-05-07 21:56:25 iteration 150/429: current training loss = 14.141449 (=3.545416+10.596033)\n",
      "2018-05-07 21:56:31 iteration 200/429: current training loss = 12.219135 (=3.662998+8.556137)\n",
      "2018-05-07 21:56:36 iteration 250/429: current training loss = 13.771328 (=3.544454+10.226873)\n",
      "2018-05-07 21:56:42 iteration 300/429: current training loss = 13.297563 (=3.547536+9.750027)\n",
      "2018-05-07 21:56:47 iteration 350/429: current training loss = 12.596585 (=3.630322+8.966264)\n",
      "2018-05-07 21:56:53 iteration 400/429: current training loss = 13.517910 (=3.602675+9.915235)\n",
      "2018-05-07 21:56:56 iteration 429/429: current training loss = 11.829271 (=3.540409+8.288862)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:57:13 end epoch 75/100: loss_train=12.395893 loss_val=12.286996 loss_test=12.292044\n",
      "\n",
      "2018-05-07 21:57:13 start epoch 76/100, with learning rate = 0.0000014800\n",
      "2018-05-07 21:57:14 iteration 1/429: current training loss = 11.646327 (=3.390803+8.255524)\n",
      "2018-05-07 21:57:19 iteration 50/429: current training loss = 13.093285 (=3.633424+9.459861)\n",
      "2018-05-07 21:57:24 iteration 100/429: current training loss = 13.211473 (=3.732808+9.478665)\n",
      "2018-05-07 21:57:30 iteration 150/429: current training loss = 12.792960 (=3.762389+9.030571)\n",
      "2018-05-07 21:57:36 iteration 200/429: current training loss = 12.572815 (=3.623803+8.949012)\n",
      "2018-05-07 21:57:42 iteration 250/429: current training loss = 11.964975 (=3.434862+8.530113)\n",
      "2018-05-07 21:57:47 iteration 300/429: current training loss = 12.986420 (=3.676917+9.309504)\n",
      "2018-05-07 21:57:53 iteration 350/429: current training loss = 12.698040 (=3.614383+9.083657)\n",
      "2018-05-07 21:57:59 iteration 400/429: current training loss = 13.427999 (=3.594504+9.833495)\n",
      "2018-05-07 21:58:02 iteration 429/429: current training loss = 12.957582 (=3.920859+9.036722)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:58:20 end epoch 76/100: loss_train=12.260207 loss_val=12.139469 loss_test=12.202788\n",
      "\n",
      "2018-05-07 21:58:20 start epoch 77/100, with learning rate = 0.0000013320\n",
      "2018-05-07 21:58:20 iteration 1/429: current training loss = 12.614896 (=3.622791+8.992105)\n",
      "2018-05-07 21:58:25 iteration 50/429: current training loss = 13.577576 (=3.729120+9.848456)\n",
      "2018-05-07 21:58:30 iteration 100/429: current training loss = 12.679852 (=3.634633+9.045219)\n",
      "2018-05-07 21:58:36 iteration 150/429: current training loss = 12.772404 (=3.428451+9.343952)\n",
      "2018-05-07 21:58:41 iteration 200/429: current training loss = 12.882696 (=3.490998+9.391699)\n",
      "2018-05-07 21:58:47 iteration 250/429: current training loss = 12.365878 (=3.583550+8.782328)\n",
      "2018-05-07 21:58:52 iteration 300/429: current training loss = 12.856394 (=3.538177+9.318217)\n",
      "2018-05-07 21:58:58 iteration 350/429: current training loss = 11.827562 (=3.484499+8.343063)\n",
      "2018-05-07 21:59:03 iteration 400/429: current training loss = 12.744192 (=3.650922+9.093270)\n",
      "2018-05-07 21:59:06 iteration 429/429: current training loss = 12.161068 (=3.576463+8.584605)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 21:59:24 end epoch 77/100: loss_train=12.548416 loss_val=12.362871 loss_test=12.487957\n",
      "\n",
      "2018-05-07 21:59:24 start epoch 78/100, with learning rate = 0.0000011988\n",
      "2018-05-07 21:59:24 iteration 1/429: current training loss = 12.717549 (=3.562824+9.154726)\n",
      "2018-05-07 21:59:30 iteration 50/429: current training loss = 13.572477 (=3.670763+9.901713)\n",
      "2018-05-07 21:59:35 iteration 100/429: current training loss = 13.121780 (=3.526544+9.595237)\n",
      "2018-05-07 21:59:41 iteration 150/429: current training loss = 12.419816 (=3.631709+8.788107)\n",
      "2018-05-07 21:59:47 iteration 200/429: current training loss = 14.902054 (=3.594760+11.307293)\n",
      "2018-05-07 21:59:52 iteration 250/429: current training loss = 12.560654 (=3.692771+8.867882)\n",
      "2018-05-07 21:59:58 iteration 300/429: current training loss = 12.561159 (=3.675477+8.885682)\n",
      "2018-05-07 22:00:03 iteration 350/429: current training loss = 12.619858 (=3.521362+9.098495)\n",
      "2018-05-07 22:00:09 iteration 400/429: current training loss = 12.985462 (=3.572899+9.412563)\n",
      "2018-05-07 22:00:12 iteration 429/429: current training loss = 12.105898 (=3.520098+8.585799)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 22:00:30 end epoch 78/100: loss_train=12.311990 loss_val=12.125576 loss_test=12.200938\n",
      "\n",
      "2018-05-07 22:00:30 start epoch 79/100, with learning rate = 0.0000010789\n",
      "2018-05-07 22:00:30 iteration 1/429: current training loss = 12.353695 (=3.651189+8.702506)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-07 22:00:35 iteration 50/429: current training loss = 12.161823 (=3.623809+8.538014)\n",
      "2018-05-07 22:00:41 iteration 100/429: current training loss = 12.713289 (=3.535258+9.178031)\n",
      "2018-05-07 22:00:46 iteration 150/429: current training loss = 12.921948 (=3.631441+9.290507)\n",
      "2018-05-07 22:00:52 iteration 200/429: current training loss = 12.729874 (=3.582154+9.147719)\n",
      "2018-05-07 22:00:57 iteration 250/429: current training loss = 13.388449 (=3.533091+9.855357)\n",
      "2018-05-07 22:01:03 iteration 300/429: current training loss = 12.574069 (=3.629891+8.944178)\n",
      "2018-05-07 22:01:08 iteration 350/429: current training loss = 12.848001 (=3.715435+9.132565)\n",
      "2018-05-07 22:01:14 iteration 400/429: current training loss = 13.442454 (=3.776797+9.665657)\n",
      "2018-05-07 22:01:17 iteration 429/429: current training loss = 12.252735 (=3.613142+8.639593)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 22:01:35 end epoch 79/100: loss_train=12.223992 loss_val=12.075660 loss_test=12.176650\n",
      "\n",
      "2018-05-07 22:01:35 start epoch 80/100, with learning rate = 0.0000009710\n",
      "2018-05-07 22:01:35 iteration 1/429: current training loss = 12.400584 (=3.659893+8.740691)\n",
      "2018-05-07 22:01:40 iteration 50/429: current training loss = 13.134301 (=3.663043+9.471258)\n",
      "2018-05-07 22:01:45 iteration 100/429: current training loss = 12.295576 (=3.559885+8.735691)\n",
      "2018-05-07 22:01:51 iteration 150/429: current training loss = 12.843637 (=3.486102+9.357534)\n",
      "2018-05-07 22:01:56 iteration 200/429: current training loss = 11.424801 (=3.512393+7.912408)\n",
      "2018-05-07 22:02:02 iteration 250/429: current training loss = 13.342204 (=3.592510+9.749695)\n",
      "2018-05-07 22:02:07 iteration 300/429: current training loss = 12.213599 (=3.444757+8.768843)\n",
      "2018-05-07 22:02:12 iteration 350/429: current training loss = 11.923875 (=3.484116+8.439758)\n",
      "2018-05-07 22:02:18 iteration 400/429: current training loss = 12.909291 (=3.557996+9.351295)\n",
      "2018-05-07 22:02:21 iteration 429/429: current training loss = 12.288709 (=3.555750+8.732959)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 22:02:38 end epoch 80/100: loss_train=12.466619 loss_val=12.304961 loss_test=12.360272\n",
      "\n",
      "2018-05-07 22:02:38 start epoch 81/100, with learning rate = 0.0000008739\n",
      "2018-05-07 22:02:38 iteration 1/429: current training loss = 12.033445 (=3.490700+8.542746)\n",
      "2018-05-07 22:02:44 iteration 50/429: current training loss = 12.467590 (=3.576357+8.891233)\n",
      "2018-05-07 22:02:49 iteration 100/429: current training loss = 12.707103 (=3.647809+9.059294)\n",
      "2018-05-07 22:02:55 iteration 150/429: current training loss = 12.351801 (=3.665622+8.686178)\n",
      "2018-05-07 22:03:01 iteration 200/429: current training loss = 13.008865 (=3.436566+9.572299)\n",
      "2018-05-07 22:03:06 iteration 250/429: current training loss = 12.350613 (=3.611625+8.738988)\n",
      "2018-05-07 22:03:12 iteration 300/429: current training loss = 12.920807 (=3.722959+9.197847)\n",
      "2018-05-07 22:03:17 iteration 350/429: current training loss = 11.994621 (=3.530998+8.463623)\n",
      "2018-05-07 22:03:23 iteration 400/429: current training loss = 12.522570 (=3.483387+9.039183)\n",
      "2018-05-07 22:03:26 iteration 429/429: current training loss = 12.295984 (=3.549751+8.746233)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 22:03:44 end epoch 81/100: loss_train=12.170540 loss_val=12.062593 loss_test=12.078485\n",
      "\n",
      "2018-05-07 22:03:44 start epoch 82/100, with learning rate = 0.0000007865\n",
      "2018-05-07 22:03:44 iteration 1/429: current training loss = 11.324482 (=3.348282+7.976200)\n",
      "2018-05-07 22:03:49 iteration 50/429: current training loss = 11.857185 (=3.628993+8.228192)\n",
      "2018-05-07 22:03:55 iteration 100/429: current training loss = 11.721645 (=3.578119+8.143527)\n",
      "2018-05-07 22:04:01 iteration 150/429: current training loss = 11.843525 (=3.600577+8.242949)\n",
      "2018-05-07 22:04:06 iteration 200/429: current training loss = 12.480503 (=3.569047+8.911456)\n",
      "2018-05-07 22:04:12 iteration 250/429: current training loss = 12.113260 (=3.555840+8.557421)\n",
      "2018-05-07 22:04:18 iteration 300/429: current training loss = 12.311344 (=3.436159+8.875185)\n",
      "2018-05-07 22:04:23 iteration 350/429: current training loss = 12.518336 (=3.637889+8.880447)\n",
      "2018-05-07 22:04:29 iteration 400/429: current training loss = 12.657513 (=3.488107+9.169406)\n",
      "2018-05-07 22:04:32 iteration 429/429: current training loss = 12.601234 (=3.562237+9.038998)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 22:04:49 end epoch 82/100: loss_train=12.711694 loss_val=12.532146 loss_test=12.657296\n",
      "\n",
      "2018-05-07 22:04:49 start epoch 83/100, with learning rate = 0.0000007079\n",
      "2018-05-07 22:04:50 iteration 1/429: current training loss = 13.003733 (=3.661844+9.341888)\n",
      "2018-05-07 22:04:55 iteration 50/429: current training loss = 13.582920 (=3.494873+10.088047)\n",
      "2018-05-07 22:05:00 iteration 100/429: current training loss = 12.666165 (=3.653346+9.012819)\n",
      "2018-05-07 22:05:06 iteration 150/429: current training loss = 11.570522 (=3.507496+8.063026)\n",
      "2018-05-07 22:05:11 iteration 200/429: current training loss = 12.573379 (=3.635289+8.938089)\n",
      "2018-05-07 22:05:17 iteration 250/429: current training loss = 12.131220 (=3.523472+8.607747)\n",
      "2018-05-07 22:05:22 iteration 300/429: current training loss = 12.826118 (=3.539879+9.286239)\n",
      "2018-05-07 22:05:28 iteration 350/429: current training loss = 12.755201 (=3.533249+9.221952)\n",
      "2018-05-07 22:05:34 iteration 400/429: current training loss = 11.508633 (=3.448085+8.060547)\n",
      "2018-05-07 22:05:37 iteration 429/429: current training loss = 12.151876 (=3.604469+8.547408)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 22:05:53 end epoch 83/100: loss_train=11.979242 loss_val=11.840416 loss_test=11.916927\n",
      "\n",
      "2018-05-07 22:05:53 start epoch 84/100, with learning rate = 0.0000006371\n",
      "2018-05-07 22:05:53 iteration 1/429: current training loss = 12.151089 (=3.545690+8.605398)\n",
      "2018-05-07 22:05:59 iteration 50/429: current training loss = 13.096937 (=3.696600+9.400337)\n",
      "2018-05-07 22:06:04 iteration 100/429: current training loss = 12.759353 (=3.701493+9.057859)\n",
      "2018-05-07 22:06:10 iteration 150/429: current training loss = 11.125478 (=3.322324+7.803154)\n",
      "2018-05-07 22:06:16 iteration 200/429: current training loss = 12.309380 (=3.407474+8.901905)\n",
      "2018-05-07 22:06:21 iteration 250/429: current training loss = 12.148103 (=3.504603+8.643499)\n",
      "2018-05-07 22:06:26 iteration 300/429: current training loss = 12.385036 (=3.458943+8.926092)\n",
      "2018-05-07 22:06:32 iteration 350/429: current training loss = 11.363036 (=3.430569+7.932467)\n",
      "2018-05-07 22:06:38 iteration 400/429: current training loss = 12.605499 (=3.485048+9.120451)\n",
      "2018-05-07 22:06:41 iteration 429/429: current training loss = 12.412132 (=3.520830+8.891302)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 22:06:59 end epoch 84/100: loss_train=12.178605 loss_val=12.009763 loss_test=12.105352\n",
      "\n",
      "2018-05-07 22:06:59 start epoch 85/100, with learning rate = 0.0000005734\n",
      "2018-05-07 22:06:59 iteration 1/429: current training loss = 12.563958 (=3.595118+8.968840)\n",
      "2018-05-07 22:07:05 iteration 50/429: current training loss = 11.680119 (=3.519318+8.160800)\n",
      "2018-05-07 22:07:10 iteration 100/429: current training loss = 11.320077 (=3.361897+7.958179)\n",
      "2018-05-07 22:07:15 iteration 150/429: current training loss = 11.360770 (=3.471152+7.889618)\n",
      "2018-05-07 22:07:21 iteration 200/429: current training loss = 12.783115 (=3.706105+9.077010)\n",
      "2018-05-07 22:07:26 iteration 250/429: current training loss = 12.875549 (=3.453659+9.421890)\n",
      "2018-05-07 22:07:32 iteration 300/429: current training loss = 12.057282 (=3.562526+8.494757)\n",
      "2018-05-07 22:07:38 iteration 350/429: current training loss = 13.748249 (=3.737898+10.010351)\n",
      "2018-05-07 22:07:43 iteration 400/429: current training loss = 12.777433 (=3.618181+9.159252)\n",
      "2018-05-07 22:07:46 iteration 429/429: current training loss = 12.723695 (=3.593531+9.130163)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 22:08:04 end epoch 85/100: loss_train=12.529099 loss_val=12.410765 loss_test=12.452975\n",
      "\n",
      "2018-05-07 22:08:04 start epoch 86/100, with learning rate = 0.0000005160\n",
      "2018-05-07 22:08:04 iteration 1/429: current training loss = 13.213001 (=3.721728+9.491274)\n",
      "2018-05-07 22:08:10 iteration 50/429: current training loss = 12.433739 (=3.425749+9.007989)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-07 22:08:15 iteration 100/429: current training loss = 12.719164 (=3.676316+9.042848)\n",
      "2018-05-07 22:08:20 iteration 150/429: current training loss = 13.390033 (=3.620449+9.769584)\n",
      "2018-05-07 22:08:26 iteration 200/429: current training loss = 11.628627 (=3.487134+8.141493)\n",
      "2018-05-07 22:08:31 iteration 250/429: current training loss = 12.292815 (=3.432678+8.860138)\n",
      "2018-05-07 22:08:36 iteration 300/429: current training loss = 12.162416 (=3.655238+8.507177)\n",
      "2018-05-07 22:08:42 iteration 350/429: current training loss = 12.410214 (=3.601029+8.809185)\n",
      "2018-05-07 22:08:47 iteration 400/429: current training loss = 12.301381 (=3.476081+8.825300)\n",
      "2018-05-07 22:08:51 iteration 429/429: current training loss = 12.221844 (=3.598676+8.623168)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 22:09:09 end epoch 86/100: loss_train=11.779350 loss_val=11.611108 loss_test=11.681138\n",
      "\n",
      "2018-05-07 22:09:09 start epoch 87/100, with learning rate = 0.0000004644\n",
      "2018-05-07 22:09:09 iteration 1/429: current training loss = 11.067869 (=3.414413+7.653457)\n",
      "2018-05-07 22:09:14 iteration 50/429: current training loss = 12.763388 (=3.463991+9.299397)\n",
      "2018-05-07 22:09:19 iteration 100/429: current training loss = 12.776766 (=3.494455+9.282310)\n",
      "2018-05-07 22:09:25 iteration 150/429: current training loss = 11.970895 (=3.475523+8.495372)\n",
      "2018-05-07 22:09:31 iteration 200/429: current training loss = 13.753100 (=3.768613+9.984488)\n",
      "2018-05-07 22:09:36 iteration 250/429: current training loss = 12.528708 (=3.458786+9.069921)\n",
      "2018-05-07 22:09:42 iteration 300/429: current training loss = 12.750789 (=3.670086+9.080703)\n",
      "2018-05-07 22:09:47 iteration 350/429: current training loss = 12.580122 (=3.576356+9.003765)\n",
      "2018-05-07 22:09:53 iteration 400/429: current training loss = 11.880090 (=3.551411+8.328678)\n",
      "2018-05-07 22:09:56 iteration 429/429: current training loss = 12.871110 (=3.747009+9.124102)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 22:10:14 end epoch 87/100: loss_train=12.513205 loss_val=12.399646 loss_test=12.439994\n",
      "\n",
      "2018-05-07 22:10:14 start epoch 88/100, with learning rate = 0.0000004180\n",
      "2018-05-07 22:10:14 iteration 1/429: current training loss = 12.416613 (=3.561235+8.855378)\n",
      "2018-05-07 22:10:19 iteration 50/429: current training loss = 12.776012 (=3.528285+9.247728)\n",
      "2018-05-07 22:10:25 iteration 100/429: current training loss = 11.793793 (=3.437830+8.355963)\n",
      "2018-05-07 22:10:31 iteration 150/429: current training loss = 12.882015 (=3.626893+9.255123)\n",
      "2018-05-07 22:10:37 iteration 200/429: current training loss = 12.138697 (=3.495503+8.643193)\n",
      "2018-05-07 22:10:42 iteration 250/429: current training loss = 12.026307 (=3.537499+8.488808)\n",
      "2018-05-07 22:10:48 iteration 300/429: current training loss = 12.435642 (=3.654647+8.780994)\n",
      "2018-05-07 22:10:53 iteration 350/429: current training loss = 11.665441 (=3.404486+8.260955)\n",
      "2018-05-07 22:10:59 iteration 400/429: current training loss = 13.532409 (=3.584340+9.948069)\n",
      "2018-05-07 22:11:02 iteration 429/429: current training loss = 12.666678 (=3.587165+9.079514)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 22:11:20 end epoch 88/100: loss_train=12.753697 loss_val=12.699479 loss_test=12.639394\n",
      "\n",
      "2018-05-07 22:11:20 start epoch 89/100, with learning rate = 0.0000003762\n",
      "2018-05-07 22:11:20 iteration 1/429: current training loss = 12.468830 (=3.458071+9.010759)\n",
      "2018-05-07 22:11:26 iteration 50/429: current training loss = 13.040064 (=3.521847+9.518216)\n",
      "2018-05-07 22:11:31 iteration 100/429: current training loss = 11.977445 (=3.587657+8.389788)\n",
      "2018-05-07 22:11:37 iteration 150/429: current training loss = 13.103876 (=3.664703+9.439174)\n",
      "2018-05-07 22:11:43 iteration 200/429: current training loss = 11.922053 (=3.492460+8.429593)\n",
      "2018-05-07 22:11:48 iteration 250/429: current training loss = 12.499339 (=3.497373+9.001966)\n",
      "2018-05-07 22:11:54 iteration 300/429: current training loss = 12.106392 (=3.461817+8.644575)\n",
      "2018-05-07 22:12:00 iteration 350/429: current training loss = 11.815090 (=3.576437+8.238653)\n",
      "2018-05-07 22:12:06 iteration 400/429: current training loss = 11.437999 (=3.430112+8.007887)\n",
      "2018-05-07 22:12:09 iteration 429/429: current training loss = 12.851602 (=3.633909+9.217693)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 22:12:27 end epoch 89/100: loss_train=12.547340 loss_val=12.344706 loss_test=12.496163\n",
      "\n",
      "2018-05-07 22:12:27 start epoch 90/100, with learning rate = 0.0000003386\n",
      "2018-05-07 22:12:27 iteration 1/429: current training loss = 12.124945 (=3.457287+8.667658)\n",
      "2018-05-07 22:12:32 iteration 50/429: current training loss = 12.147064 (=3.471875+8.675189)\n",
      "2018-05-07 22:12:38 iteration 100/429: current training loss = 12.142957 (=3.532144+8.610813)\n",
      "2018-05-07 22:12:44 iteration 150/429: current training loss = 11.730883 (=3.359732+8.371151)\n",
      "2018-05-07 22:12:50 iteration 200/429: current training loss = 12.826262 (=3.515676+9.310587)\n",
      "2018-05-07 22:12:56 iteration 250/429: current training loss = 12.157348 (=3.444211+8.713137)\n",
      "2018-05-07 22:13:01 iteration 300/429: current training loss = 12.399709 (=3.664115+8.735594)\n",
      "2018-05-07 22:13:07 iteration 350/429: current training loss = 12.296329 (=3.510522+8.785807)\n",
      "2018-05-07 22:13:12 iteration 400/429: current training loss = 12.831537 (=3.557763+9.273775)\n",
      "2018-05-07 22:13:16 iteration 429/429: current training loss = 12.056602 (=3.564934+8.491669)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 22:13:33 end epoch 90/100: loss_train=12.118775 loss_val=12.041368 loss_test=12.018112\n",
      "\n",
      "2018-05-07 22:13:33 start epoch 91/100, with learning rate = 0.0000003047\n",
      "2018-05-07 22:13:33 iteration 1/429: current training loss = 11.348900 (=3.318143+8.030756)\n",
      "2018-05-07 22:13:38 iteration 50/429: current training loss = 11.952206 (=3.606169+8.346037)\n",
      "2018-05-07 22:13:44 iteration 100/429: current training loss = 11.994841 (=3.475373+8.519468)\n",
      "2018-05-07 22:13:50 iteration 150/429: current training loss = 12.528069 (=3.661189+8.866879)\n",
      "2018-05-07 22:13:55 iteration 200/429: current training loss = 12.155390 (=3.572855+8.582535)\n",
      "2018-05-07 22:14:01 iteration 250/429: current training loss = 11.180953 (=3.505594+7.675359)\n",
      "2018-05-07 22:14:07 iteration 300/429: current training loss = 12.914976 (=3.639675+9.275301)\n",
      "2018-05-07 22:14:12 iteration 350/429: current training loss = 13.037684 (=3.779208+9.258476)\n",
      "2018-05-07 22:14:18 iteration 400/429: current training loss = 11.381969 (=3.487541+7.894428)\n",
      "2018-05-07 22:14:21 iteration 429/429: current training loss = 13.118906 (=3.564706+9.554200)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 22:14:39 end epoch 91/100: loss_train=13.541301 loss_val=13.333612 loss_test=13.430798\n",
      "\n",
      "2018-05-07 22:14:39 start epoch 92/100, with learning rate = 0.0000002742\n",
      "2018-05-07 22:14:39 iteration 1/429: current training loss = 14.021106 (=3.658597+10.362509)\n",
      "2018-05-07 22:14:44 iteration 50/429: current training loss = 12.785727 (=3.649626+9.136101)\n",
      "2018-05-07 22:14:50 iteration 100/429: current training loss = 12.147256 (=3.614957+8.532299)\n",
      "2018-05-07 22:14:56 iteration 150/429: current training loss = 12.360267 (=3.629537+8.730730)\n",
      "2018-05-07 22:15:01 iteration 200/429: current training loss = 12.366975 (=3.563420+8.803555)\n",
      "2018-05-07 22:15:07 iteration 250/429: current training loss = 12.243092 (=3.432218+8.810874)\n",
      "2018-05-07 22:15:12 iteration 300/429: current training loss = 13.051820 (=3.544385+9.507435)\n",
      "2018-05-07 22:15:18 iteration 350/429: current training loss = 12.036453 (=3.426221+8.610232)\n",
      "2018-05-07 22:15:23 iteration 400/429: current training loss = 12.089772 (=3.552544+8.537229)\n",
      "2018-05-07 22:15:26 iteration 429/429: current training loss = 12.996598 (=3.663439+9.333159)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 22:15:43 end epoch 92/100: loss_train=11.932563 loss_val=11.728803 loss_test=11.837056\n",
      "\n",
      "2018-05-07 22:15:43 start epoch 93/100, with learning rate = 0.0000002468\n",
      "2018-05-07 22:15:43 iteration 1/429: current training loss = 11.842005 (=3.421594+8.420410)\n",
      "2018-05-07 22:15:48 iteration 50/429: current training loss = 12.437086 (=3.525352+8.911735)\n",
      "2018-05-07 22:15:53 iteration 100/429: current training loss = 11.676431 (=3.421851+8.254580)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-07 22:15:59 iteration 150/429: current training loss = 11.959531 (=3.405004+8.554527)\n",
      "2018-05-07 22:16:05 iteration 200/429: current training loss = 11.869059 (=3.560312+8.308746)\n",
      "2018-05-07 22:16:10 iteration 250/429: current training loss = 11.871885 (=3.478671+8.393214)\n",
      "2018-05-07 22:16:16 iteration 300/429: current training loss = 11.632757 (=3.472419+8.160337)\n",
      "2018-05-07 22:16:21 iteration 350/429: current training loss = 12.682129 (=3.559456+9.122673)\n",
      "2018-05-07 22:16:26 iteration 400/429: current training loss = 11.425501 (=3.436250+7.989251)\n",
      "2018-05-07 22:16:29 iteration 429/429: current training loss = 11.437788 (=3.342714+8.095074)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 22:16:45 end epoch 93/100: loss_train=12.457772 loss_val=12.435576 loss_test=12.363435\n",
      "\n",
      "2018-05-07 22:16:45 start epoch 94/100, with learning rate = 0.0000002221\n",
      "2018-05-07 22:16:45 iteration 1/429: current training loss = 13.178617 (=3.661282+9.517336)\n",
      "2018-05-07 22:16:50 iteration 50/429: current training loss = 11.609246 (=3.426608+8.182638)\n",
      "2018-05-07 22:16:56 iteration 100/429: current training loss = 12.345728 (=3.584456+8.761272)\n",
      "2018-05-07 22:17:02 iteration 150/429: current training loss = 12.061905 (=3.556839+8.505067)\n",
      "2018-05-07 22:17:07 iteration 200/429: current training loss = 12.520157 (=3.575182+8.944975)\n",
      "2018-05-07 22:17:13 iteration 250/429: current training loss = 11.118378 (=3.386751+7.731627)\n",
      "2018-05-07 22:17:19 iteration 300/429: current training loss = 12.021528 (=3.626510+8.395018)\n",
      "2018-05-07 22:17:25 iteration 350/429: current training loss = 12.834637 (=3.626795+9.207842)\n",
      "2018-05-07 22:17:30 iteration 400/429: current training loss = 11.663984 (=3.505379+8.158605)\n",
      "2018-05-07 22:17:33 iteration 429/429: current training loss = 12.711900 (=3.602794+9.109106)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 22:17:51 end epoch 94/100: loss_train=12.285682 loss_val=12.190095 loss_test=12.259858\n",
      "\n",
      "2018-05-07 22:17:51 start epoch 95/100, with learning rate = 0.0000001999\n",
      "2018-05-07 22:17:51 iteration 1/429: current training loss = 13.029107 (=3.663516+9.365591)\n",
      "2018-05-07 22:17:57 iteration 50/429: current training loss = 12.498002 (=3.546626+8.951376)\n",
      "2018-05-07 22:18:02 iteration 100/429: current training loss = 11.753803 (=3.457115+8.296688)\n",
      "2018-05-07 22:18:08 iteration 150/429: current training loss = 12.162991 (=3.682179+8.480812)\n",
      "2018-05-07 22:18:14 iteration 200/429: current training loss = 11.824944 (=3.548374+8.276569)\n",
      "2018-05-07 22:18:20 iteration 250/429: current training loss = 11.880159 (=3.479754+8.400406)\n",
      "2018-05-07 22:18:25 iteration 300/429: current training loss = 12.552953 (=3.412572+9.140381)\n",
      "2018-05-07 22:18:31 iteration 350/429: current training loss = 11.566252 (=3.566313+7.999939)\n",
      "2018-05-07 22:18:36 iteration 400/429: current training loss = 11.750443 (=3.434799+8.315643)\n",
      "2018-05-07 22:18:40 iteration 429/429: current training loss = 11.426996 (=3.480477+7.946519)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 22:18:56 end epoch 95/100: loss_train=11.647743 loss_val=11.536537 loss_test=11.576284\n",
      "\n",
      "2018-05-07 22:18:56 start epoch 96/100, with learning rate = 0.0000001799\n",
      "2018-05-07 22:18:56 iteration 1/429: current training loss = 12.040490 (=3.660699+8.379791)\n",
      "2018-05-07 22:19:01 iteration 50/429: current training loss = 12.108335 (=3.547720+8.560616)\n",
      "2018-05-07 22:19:07 iteration 100/429: current training loss = 12.263138 (=3.606028+8.657110)\n",
      "2018-05-07 22:19:13 iteration 150/429: current training loss = 12.863448 (=3.692462+9.170986)\n",
      "2018-05-07 22:19:18 iteration 200/429: current training loss = 12.239746 (=3.476199+8.763547)\n",
      "2018-05-07 22:19:24 iteration 250/429: current training loss = 12.196636 (=3.629456+8.567181)\n",
      "2018-05-07 22:19:30 iteration 300/429: current training loss = 13.663451 (=3.832400+9.831051)\n",
      "2018-05-07 22:19:36 iteration 350/429: current training loss = 11.585257 (=3.543099+8.042157)\n",
      "2018-05-07 22:19:41 iteration 400/429: current training loss = 11.893105 (=3.460976+8.432129)\n",
      "2018-05-07 22:19:44 iteration 429/429: current training loss = 12.378654 (=3.526375+8.852280)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 22:20:01 end epoch 96/100: loss_train=12.346953 loss_val=12.179782 loss_test=12.253462\n",
      "\n",
      "2018-05-07 22:20:01 start epoch 97/100, with learning rate = 0.0000001619\n",
      "2018-05-07 22:20:01 iteration 1/429: current training loss = 12.864936 (=3.596530+9.268406)\n",
      "2018-05-07 22:20:06 iteration 50/429: current training loss = 11.990694 (=3.397572+8.593122)\n",
      "2018-05-07 22:20:12 iteration 100/429: current training loss = 13.458002 (=3.528315+9.929687)\n",
      "2018-05-07 22:20:17 iteration 150/429: current training loss = 12.120295 (=3.476528+8.643766)\n",
      "2018-05-07 22:20:23 iteration 200/429: current training loss = 11.514409 (=3.401538+8.112871)\n",
      "2018-05-07 22:20:28 iteration 250/429: current training loss = 12.464747 (=3.550180+8.914568)\n",
      "2018-05-07 22:20:34 iteration 300/429: current training loss = 12.239546 (=3.567384+8.672162)\n",
      "2018-05-07 22:20:39 iteration 350/429: current training loss = 12.991863 (=3.411517+9.580346)\n",
      "2018-05-07 22:20:44 iteration 400/429: current training loss = 12.631417 (=3.653361+8.978057)\n",
      "2018-05-07 22:20:48 iteration 429/429: current training loss = 12.793150 (=3.688577+9.104573)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 22:21:05 end epoch 97/100: loss_train=12.057406 loss_val=11.936089 loss_test=11.975617\n",
      "\n",
      "2018-05-07 22:21:05 start epoch 98/100, with learning rate = 0.0000001457\n",
      "2018-05-07 22:21:05 iteration 1/429: current training loss = 12.261208 (=3.548441+8.712767)\n",
      "2018-05-07 22:21:11 iteration 50/429: current training loss = 12.022937 (=3.638204+8.384732)\n",
      "2018-05-07 22:21:17 iteration 100/429: current training loss = 12.560751 (=3.433333+9.127418)\n",
      "2018-05-07 22:21:22 iteration 150/429: current training loss = 12.464052 (=3.494392+8.969660)\n",
      "2018-05-07 22:21:28 iteration 200/429: current training loss = 12.490762 (=3.583080+8.907682)\n",
      "2018-05-07 22:21:34 iteration 250/429: current training loss = 11.570395 (=3.583189+7.987206)\n",
      "2018-05-07 22:21:39 iteration 300/429: current training loss = 11.971670 (=3.611091+8.360579)\n",
      "2018-05-07 22:21:45 iteration 350/429: current training loss = 11.617697 (=3.559994+8.057703)\n",
      "2018-05-07 22:21:51 iteration 400/429: current training loss = 11.217374 (=3.404759+7.812614)\n",
      "2018-05-07 22:21:54 iteration 429/429: current training loss = 12.019295 (=3.584191+8.435103)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 22:22:12 end epoch 98/100: loss_train=11.617967 loss_val=11.533730 loss_test=11.546367\n",
      "\n",
      "2018-05-07 22:22:12 start epoch 99/100, with learning rate = 0.0000001312\n",
      "2018-05-07 22:22:12 iteration 1/429: current training loss = 11.613819 (=3.470817+8.143002)\n",
      "2018-05-07 22:22:18 iteration 50/429: current training loss = 12.130461 (=3.522924+8.607537)\n",
      "2018-05-07 22:22:24 iteration 100/429: current training loss = 12.413297 (=3.662480+8.750816)\n",
      "2018-05-07 22:22:30 iteration 150/429: current training loss = 11.651981 (=3.563769+8.088213)\n",
      "2018-05-07 22:22:35 iteration 200/429: current training loss = 12.516108 (=3.473763+9.042345)\n",
      "2018-05-07 22:22:41 iteration 250/429: current training loss = 11.523713 (=3.432370+8.091343)\n",
      "2018-05-07 22:22:46 iteration 300/429: current training loss = 12.493933 (=3.635944+8.857988)\n",
      "2018-05-07 22:22:52 iteration 350/429: current training loss = 11.269556 (=3.579903+7.689653)\n",
      "2018-05-07 22:22:57 iteration 400/429: current training loss = 11.389568 (=3.258198+8.131371)\n",
      "2018-05-07 22:23:01 iteration 429/429: current training loss = 13.015106 (=3.656042+9.359064)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 22:23:19 end epoch 99/100: loss_train=12.269791 loss_val=12.109923 loss_test=12.182335\n",
      "\n",
      "2018-05-07 22:23:19 start epoch 100/100, with learning rate = 0.0000001181\n",
      "2018-05-07 22:23:19 iteration 1/429: current training loss = 12.437937 (=3.669366+8.768571)\n",
      "2018-05-07 22:23:24 iteration 50/429: current training loss = 12.826611 (=3.373559+9.453052)\n",
      "2018-05-07 22:23:30 iteration 100/429: current training loss = 12.343902 (=3.620542+8.723360)\n",
      "2018-05-07 22:23:36 iteration 150/429: current training loss = 13.069992 (=3.619470+9.450521)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-07 22:23:41 iteration 200/429: current training loss = 11.510098 (=3.465724+8.044374)\n",
      "2018-05-07 22:23:46 iteration 250/429: current training loss = 12.204111 (=3.582030+8.622081)\n",
      "2018-05-07 22:23:52 iteration 300/429: current training loss = 12.697358 (=3.517987+9.179371)\n",
      "2018-05-07 22:23:58 iteration 350/429: current training loss = 12.101208 (=3.633309+8.467899)\n",
      "2018-05-07 22:24:04 iteration 400/429: current training loss = 11.514001 (=3.524690+7.989310)\n",
      "2018-05-07 22:24:07 iteration 429/429: current training loss = 12.161015 (=3.571764+8.589251)\n",
      "model saved in path: parameters/DRAW/DRAW.ckpt\n",
      "2018-05-07 22:24:24 end epoch 100/100: loss_train=11.942792 loss_val=11.820119 loss_test=11.875716\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size=128\n",
    "max_epoch=100\n",
    "print_every=50\n",
    "num_iteration=num_train//batch_size\n",
    "loss_train_his=[]\n",
    "loss_val_his=[]\n",
    "loss_test_his=[]\n",
    "\n",
    "def eval(dataset,num_iteration):\n",
    "    t_loss=0\n",
    "    for it in range(num_iteration):\n",
    "        images,labels=dataset.next_batch(batch_size)\n",
    "        loss_num = sess.run(total_loss,feed_dict={X:images.reshape((-1,1,28,28))})\n",
    "        t_loss+=loss_num\n",
    "    t_loss/=num_iteration\n",
    "    return t_loss\n",
    "\n",
    "saver=tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(max_epoch):\n",
    "        print(time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())),\n",
    "                  'start epoch %d/%d, with learning rate = %.10f' % (epoch+1,max_epoch,sess.run(learning_rate)))\n",
    "        average_loss=0\n",
    "        average_loss1=0\n",
    "        average_loss2=0\n",
    "        for it in range(num_iteration):\n",
    "            images,labels=mnist.train.next_batch(batch_size)\n",
    "            feed_dict={X:images.reshape((-1,1,28,28))}\n",
    "#             loss_num,l1,l2,temp1,temp2,_=sess.run([total_loss,total_latent_loss,total_likelihood_loss,X,canvas,train_step],feed_dict=feed_dict)\n",
    "            loss_num,l1,l2,_=sess.run([total_loss,total_latent_loss,total_likelihood_loss,train_step],feed_dict=feed_dict)\n",
    "            if it==0 or (it+1)%print_every==0 or it==num_iteration-1:\n",
    "                print(time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())),\n",
    "                      'iteration %d/%d:' % (it+1,num_iteration),'current training loss = %f (=%f+%f)' % (loss_num,l1,l2))\n",
    "        \n",
    "        loss_train=eval(mnist.train,num_train//batch_size)\n",
    "        loss_val=eval(mnist.validation,num_val//batch_size)\n",
    "        loss_test=eval(mnist.test,num_test//batch_size)\n",
    "        loss_train_his.append(loss_train)\n",
    "        loss_val_his.append(loss_val)\n",
    "        loss_test_his.append(loss_test)\n",
    "        \n",
    "        save_path = saver.save(sess, \"parameters/DRAW/DRAW.ckpt\")\n",
    "        print(\"model saved in path: %s\" % save_path)\n",
    "        print(time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())),'end epoch %d/%d:' % (epoch+1,max_epoch),\n",
    "                 'loss_train=%f loss_val=%f loss_test=%f' % (loss_train,loss_val,loss_test))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "ptr,=plt.plot(range(max_epoch),loss_train_his,'r-')\n",
    "pva,=plt.plot(range(max_epoch),loss_val_his,'b-')\n",
    "pte,=plt.plot(range(max_epoch),loss_test_his,'y-')\n",
    "plt.xlabel('training epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('loss on three sets')\n",
    "plt.legend((ptr,pva,pte),('train','validation','test'))\n",
    "plt.savefig('model-DRAW.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_patch(image,_gx,_gy,_stride,_sigma):\n",
    "    '''\n",
    "    draw the attention boundary on the canvas\n",
    "    width of edge reflects sigma\n",
    "    '''\n",
    "    fig = plt.figure(1)\n",
    "    ax = fig.add_subplot(111, aspect='equal')\n",
    "    plt.imshow(image,vmin=0,vmax=1,cmap='gray')\n",
    "    upper_left_x=_gx-_stride*(patch-1)//2\n",
    "    upper_left_y=_gy-_stride*(patch-1)//2\n",
    "    width=_stride*(patch-1)\n",
    "    height=_stride*(patch-1)\n",
    "    rect = patches.Rectangle((upper_left_x,upper_left_y),width,height,linewidth=_sigma*3.0,edgecolor='r',facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from parameters/DRAW/DRAW.ckpt\n",
      "time = 0\n",
      "gx = 17.691887\n",
      "gy = 10.155741\n",
      "stride = 1.7164845\n",
      "sigma = 1.1931188\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADPRJREFUeJzt3V2IHfd5x/Hvs3qxQcqFTLAQjlOnwYQ2hjpF+CYhqBQHtwTkXCREV0pbsrmoIbmL8U1MS8CUJu1dqFKLqNA4DTiuhSl1TUjrXLTGsinxi+rYuEqiaJFqFIhikLyrfXqxI7GSzs6cPW9zVs/3A8s5Z86cmWeH8zvz8p+Zf2QmkupZ6LsASf0w/FJRhl8qyvBLRRl+qSjDLxVl+KWiDL9UlOGXito+y5lFhKcTSlOWmTHMeGOt+SPigYh4IyLeioiHx5mWpNmKUc/tj4htwE+B+4HTwIvAocx8veUzrvmlKZvFmv8+4K3MfDsz3wO+BxwcY3qSZmic8N8B/GLd69PNsGtExGJEnIiIE2PMS9KEjXPAb9CmxQ2b9Zl5BDgCbvZL82ScNf9p4M51rz8AnBmvHEmzMk74XwTujogPRcRO4PPA8cmUJWnaRt7sz8yViHgIeBbYBhzNzNcmVpmkqRq5qW+kmbnPL03dTE7ykbR1GX6pKMMvFWX4paIMv1SU4ZeKMvxSUYZfKsrwS0UZfqkowy8VZfilogy/VJThl4oy/FJRhl8qyvBLRRl+qSjDLxVl+KWiDL9U1Ey76NbsLSy0/753vb9t27ax5t92d+iuO0dfvny59f3V1dWRatIa1/xSUYZfKsrwS0UZfqkowy8VZfilogy/VNRY7fwRcQq4AFwGVjJz/ySK0uZEbNwpa1c7/fbt7V+BW265ZaSarmhry+9qp19eXm59/+LFiyPVpDWTOMnnDzLznQlMR9IMudkvFRVdp1i2fjjif4FfAQn8XWYe6Rh/9JlpQ22b/W2b9X+/ssLvdk274/TfsXR897q+m6tjfHcn7XXgT/ouopGZG38h1hl3s//jmXkmIm4HnouI/8nM59ePEBGLwOKY89EU/A6wvytAHefXa+sa62c9M880j+eAp4D7BoxzJDP3ezBQmi8jr/kjYhewkJkXmuefAv5iYpVppt4FTg7YfXCzf2MfBXb1WsF4xtns3ws81exvbge+m5n/OpGqNHMnI/jkrbfeMNymvo29wIBN3S1k5PBn5tvA702wFk1B28HA60YceG3/OAeEu+zYsaP1/VsH/Bitt2tX+3p3ZWVlw/e6fli63l9ZWblhy2X9sp7mcpsUm/qkogy/VJThl4oy/FJRhl8qyvBLRXnrbl01qHmq6/bZXdpuDd512/CdO3e2vt/VVNimqynu3Xff7Xx/4eLFq819CxHXNE1eunSp9fPzcNtx1/xSUYZfKsrwS0UZfqkowy8VZfilogy/VJTt/DeBtjbrtsta138uV1cHtk13tYd3tdW3tcV3TXuoy2pHnPfu3btbPzvMLc3jvfeu3uYsFhauufdBV22280vqjeGXijL8UlGGXyrK8EtFGX6pKMMvFWU7/01u2PbkZLRr97va6ttuHd5V27jnAbT1OdDVH8FWuPX2uFzzS0UZfqkowy8VZfilogy/VJThl4oy/FJRne38EXEU+DRwLjPvaYbdBvwTcBdwCvhcZv5qemVqXnW1h7edO9B1zfu4be2j3ucAus9BWF5evvZ+CJnXnHewFc4TGGbN/x3ggeuGPQz8MDPvBn7YvJa0hXSGPzOfB85fN/ggcKx5fgx4cMJ1SZqyUff592bmEkDzePvkSpI0C1M/tz8iFoHFac9H0uaMuuY/GxH7AJrHcxuNmJlHMnN/Zu4fcV6SpmDU8B8HDjfPDwNPT6YcSbPSGf6IeAL4T+AjEXE6Iv4MeAy4PyLeBO5vXkvaQjr3+TPz0AZv/eGEa9Ecarsefxht7d3Tbgtvm37XvQuGen/99DOv+cw83Je/i2f4SUUZfqkowy8VZfilogy/VJThl4ry1t26alCzXldTX1dz3TSb88Zphhz3tuGZyfoxcojPzBvX/FJRhl8qyvBLRRl+qSjDLxVl+KWiDL9UlO38arUVLk0dxbj/18LCAuvPMohm2NXXY14KPQuu+aWiDL9UlOGXijL8UlGGXyrK8EtFGX6pKNv5b3Kt7c1b7PrzzWq7vn7c6/lXV1dvuJ5//TS3wrX9rvmlogy/VJThl4oy/FJRhl8qyvBLRRl+qajOdv6IOAp8GjiXmfc0wx4Fvgj8XzPaI5n5L9MqUhpFW1v+8vJy62e7uui+oZ0/k0uXLm2mvN4Ns+b/DvDAgOF/k5n3Nn8GX9piOsOfmc8D52dQi6QZGmef/6GI+ElEHI2IPROrSNJMjBr+bwEfBu4FloBvbDRiRCxGxImIODHivCRNwUgX9mTm2SvPI+LbwDMt4x4BjjTjzv/VDkV9FPivLXAxyjU66o22g3ZjXtgDa8tsKxsp/BGxLzOXmpefAV6dXEnqwy7gvr6LmKWt9kM3BcM09T0BHADeHxGnga8BByLiXtauZDwFfGmKNUqags7wZ+ahAYMfn0ItmoK2zdfXZ1jHzW4rLsuY5U0H3OefP12dS8zzTSm6ah+n44yt3FlJZg71j3t6r1SU4ZeKMvxSUYZfKsrwS0V56+7i5vlofpeu2rfy/zYLrvmlogy/VJThl4oy/FJRhl8qyvBLRRl+qSjDLxVl+KWiDL9UlOGXijL8UlGGXyrK8EtFGX6pKMMvFWX4paIMv1SU4ZeKMvxSUYZfKsrwS0UZfqmozvBHxJ0R8aOIOBkRr0XEl5vht0XEcxHxZvO4Z/rlSpqUzi66I2IfsC8zX46I9wEvAQ8CXwDOZ+ZjEfEwsCczv9oxLXtRkKZsYl10Z+ZSZr7cPL8AnATuAA4Cx5rRjrH2gyBpi9jUPn9E3AV8DHgB2JuZS7D2AwHcPuniJE3P0H31RcRu4EngK5n564ihtiyIiEVgcbTyJE1L5z4/QETsAJ4Bns3MbzbD3gAOZOZSc1zg3zPzIx3TcZ9fmrKJ7fPH2ir+ceDkleA3jgOHm+eHgac3W6Sk/gxztP8TwI+BV4DVZvAjrO33fx/4IPBz4LOZeb5jWq75pSkbds0/1Gb/pBh+afomttkv6eZk+KWiDL9UlOGXijL8UlGGXyrK8EtFGX6pKMMvFWX4paIMv1SU4ZeKMvxSUYZfKsrwS0UZfqkowy8VZfilogy/VJThl4oy/FJRhl8qyvBLRRl+qSjDLxVl+KWiDL9UlOGXijL8UlGGXyqqM/wRcWdE/CgiTkbEaxHx5Wb4oxHxy4j47+bvj6dfrqRJicxsHyFiH7AvM1+OiPcBLwEPAp8DfpOZfz30zCLaZyZpbJkZw4y3fYgJLQFLzfMLEXESuGO88iT1bVP7/BFxF/Ax4IVm0EMR8ZOIOBoRezb4zGJEnIiIE2NVKmmiOjf7r44YsRv4D+DrmfmDiNgLvAMk8Jes7Rr8acc03OyXpmzYzf6hwh8RO4BngGcz85sD3r8LeCYz7+mYjuGXpmzY8A9ztD+Ax4GT64PfHAi84jPAq5stUlJ/hjna/wngx8ArwGoz+BHgEHAva5v9p4AvNQcH26blml+asolu9k+K4Zemb2Kb/ZJuToZfKsrwS0UZfqkowy8VZfilogy/VJThl4oy/FJRhl8qyvBLRRl+qSjDLxVl+KWiOm/gOWHvAD9b9/r9zbB5NK+1zWtdYG2jmmRtvzXsiDO9nv+GmUecyMz9vRXQYl5rm9e6wNpG1VdtbvZLRRl+qai+w3+k5/m3mdfa5rUusLZR9VJbr/v8kvrT95pfUk96CX9EPBARb0TEWxHxcB81bCQiTkXEK03Pw712MdZ0g3YuIl5dN+y2iHguIt5sHgd2k9ZTbXPRc3NLz9K9Lrt56/F65pv9EbEN+ClwP3AaeBE4lJmvz7SQDUTEKWB/ZvbeJhwRnwR+A/zDld6QIuKvgPOZ+Vjzw7knM786J7U9yiZ7bp5SbRv1LP0Felx2k+zxehL6WPPfB7yVmW9n5nvA94CDPdQx9zLzeeD8dYMPAsea58dY+/LM3Aa1zYXMXMrMl5vnF4ArPUv3uuxa6upFH+G/A/jFutenma8uvxP4t4h4KSIW+y5mgL1XekZqHm/vuZ7rdfbcPEvX9Sw9N8tulB6vJ62P8A/qTWSemhw+npm/D/wR8OfN5q2G8y3gw6x147YEfKPPYpqepZ8EvpKZv+6zlvUG1NXLcusj/KeBO9e9/gBwpoc6BsrMM83jOeAp1nZT5snZK52kNo/neq7nqsw8m5mXM3MV+DY9LrumZ+kngX/MzB80g3tfdoPq6mu59RH+F4G7I+JDEbET+DxwvIc6bhARu5oDMUTELuBTzF/vw8eBw83zw8DTPdZyjXnpuXmjnqXpednNW4/XvZzk0zRl/C2wDTiamV+feREDRMRvs7a2h7UrHr/bZ20R8QRwgLWrvs4CXwP+Gfg+8EHg58BnM3PmB942qO0Am+y5eUq1bdSz9Av0uOwm2eP1ROrxDD+pJs/wk4oy/FJRhl8qyvBLRRl+qSjDLxVl+KWiDL9U1P8DuQ5/XvxIEN8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 1\n",
      "gx = 17.104765\n",
      "gy = 11.48263\n",
      "stride = 2.141722\n",
      "sigma = 0.95892894\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 2\n",
      "gx = 16.746237\n",
      "gy = 12.049476\n",
      "stride = 2.138499\n",
      "sigma = 0.96457326\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAD2FJREFUeJzt3V+IHed5x/Hfs2v9/2NLxJJla2XFQZQWQ5WwMYWE4hIc3BKQcxETXam0VLmIoYFe1PgmhhIIIUnbq4CCRRRInARs1yKUJsGUOheNsSxC7EhN5CirRJW8GyHJ+mdJ1u6Ti501q/WZ9z17ZubM7D7fD4jz552Z8+hIvzNzzjvzvubuAhDPSNsFAGgH4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/ENQdw3wxM+N0QqBh7m79LFdpz29mj5rZr8zsTTN7ssq2AAyXDXpuv5mNSvq1pEcknZb0qqS97n4ssQ57fqBhw9jzPyTpTXc/6e43JX1P0p4K2wMwRFXCf5+k3897fLp47jZmtt/MjpjZkQqvBaBmVX7w63Vo8b7Denc/IOmAxGE/0CVV9vynJY3Ne7xd0plq5QAYlirhf1XSLjP7oJmtlPRZSYfrKQtA0wY+7Hf3W2b2hKQfSRqVdNDdf1lbZQAaNXBX30Avxnd+oHFDOckHwNJF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUEMduhuDMUtfpDUyUv4Zfscd6X/i0dHRSq+dc+vWrYHaJGl6errSayONPT8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEU/fwfk+tpXrVqVbF+7dm1p2+bNm5PrbtiwIdm+YsWKZHtu9OeLFy+Wtp0/fz657oULF5LtufMEkMaeHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCqtTPb2YTki5LmpZ0y93H6yhqucldE79y5cpk+5133plsv/vuu0vbdu3alVz3nnvuSbbnastdc3/q1KmB2iTpxo0byfZLly4l25FWx0k+f+Xu52rYDoAh4rAfCKpq+F3Sj83sNTPbX0dBAIaj6mH/x9z9jJltkfQTM/s/d395/gLFhwIfDEDHVNrzu/uZ4nZK0guSHuqxzAF3H+fHQKBbBg6/ma0zsw1z9yV9UtIbdRUGoFlVDvu3Snqh6Ma6Q9J33f2/aqkKQOMGDr+7n5T05zXWsmzl+vlzY+unrteXpDVr1pS2zczMJNe9du1asj3X115lbP1NmzYl28fGxpLt586le5hv3rxZ2pYbh+D69euV2pcCuvqAoAg/EBTDeC0Dh48e1bqSw29LTOUlVZ+OKyd1eJ079K7artRrp9esxWVJ24fwOoMi/MvAuulprSv7bp/5zo+4CP8yc3XBnp49f0lTes1KNja47ToR/mXk6siIPvHRj9723L333ptc56677kq250YWzv3anxqhN3dV3tTUVLK9q7/2v62l8QFA+DsgNcW2lO8K9Hm3C/9Tnjx5skJl+fDnhvZev359aVtuWPHcB1PucuXU0N5VLkWWpGPHjiXblwJ+7QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoOjn74DcCSfvvvtubgPv3V69evW2pitXrlTadpV+fCk9vXjVS52r1J47h2Dh+7hQ8u+dec+7gj0/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRFP/8QVO3Hz/U5z7+ef2G/fm7budpyQ3/n1k8NqPHOO+8k182dB5C7Jr/KWAK5wTxSU5uP/OY37517sXr16oG2Pwzs+YGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gqGw/v5kdlPQpSVPu/mDx3GZJ35e0U9KEpMfd/UJzZS5vub70VF/5Qqmx6nvJ9aVXrS03nkDKypUrk+25qctT4wHktp0bpyDVz2+//a00PS0z05YtW3ouMzk5Wbp+blr0uvSz5/+WpEcXPPekpJfcfZekl4rHAJaQbPjd/WVJC+dc2iPpUHH/kKTHaq4LQMMG/c6/1d3PSlJx2/vYBkBnNX5uv5ntl7S/6dcBsDiD7vknzWybJBW3pdOpuvsBdx939/EBXwtAAwYN/2FJ+4r7+yS9WE85AIYlG34ze1bS/0r6EzM7bWZ/L+nLkh4xsxOSHikeA1hCst/53X1vSdMnaq4lrNw18bn21LJVt527Zj43XkCqz/rixYvJdXN98Rs2bEi2p8YLyP29RkdHk+1jY2Olbfazn0mSRkZGtGPHjp7LpMZoyL2nuXMv+sUZfkBQhB8IivADQRF+ICjCDwRF+IGgGLp7Cch29c2bonuxXX25bqPcJcK5LrNr164l21NGRtL7ptxlt2+//XZpW2449Pvvvz/Z/sADD5S2zdVtZtq+fXvPZSYmJkrXz3WB1oU9PxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERT//EDR9We38KboXO3R31X7+qlOAV5GrPTVseOocACl/ufDu3btL2+aGQzczbdq0qecyq1atyq7fNPb8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU/fwdUPWa+9SyVc8xqHNY8WFLDRuemwY7Ney3lJ7+e46ZafXq1T3bUkOD088PoFGEHwiK8ANBEX4gKMIPBEX4gaAIPxBUtrPSzA5K+pSkKXd/sHjuaUn/IOkPxWJPuft/NlXkcldnX3rd/fy5Pufc2Pp1TSfdS66vPVV7bvrv3Pvy1ltvZdd1d507d67nMqnzDIZ17kQ/e/5vSXq0x/P/6u67iz8EH1hisuF395clnR9CLQCGqMp3/ifM7BdmdtDMeo9VBKCzBg3/NyR9SNJuSWclfa1sQTPbb2ZHzOzIgK8FoAEDhd/dJ9192t1nJH1T0kOJZQ+4+7i7jw9aJID6DRR+M9s27+GnJb1RTzkAhqWfrr5nJT0s6QNmdlrSFyU9bGa7NTta9ISkzzVYI4AGZMPv7nt7PP1MA7WgAU338+f62lP9/LnXzp1DkHvtjRs3lraVjac/p+w6/DmTk5OlbXN/55mZmdLzAa5fv166fpf6+QEsQ4QfCIrwA0ERfiAowg8ERfiBoBi6ewlYTNfPwmWrdhvluvqqXPKbWzc1vLWUnuZaktatW1fatn79+uS6qa44STpx4kRp2/yuvrLlLl++nF2/aez5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAo+vmXgCp99VWne67az5+S68fPDa+9Zs2aZPvatWtL23LnCFy4cCHZfurUqdK2uX56d9fExERyO21izw8ERfiBoAg/EBThB4Ii/EBQhB8IivADQdHP3wG5fvzFXN89PT1dtZzbVD1PoIpbt24l22/evJlsv3LlSmlb7j09fz49N+3Vq1eT7UsBe34gKPb8y8hGSX/I7A2XE7t0afB1M0c02clOEm3lU4V0C+FfZpbKf7xaVBmibEiz4nQZ4V8GykeDW96q/B5Rec/fx4dH1/9dbFjzgkmSmfFx20NuTrrcBTBN/ijX5LZzf68VK1Yk23Pz6aUu/Eld9CPlf/Arm4OvC9y9r380fvADgiL8QFDZw34zG5P0bUn3SJqRdMDd/93MNkv6vqSdkiYkPe7uyYugOewfTJPX1Lepypj//bSnpvDOrZs7h+DGjRvJ9jbVedh/S9I/ufufSvoLSZ83sz+T9KSkl9x9l6SXiscAlohs+N39rLsfLe5flnRc0n2S9kg6VCx2SNJjTRUJoH6L+s5vZjslfVjSK5K2uvtZafYDQtKWuosD0Jy++/nNbL2k5yR9wd0v9fs908z2S9o/WHkAmtLXnt/MVmg2+N9x9+eLpyfNbFvRvk3SVK913f2Au4+7+3gdBQOoRzb8NruLf0bScXf/+rymw5L2Fff3SXqx/vIANKWfrr6PS/qppNc129UnSU9p9nv/DyTtkPQ7SZ9x9+RpUXT1oU5NdnEO88zXuvXb1cfpvViyCH9vnN4LIInwA0ERfiAowg8ERfiBoAg/EBTDeGHJWsrdcV3Anh8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4LKht/Mxszsv83suJn90sz+sXj+aTP7fzP7efHnb5ovF0BdLDfxgZltk7TN3Y+a2QZJr0l6TNLjkq64+1f7fjEzZlkAGubu1s9y2Rl73P2spLPF/ctmdlzSfdXKA9C2RX3nN7Odkj4s6ZXiqSfM7BdmdtDMNpWss9/MjpjZkUqVAqhV9rD/vQXN1kv6H0lfcvfnzWyrpHOSXNK/aParwd9ltsFhP9Cwfg/7+wq/ma2Q9ENJP3L3r/do3ynph+7+YGY7hB9oWL/h7+fXfpP0jKTj84Nf/BA459OS3lhskQDa08+v/R+X9FNJr0uaKZ5+StJeSbs1e9g/IelzxY+DqW2x5wcaVuthf10IP9C82g77ASxPhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaCyA3jW7JykU/Mef6B4rou6WltX65KobVB11nZ/vwsO9Xr+97242RF3H2+tgISu1tbVuiRqG1RbtXHYDwRF+IGg2g7/gZZfP6WrtXW1LonaBtVKba1+5wfQnrb3/ABa0kr4zexRM/uVmb1pZk+2UUMZM5sws9eLmYdbnWKsmAZtyszemPfcZjP7iZmdKG57TpPWUm2dmLk5MbN0q+9d12a8Hvphv5mNSvq1pEcknZb0qqS97n5sqIWUMLMJSePu3nqfsJn9paQrkr49NxuSmX1F0nl3/3LxwbnJ3f+5I7U9rUXO3NxQbWUzS/+tWnzv6pzxug5t7PkfkvSmu59095uSvidpTwt1dJ67vyzp/IKn90g6VNw/pNn/PENXUlsnuPtZdz9a3L8saW5m6Vbfu0RdrWgj/PdJ+v28x6fVrSm/XdKPzew1M9vfdjE9bJ2bGam43dJyPQtlZ24epgUzS3fmvRtkxuu6tRH+XrOJdKnL4WPu/hFJfy3p88XhLfrzDUkf0uw0bmclfa3NYoqZpZ+T9AV3v9RmLfP1qKuV962N8J+WNDbv8XZJZ1qooyd3P1PcTkl6QbNfU7pkcm6S1OJ2quV63uPuk+4+7e4zkr6pFt+7Ymbp5yR9x92fL55u/b3rVVdb71sb4X9V0i4z+6CZrZT0WUmHW6jjfcxsXfFDjMxsnaRPqnuzDx+WtK+4v0/Siy3WcpuuzNxcNrO0Wn7vujbjdSsn+RRdGf8maVTSQXf/0tCL6MHMHtDs3l6aveLxu23WZmbPSnpYs1d9TUr6oqT/kPQDSTsk/U7SZ9x96D+8ldT2sBY5c3NDtZXNLP2KWnzv6pzxupZ6OMMPiIkz/ICgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBPVHMT52qGFLL9UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 3\n",
      "gx = 15.942428\n",
      "gy = 12.802816\n",
      "stride = 2.3393629\n",
      "sigma = 0.7835712\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 4\n",
      "gx = 16.393238\n",
      "gy = 12.682791\n",
      "stride = 2.0945554\n",
      "sigma = 0.8561621\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 5\n",
      "gx = 15.017131\n",
      "gy = 13.478482\n",
      "stride = 2.3492763\n",
      "sigma = 0.8345068\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 6\n",
      "gx = 14.442847\n",
      "gy = 13.8927765\n",
      "stride = 2.3399587\n",
      "sigma = 0.87796706\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 7\n",
      "gx = 13.937519\n",
      "gy = 14.387347\n",
      "stride = 2.2440908\n",
      "sigma = 0.8767498\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 8\n",
      "gx = 13.372909\n",
      "gy = 14.767207\n",
      "stride = 2.2068708\n",
      "sigma = 0.82100314\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 9\n",
      "gx = 12.79353\n",
      "gy = 15.132955\n",
      "stride = 2.1270626\n",
      "sigma = 0.9161524\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 10\n",
      "gx = 12.060598\n",
      "gy = 15.584583\n",
      "stride = 2.0366004\n",
      "sigma = 0.92099017\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 11\n",
      "gx = 11.2080145\n",
      "gy = 16.24907\n",
      "stride = 1.917633\n",
      "sigma = 0.95699674\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 12\n",
      "gx = 10.507066\n",
      "gy = 16.648806\n",
      "stride = 1.912993\n",
      "sigma = 1.0242323\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 13\n",
      "gx = 10.12096\n",
      "gy = 16.984028\n",
      "stride = 1.8443285\n",
      "sigma = 1.0482502\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 14\n",
      "gx = 9.553763\n",
      "gy = 17.615438\n",
      "stride = 1.7145373\n",
      "sigma = 1.0659357\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAE4NJREFUeJzt3WtsVOeZB/D/gzGEcDFXX7hs3IRLFhEWVhRWIVplVVGRqCJpqiZNlA2rrUqzKattd7XaKF8aaVUp2k27W+2HSq6CSqQ2bSVyQVVTSpLVJkgbYgIkXGyHS0wwNjaXcDEGG9vPfvAhOwxznmeYOTNnzPv/ScieeebMvD7473Nm3vO+r6gqiCg8Y9JuABGlg+EnChTDTxQohp8oUAw/UaAYfqJAMfxEgWL4iQLF8BMFamw5X0xEeDkhUYmpquTzuKKO/CKyVkTaROSwiDxbzHMRUXlJodf2i0gVgE8ArAHQAaAZwOOqetDYhkd+ohIrx5F/JYDDqnpUVQcA/BrAQ0U8HxGVUTHhnwPgeMbtjui+64jIBhHZJSK7ingtIkpYMR/45Tq1uOG0XlWbADQBPO0nqiTFHPk7AMzLuD0XQGdxzSGicikm/M0AFojIl0RkHIBvAdiaTLOIqNQKPu1X1UER2QhgG4AqAJtU9UBiLSOikiq4q6+gF+N7fqKSK8tFPkQ0ejH8RIFi+IkCxfATBYrhJwoUw08UqLKO56fyE8mr16dkuCJU5eKRnyhQDD9RoBh+okAx/ESBYviJAsXwEwWKXX0VwOuOq6qqKrg+dqz9X+w9t9c2rytvcHAwtnb16tWCt83ntcnGIz9RoBh+okAx/ESBYviJAsXwEwWK4ScKFMNPFCj285eB11c+YcIEs15TU1Nwvba21tx28uTJZt27DmBoaMisnz59OrbW3d1tbnvy5EmzfuXKFbNONh75iQLF8BMFiuEnChTDTxQohp8oUAw/UaAYfqJAFdXPLyLtAC4CGAIwqKorkmjUraa6utqsz54926wvXrzYrC9YsCC2tmTJEnPb+vp6s+7183t97a2trbG1PXv2mNs2Nzeb9cOHD5t1siVxkc9fqWr8lRxEVJF42k8UqGLDrwD+KCIfisiGJBpEROVR7Gn/alXtFJFaANtFpFVV3818QPRHgX8YiCpMUUd+Ve2MvvYAeA3AyhyPaVLVFfwwkKiyFBx+EZkoIpOvfQ/gqwD2J9UwIiqtYk776wC8Fg1XHQvgV6r6h0RaRUQlV3D4VfUogD9LsC23LG/M/PLly836mjVrzPrdd98dW5s/f765rdc2b278/v5+sz5v3rzY2ty5c81tZ86cadZ3795t1o8dOxZbO3v2rLltX1+fWb8VsKuPKFAMP1GgGH6iQDH8RIFi+IkCxfATBUrKucyxiAS5pvKqVavM+lNPPWXWva6+SZMmxda8qbU948aNM+vetOPW9r29vea2LS0tZr2trc2sf/zxx7G19vZ2c9uDBw+a9UoeTqyq9lzxER75iQLF8BMFiuEnChTDTxQohp8oUAw/UaAYfqJAcYnuBCxcuNCsr1271qyvXr3arHtDW3t6emJr3jLXXj++t8S3188/fvz4gmqAv1/HjLGPXdY1LLNmzTK39aYs//zzz836mTNnzHol4JGfKFAMP1GgGH6iQDH8RIFi+IkCxfATBYrhJwoU+/nztGjRotjaE088YW67bt06sz5jxgyzfuLECbP+2WefxdauXr1qbtvY2GjW6+rqzLo1l0CxvGnFvWnJrf3q7Rdv6XJvnoQPPvjArJ86darg504Kj/xEgWL4iQLF8BMFiuEnChTDTxQohp8oUAw/UaDcfn4R2QTgawB6VHVJdN90AL8B0AigHcCjqmoPcC4xEXuqcm/curWUNAA8+eSTsbWNGzea206dOtWsf/TRR2Z93759Zv3cuXOxNW8Z7DT78c+fP2/WvTH13lwDXt3i7RdvvYuBgQGz3tzcHFvz5goYHh426/nK58j/CwDZs1E8C+BtVV0A4O3oNhGNIm74VfVdAGez7n4IwObo+80AHk64XURUYoW+569T1S4AiL4Wfn5FRKko+bX9IrIBwIZSvw4R3ZxCj/zdItIAANHX2BkkVbVJVVeo6ooCX4uISqDQ8G8FsD76fj2AN5JpDhGVixt+EXkFwP8CWCQiHSLybQAvAFgjIocArIluE9Eo4r7nV9XHY0pfSbgtRfHmgL/jjjvM+oMPPmjWn3nmmdia14/v8dah9/r5rbnz58yZU1Cb8tXf32/WrbkGurq6zG1vv/12s+6N5y/m/8Wb1//hh+0Oru7ubrP+6aefxtYuXLhgblvOfn4iugUx/ESBYviJAsXwEwWK4ScKFMNPFKhRNXW3NWx34sSJ5rbLli0z64899phZnz59ulm37N+/36y3t7ebdW9oqzXNtNfd1dvba9YPHTpk1r0urY6Ojtia19U3ODho1ltbW836nXfeGVtbunSpua03lNnrCrz33nvN+rZt22JrVvco4E87ni8e+YkCxfATBYrhJwoUw08UKIafKFAMP1GgRlVXXynI8DBq+vtRffq0/UCnW8oy1liRFQAmOqO41OmOu92YBXfcmTPmtlXOaEhvltrs/XZ12jTA6ZqkyjCqwl9MP//ixYtz3j/p4kX844svAlu3FtU2y91F1itZdk/6v//gB+jNWFrbmlbcm6L68uXLZt1bwvvAgQOxtZMnT5rbPvLII2bdY11jANhtHzOmPCfkPO0nChTDTxSoUXXaXxZ79gDOai03y5uJx5rVBQCmTJli1qcZlx6PcVYyunjxoln32nbh0CH8XVOT+RiqTAx/tro6oKEh0accdN5fXjHeFwPAbc71+YMzZsTWvPePA84yZped9+W9zmctVLl42k8UKIafKFAMP1GgRtV7fquf35vmOW4J7gnO++0keFNMe8tBez+b9aHd4cOHzW337t1r1nfv3m3WL7S14Z8zbu/YsQNnMj5HsJbh9sal33bbbWbdm2Ohpyd2ISl3yfZ169aZ9bFj7eh4U8lbczR4y81bde+irEw88hMFiuEnChTDTxQohp8oUAw/UaAYfqJAMfxEgXL7+UVkE4CvAehR1SXRfc8D+A6Aa7NUPKeqvy9VIzPaElvzrmGP65f1+muT4M2N78197/WHW33px44dM7f15og/fvy4WT/Z1nbd7ba2NnRn/F9Y4/k93rLqXj+/dX2Etaw5AFy6dMms19TUmPXOzk6zfuXKldia11d/M335lnyO/L8AsDbH/f+hqsuifyUPPhElyw2/qr4L4GwZ2kJEZVTMe/6NIvKxiGwSkWmJtYiIyqLQ8P8MwF0AlgHoAvDjuAeKyAYR2SUiuwp8LSIqgYLCr6rdqjqkqsMAfg5gpfHYJlVdoaorCm0kESWvoPCLSOZUN18HYC9DS0QVJ5+uvlcA3A9gpoh0APghgPtFZBkABdAO4LslbCMRlYAbflV9PMfdL5WgLa7h4eHYmjcRZdwc7pOz+uCPHj2KoRz98taY/LNn7c6QXbvsjzt27txp1s84C29Y1z9Y+wzw2+7Nb38+a8GR8xcuIKkZErxrMOrr68368uXLY2srV8a+UwXgzyXg8eZRsK798P7PksIr/IgCxfATBYrhJwoUw08UKIafKFAMP1GgRtXU3dZQxr6+PnPbo0eP5rx/atYy0EeOHEF/jiWq5syZE/vcg4OD5mtbU0hbbbvG626z9ovXtgtZXXXZTp8+bdarzapt5syZZt2b8nzp0qVm/b777outLVq0yNzW2y+tra1m/f333zfr1n4dGhoyt00Kj/xEgWL4iQLF8BMFiuEnChTDTxQohp8oUAw/UaBGVT+/ZWBgwKzHTY99tb//utsnT55EX1bfv/f83hLa3hLcCxcuNOtTpkwx69bU3d6QXc/UqVPt+uXLQHPzF7dXfvnL1y3RbS2F3djYaD63NSQXAFatWmXW77nnntiaN1z4vffeM+uvv/56UdufOnUqtuZdm5EUHvmJAsXwEwWK4ScKFMNPFCiGnyhQDD9RoBh+okCNqn5+a9y6188fN6Zes/pUT5w4gd4cY7mtqcFnz55tvrbXj2/1hQP+mHqr7i3vPXHiRLPu9fPX9PVd18//9NNPoz9j6ezx48fHbjtjxgzzuWtra826Nx+ANaW5Nx7/rbfeMuvbt2836+3t7Wa9P+v6kkxJLcHt4ZGfKFAMP1GgGH6iQDH8RIFi+IkCxfATBYrhJwqU288vIvMAvAygHsAwgCZV/amITAfwGwCNANoBPKqqN054XyZWvykAdHZ25rx/KGs55CNHjuDchAk3PO748eOxzz1r1izztRsaGsz6pEmTzPqVK1fMutWXP3nyZHPbadOmmfUJOfbFdbq6rrv5wAMPAM7Pe403bv3cOXux7xMnTpj1I0eOxNZ27Nhhbvvmm2+a9U8++cSsl2uZ7WLkc+QfBPBPqvqnAP4CwPdEZDGAZwG8raoLALwd3SaiUcINv6p2qeru6PuLAFoAzAHwEIDN0cM2A3i4VI0kouTd1Ht+EWkEsBzATgB1qtoFjPyBAGBfi0lEFSXva/tFZBKALQC+r6oXrOums7bbAGBDYc0jolLJ68gvItUYCf4vVfXV6O5uEWmI6g0Aco6cUdUmVV2hqiuSaDARJcMNv4wc4l8C0KKqP8kobQWwPvp+PYA3km8eEZVKPqf9qwH8NYB9IrI3uu85AC8A+K2IfBvAZwC+WZomJiNuyeXsSbdbW1txKse0zu+8807sc3vDZr0hv9XV9kLX3jTTVt17e2ZN+w34S1UPdXYi86fr7OzEcMYS09b23tLjXleet31LS0tsbc+ePea23pDf0dCV53HDr6o7AMT9Bn0l2eYQUbnwCj+iQDH8RIFi+IkCxfATBYrhJwoUw08UKCnXNMEAICLle7E81QPIHJTaACBX7/H8+fNjn2Px4sXma3hTd3tTWI8ZY/+Ntob8Xrp0ydzWmpIc8KdEn3DuHP5ry5Yvbv/9N76B8xlLlvf19cVua9Xyee3LOZZSzxQ3XTsQv2T7Nd5+qWSqmte19zzyEwWK4ScKFMNPFCiGnyhQDD9RoBh+okAx/ESBYj8/8uvnt3jj8evr6816TU2NWa+qqjLr1rTlXl+6dx2A19c+a3AQRzL62++aMAHdGdclWOPevesXvJ/bY7Xd+7lG83j9fPv5857DLxR1BWxT7fwBrc2Y3CKXyc5kIFXOL+KAMf/9Zee1+7znduozy3jwoGQx/Fn2+g+5kbP4BGIWDCFKE9/zEwWK4ScKVPCn/T0Y+ZCvGNXOBJu1tfZ6Jt56et4HX9aHV97gl2IH12R/MHYqz/UcKH3Bh38YN//pfrZq7xfe+7Te6S1wP+03PpTrc7a95HziPuDUR+9n4sTTfqJABd/PXw7ekdu7TsBj9UkPOV19Xj1N+S4JV4hy/t6XG8fzE5GJ4ScKFMNPFCiGnyhQDD9RoBh+okAx/ESBcvv5RWQegJcxMvR9GECTqv5URJ4H8B0Ap6KHPqeqv3ee69btXCWqEPn28+cT/gYADaq6W0QmA/gQwMMAHgXQq6ov5tsohp+o9BKbzENVuxBNdqOqF0WkBcCc4ppHRGm7qff8ItIIYDmAndFdG0XkYxHZJCLTYrbZICK7RGRXUS0lokTlfW2/iEwC8D8AfqSqr4pIHYDTABTAv2LkrcHfOs/B036iEkvsPT8AiEg1gN8B2KaqP8lRbwTwO1Vd4jwPw09UYokN7JGRoVUvAWjJDH70QeA1Xwew/2YbSUTpyefT/vsAvAdgH/5/7obnADwOYBlGTvvbAXw3+nDQei4e+YlKLNHT/qQw/ESlx/H8RGRi+IkCxfATBYrhJwoUw08UKIafKFAMP1GgGH6iQDH8RIFi+IkCxfATBYrhJwoUw08UKIafKFDuBJ4JOw3gWMbtmdF9lahS21ap7QLYtkIl2bY78n1gWcfz3/DiIrtUdUVqDTBUatsqtV0A21aotNrG036iQDH8RIFKO/xNKb++pVLbVqntAti2QqXStlTf8xNRetI+8hNRSlIJv4isFZE2ETksIs+m0YY4ItIuIvtEZG/aS4xFy6D1iMj+jPumi8h2ETkUfc25TFpKbXteRE5E+26viDyYUtvmich/i0iLiBwQkX+I7k913xntSmW/lf20X0SqAHwCYA2ADgDNAB5X1YNlbUgMEWkHsEJVU+8TFpG/BNAL4OVrqyGJyL8BOKuqL0R/OKep6r9USNuex02u3FyitsWtLP03SHHfJbnidRLSOPKvBHBYVY+q6gCAXwN4KIV2VDxVfRfA2ay7HwKwOfp+M0Z+ecoupm0VQVW7VHV39P1FANdWlk513xntSkUa4Z8D4HjG7Q5U1pLfCuCPIvKhiGxIuzE51F1bGSn6Wptye7K5KzeXU9bK0hWz7wpZ8TppaYQ/12oildTlsFpV/xzAAwC+F53eUn5+BuAujCzj1gXgx2k2JlpZeguA76vqhTTbkilHu1LZb2mEvwPAvIzbcwF0ptCOnFS1M/raA+A1jLxNqSTd1xZJjb72pNyeL6hqt6oOqeowgJ8jxX0XrSy9BcAvVfXV6O7U912udqW139IIfzOABSLyJREZB+BbALam0I4biMjE6IMYiMhEAF9F5a0+vBXA+uj79QDeSLEt16mUlZvjVpZGyvuu0la8TuUin6gr4z8BVAHYpKo/KnsjchCROzFytAdGRjz+Ks22icgrAO7HyKivbgA/BPA6gN8C+BMAnwH4pqqW/YO3mLbdj5tcublEbYtbWXonUtx3Sa54nUh7eIUfUZh4hR9RoBh+okAx/ESBYviJAsXwEwWK4ScKFMNPFCiGnyhQ/wf8T2tOLHtciAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G_batch_size=tf.placeholder(shape=(),dtype=tf.int32,name='batch_size')\n",
    "G_init_state_decode=decoder_lstm.zero_state(G_batch_size, tf.float32)\n",
    "G_state_decode=None\n",
    "G_unit_gaussian=tf.distributions.Normal(loc=tf.zeros((G_batch_size,latent_dim)),scale=tf.ones((G_batch_size,latent_dim)))\n",
    "G_canvas=tf.zeros(shape=[G_batch_size,channel,height,width],dtype=tf.float32)\n",
    "\n",
    "G_canvas_his=[]\n",
    "G_write_paras_his=[]\n",
    "for t in range(n_glimpse):\n",
    "    G_Z=G_unit_gaussian.sample()\n",
    "    with tf.variable_scope(\"LSTM_decoder\") as vs:\n",
    "        decoder_out,G_state_decode=decoder_lstm(G_Z,G_init_state_decode if t==0 else G_state_decode)\n",
    "    _gx,_gy,_sigma,_stride,_gamma=decode_attention_para(decoder_out,WRITE_attention_paras)\n",
    "    G_write_paras_his.append((_gx,_gy,_stride,_sigma))\n",
    "    new_patch_image=WRITE_patch(decoder_out)\n",
    "    _FX,_FY=filterbank(G_batch_size,_gx,_gy,_sigma,_stride)\n",
    "    added_image=write(new_patch_image,G_batch_size,_FX,_FY,_gamma)\n",
    "    G_canvas+=added_image\n",
    "    G_canvas_his.append(G_canvas)\n",
    "\n",
    "saver=tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    saver.restore(sess, \"parameters/DRAW/DRAW.ckpt\")\n",
    "    output,paras=sess.run([G_canvas_his,G_write_paras_his],feed_dict={G_batch_size:1})\n",
    "#     images,labels=mnist.test.next_batch(1)\n",
    "#     plt.imshow(images.reshape(28,28),vmin=0,vmax=1,cmap='gray')\n",
    "#     plt.show()\n",
    "#     output,paras,temp=sess.run([canvas_his,write_paras_his,Z],feed_dict={X:images.reshape(-1,1,28,28)})\n",
    "#     print(temp)\n",
    "    for tt in range(n_glimpse):\n",
    "        print('time =',tt)\n",
    "        new_img=output[tt].reshape(28,28)\n",
    "        para=paras[tt]\n",
    "        print('gx =',para[0][0,0])\n",
    "        print('gy =',para[1][0,0])\n",
    "        print('stride =',para[2][0,0])\n",
    "        print('sigma =',np.sqrt(para[3][0,0]))\n",
    "#         print(np.min(new_img),np.max(new_img))\n",
    "#         print(dd)\n",
    "        draw_patch(new_img,para[0][0,0],para[1][0,0],para[2][0,0],np.sqrt(para[3][0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w,b=WRITE_attention_paras.variables\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     tf.global_variables_initializer().run()\n",
    "#     saver.restore(sess, \"parameters/DRAW/DRAW.ckpt\")\n",
    "#     w_out=sess.run(w)\n",
    "#     b_out=sess.run(b)\n",
    "#     print(w_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
